{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023, ISCS, Wenjie Zhang.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import argparse\n",
    "\n",
    "import builtins\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dsmeasure2.core.dsm_device_mng   import DeviceManager\n",
    "from dsmeasure2.core.dsm_operator_mng import OperatorManager\n",
    "\n",
    "from dsmeasure2.core.dsm_tensor   import AbstractTensor\n",
    "from dsmeasure2.core.dsm_device   import AbstractDeviceConfig, AbstractDevice\n",
    "from dsmeasure2.core.dsm_operator import AbstractOperatorConfig, \\\n",
    "                                         AbstractOperator, \\\n",
    "                                         OperatorComputationalConfig, \\\n",
    "                                         OperatorNonComputationalConfig , \\\n",
    "                                         OperatorCustomConfig , \\\n",
    "                                         OpStaticComputational , \\\n",
    "                                         OpStaticNonComputational, \\\n",
    "                                         OpStaticDerivative\n",
    "\n",
    "from dsmeasure2.device.device_cuda import DeviceCUDA, DeviceCUDAConfig\n",
    "from dsmeasure2.device.device_pcie import DevicePCIE4, DevicePCIEConfig\n",
    "\n",
    "from dsmeasure2.core.dsm_tensor_mng    import TensorManager\n",
    "from dsmeasure2.graph.tensor_define    import ActivationTensor, WeightTensor, TensorState\n",
    "from dsmeasure2.graph.operator_graph   import UnaryOperator, BinaryOperator, TernaryOperator, InitiateOperator\n",
    "from dsmeasure2.graph.unary_operator   import make_linear, make_layernorm, make_dropout, make_gelu, make_softmax\n",
    "from dsmeasure2.graph.binary_operator  import make_add, make_matmul\n",
    "from dsmeasure2.graph.operator_attn    import make_attn_tp, AttentionTPCRParallel, AttentionTPCRParallelBackward\n",
    "from dsmeasure2.graph.dsm2_transformer import make_ffn_gpt2, FeedForwardGPT2, FeedForwardGPT2Backward, \\\n",
    "                                              make_transformer_block, TransformerBlockGPT2, TransformerBlockGPT2Backward\n",
    "from dsmeasure2.graph.gpt2_sequence    import make_gpt_2\n",
    "from dsmeasure2.engine import CostEngine\n",
    "\n",
    "from dsmeasure2.flatten.flatten import flatten, convert_graph_to_flatten_seq\n",
    "from dsmeasure2.flatten.flatten_engine import FlattenEngine\n",
    "from dsmeasure2.flatten.flatten_stream import FlattenStream, stream_synchronize\n",
    "from dsmeasure2.flatten.flatten_offload import make_passive_offload\n",
    "from dsmeasure2.flatten.flatten_operator import FlattenInitiate, FlattenOperator\n",
    "\n",
    "gpt2 = make_gpt_2(\n",
    "        compute_time_linear_qkv=490,\n",
    "        compute_time_matmul_kq=214, \n",
    "        compute_time_sm=163,\n",
    "        compute_time_attention_dropout=286,\n",
    "        compute_time_matmul_v=191,\n",
    "        compute_time_linear=146,\n",
    "        compute_time_dropout_attn=140,\n",
    "\n",
    "        compute_time_linear_qkv_backward=340,\n",
    "        compute_time_matmul_kq_backward=531,\n",
    "        compute_time_sm_backward=212,\n",
    "        compute_time_attention_dropout_backward=248,\n",
    "        compute_time_matmul_v_backward=360,\n",
    "        compute_time_linear_backward=250,\n",
    "        compute_time_dropout_attn_backward=155,\n",
    "\n",
    "        compute_time_allreduce_attn=2200,\n",
    "\n",
    "        compute_time_linear_1=512,\n",
    "        compute_time_gelu=428,\n",
    "        compute_time_linear_2=483,\n",
    "        compute_time_dropout_ffn=75,\n",
    "        \n",
    "        compute_time_linear_1_backward=442,\n",
    "        compute_time_gelu_backward=210,\n",
    "        compute_time_linear_2_backward=100,\n",
    "        compute_time_dropout_ffn_backward=102,\n",
    "\n",
    "        compute_time_allreduce_ffn=2200,\n",
    "        \n",
    "        compute_time_layernorm_1=67,\n",
    "        compute_time_layernorm_2=67,\n",
    "        compute_time_residual_add_1=67,\n",
    "        compute_time_residual_add_2=67,\n",
    "\n",
    "        compute_time_layernorm_1_backward=236,\n",
    "        compute_time_layernorm_2_backward=236,\n",
    "\n",
    "        compute_time_loss_with_backward=20000,\n",
    "\n",
    "        batch_size=16,\n",
    "        seq_len=1024,\n",
    "        hidden_size=1792,\n",
    "        head_num=16,\n",
    "        head_hidden_size=112,\n",
    "        tensor_parallel=2,\n",
    "        precision=2,\n",
    "\n",
    "        transfomer_block_num=32\n",
    "    )\n",
    "for _op in gpt2:\n",
    "        OperatorManager().register(_op)\n",
    "DeviceManager().register(DeviceCUDAConfig(memory_max_capacity=80000, memory_limit_capacity=80000))\n",
    "DeviceManager().register(DevicePCIEConfig())\n",
    "# CostEngine().evaluation(10, [_op._config.op_uid for _op in gpt2])\n",
    "seq2 = flatten([_op._config.op_uid for _op in gpt2], [0], False)\n",
    "seq2 = convert_graph_to_flatten_seq([_op._config.op_uid for _op in gpt2], [0])\n",
    "stream_0 = FlattenStream(seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlattenEngine().evaluation([stream_0], 10)\n",
    "a = FlattenEngine()._cuda_mem_trace.copy()\n",
    "_ref_count = FlattenEngine()._tensor_ref_cnt.copy()\n",
    "_interval_tot = FlattenEngine()._interval_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "offload_streams = []\n",
    "_i = 2\n",
    "_end = int(len(stream_0._flat_seq) / 2) - 1\n",
    "_tensor_seen = {}\n",
    "while _i < _end:\n",
    "    if isinstance(stream_0[_i], FlattenOperator) and 'backward' not in stream_0[_i]._config.op_name:\n",
    "        _T = stream_0[_i]._input[0]\n",
    "        if _T.tensor_uid not in _tensor_seen:\n",
    "            _tensor_seen[_T.tensor_uid] = 0\n",
    "        else:\n",
    "            _tensor_seen[_T.tensor_uid] += 1\n",
    "        if _tensor_seen[_T.tensor_uid] < len(_ref_count[_T.tensor_uid]) - 1 and \\\n",
    "            _ref_count[_T.tensor_uid][_tensor_seen[_T.tensor_uid] + 1] - _ref_count[_T.tensor_uid][_tensor_seen[_T.tensor_uid]] > _interval_tot / 3:\n",
    "            # if _T.tensor_uid == 1641:\n",
    "            #     print(_ref_count[_T.tensor_uid][_tensor_seen[_T.tensor_uid] + 1] - _ref_count[_T.tensor_uid][_tensor_seen[_T.tensor_uid]])\n",
    "            offload_streams.append(make_passive_offload(stream_0, _i, _T.tensor_uid))\n",
    "            _end += 1\n",
    "    _i += 1\n",
    "# stream_offload_linear_qkv_148 = make_passive_offload(stream_0, 2, 107)\n",
    "# FlattenEngine().evaluation([stream_0, stream_offload_linear_qkv_148], 10)\n",
    "# print(len(offload_streams))\n",
    "while _i < len(stream_0._flat_seq):\n",
    "    if stream_0[_i]._config.op_name == 'loss_fn':\n",
    "        break\n",
    "    _i += 1\n",
    "stream_synchronize(stream_0, offload_streams, _i)\n",
    "FlattenEngine().evaluation([stream_0, *offload_streams], 10, verbose=False)\n",
    "b = FlattenEngine()._cuda_mem_trace.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2a3ff78d60>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(100,40))\n",
    "plt.plot(list(range(len(FlattenEngine()._cuda_mem_trace))), FlattenEngine()._cuda_mem_trace, '.-', markersize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2a403aec50>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(100,40))\n",
    "plt.plot(list(range(len(a))), a, '.-', markersize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<operator-1346, init_fn>] None None\n",
      "[<operator-1347, layernorm_forward>] [Tensor(uid=1218,size=28.0)] [Tensor(uid=1347,size=28)]\n",
      "[<operator-1348, linear_qkv>] [Tensor(uid=1347,size=28)] [Tensor(uid=1348,size=42)]\n",
      "[<operator-2439, linear_qkv_branch_offload>] None None\n",
      "[<operator-1349, matmul_qk>] [Tensor(uid=1348,size=42)] [Tensor(uid=1349,size=128)]\n",
      "[<operator-1350, softmax_forward>] [Tensor(uid=1349,size=128)] [Tensor(uid=1350,size=128)]\n",
      "[<operator-1351, dropout_forward>] [Tensor(uid=1350,size=128)] [Tensor(uid=1351,size=128), Tensor(uid=1352,size=64)]\n",
      "[<operator-2445, dropout_forward_branch_offload>] None None\n",
      "[<operator-1352, matmul_v>] [Tensor(uid=1351,size=128), Tensor(uid=1348,size=42)] [Tensor(uid=1353,size=14)]\n",
      "[<operator-2451, matmul_v_branch_offload>] None None\n",
      "[<operator-1353, linear_forward>] [Tensor(uid=1353,size=14)] [Tensor(uid=1354,size=28)]\n",
      "[<operator-2457, linear_forward_branch_offload>] None None\n",
      "[<operator-1354, allreduce_forward>] [Tensor(uid=1354,size=28)] []\n",
      "[<operator-1355, output_dropout>] [Tensor(uid=1354,size=28)] [Tensor(uid=1355,size=28), Tensor(uid=1356,size=14)]\n",
      "[<operator-1356, add_forward>] [Tensor(uid=1218,size=28.0), Tensor(uid=1355,size=28)] [Tensor(uid=1357,size=28)]\n",
      "[<operator-1357, layernorm_forward>] [Tensor(uid=1357,size=28)] [Tensor(uid=1358,size=28)]\n",
      "[<operator-1358, linear_1_forward>] [Tensor(uid=1358,size=28)] [Tensor(uid=1359,size=56)]\n",
      "[<operator-2463, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1359, gelu_forward>] [Tensor(uid=1359,size=56)] [Tensor(uid=1360,size=56)]\n",
      "[<operator-2469, gelu_forward_branch_offload>] None None\n",
      "[<operator-1360, linear_2_forward>] [Tensor(uid=1360,size=56)] [Tensor(uid=1361,size=28)]\n",
      "[<operator-2475, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1361, allreduce_forward>] [Tensor(uid=1361,size=28)] []\n",
      "[<operator-1362, dropout_forward>] [Tensor(uid=1361,size=28)] [Tensor(uid=1362,size=28), Tensor(uid=1363,size=14)]\n",
      "[<operator-1363, add_forward>] [Tensor(uid=1357,size=28), Tensor(uid=1362,size=28)] [Tensor(uid=1364,size=28)]\n",
      "[<operator-2481, add_forward_branch_offload>] None None\n",
      "[<operator-1364, layernorm_forward>] [Tensor(uid=1364,size=28)] [Tensor(uid=1365,size=28)]\n",
      "[<operator-1365, linear_qkv>] [Tensor(uid=1365,size=28)] [Tensor(uid=1366,size=42)]\n",
      "[<operator-2487, linear_qkv_branch_offload>] None None\n",
      "[<operator-1366, matmul_qk>] [Tensor(uid=1366,size=42)] [Tensor(uid=1367,size=128)]\n",
      "[<operator-1367, softmax_forward>] [Tensor(uid=1367,size=128)] [Tensor(uid=1368,size=128)]\n",
      "[<operator-1368, dropout_forward>] [Tensor(uid=1368,size=128)] [Tensor(uid=1369,size=128), Tensor(uid=1370,size=64)]\n",
      "[<operator-2493, dropout_forward_branch_offload>] None None\n",
      "[<operator-1369, matmul_v>] [Tensor(uid=1369,size=128), Tensor(uid=1366,size=42)] [Tensor(uid=1371,size=14)]\n",
      "[<operator-2499, matmul_v_branch_offload>] None None\n",
      "[<operator-1370, linear_forward>] [Tensor(uid=1371,size=14)] [Tensor(uid=1372,size=28)]\n",
      "[<operator-2505, linear_forward_branch_offload>] None None\n",
      "[<operator-1371, allreduce_forward>] [Tensor(uid=1372,size=28)] []\n",
      "[<operator-1372, output_dropout>] [Tensor(uid=1372,size=28)] [Tensor(uid=1373,size=28), Tensor(uid=1374,size=14)]\n",
      "[<operator-1373, add_forward>] [Tensor(uid=1364,size=28), Tensor(uid=1373,size=28)] [Tensor(uid=1375,size=28)]\n",
      "[<operator-2511, add_forward_branch_offload>] None None\n",
      "[<operator-1374, layernorm_forward>] [Tensor(uid=1375,size=28)] [Tensor(uid=1376,size=28)]\n",
      "[<operator-1375, linear_1_forward>] [Tensor(uid=1376,size=28)] [Tensor(uid=1377,size=56)]\n",
      "[<operator-2517, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1376, gelu_forward>] [Tensor(uid=1377,size=56)] [Tensor(uid=1378,size=56)]\n",
      "[<operator-2523, gelu_forward_branch_offload>] None None\n",
      "[<operator-1377, linear_2_forward>] [Tensor(uid=1378,size=56)] [Tensor(uid=1379,size=28)]\n",
      "[<operator-2529, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1378, allreduce_forward>] [Tensor(uid=1379,size=28)] []\n",
      "[<operator-1379, dropout_forward>] [Tensor(uid=1379,size=28)] [Tensor(uid=1380,size=28), Tensor(uid=1381,size=14)]\n",
      "[<operator-1380, add_forward>] [Tensor(uid=1375,size=28), Tensor(uid=1380,size=28)] [Tensor(uid=1382,size=28)]\n",
      "[<operator-2535, add_forward_branch_offload>] None None\n",
      "[<operator-1381, layernorm_forward>] [Tensor(uid=1382,size=28)] [Tensor(uid=1383,size=28)]\n",
      "[<operator-1382, linear_qkv>] [Tensor(uid=1383,size=28)] [Tensor(uid=1384,size=42)]\n",
      "[<operator-2541, linear_qkv_branch_offload>] None None\n",
      "[<operator-1383, matmul_qk>] [Tensor(uid=1384,size=42)] [Tensor(uid=1385,size=128)]\n",
      "[<operator-1384, softmax_forward>] [Tensor(uid=1385,size=128)] [Tensor(uid=1386,size=128)]\n",
      "[<operator-1385, dropout_forward>] [Tensor(uid=1386,size=128)] [Tensor(uid=1387,size=128), Tensor(uid=1388,size=64)]\n",
      "[<operator-2547, dropout_forward_branch_offload>] None None\n",
      "[<operator-1386, matmul_v>] [Tensor(uid=1387,size=128), Tensor(uid=1384,size=42)] [Tensor(uid=1389,size=14)]\n",
      "[<operator-2553, matmul_v_branch_offload>] None None\n",
      "[<operator-1387, linear_forward>] [Tensor(uid=1389,size=14)] [Tensor(uid=1390,size=28)]\n",
      "[<operator-2559, linear_forward_branch_offload>] None None\n",
      "[<operator-1388, allreduce_forward>] [Tensor(uid=1390,size=28)] []\n",
      "[<operator-1389, output_dropout>] [Tensor(uid=1390,size=28)] [Tensor(uid=1391,size=28), Tensor(uid=1392,size=14)]\n",
      "[<operator-1390, add_forward>] [Tensor(uid=1382,size=28), Tensor(uid=1391,size=28)] [Tensor(uid=1393,size=28)]\n",
      "[<operator-2565, add_forward_branch_offload>] None None\n",
      "[<operator-1391, layernorm_forward>] [Tensor(uid=1393,size=28)] [Tensor(uid=1394,size=28)]\n",
      "[<operator-1392, linear_1_forward>] [Tensor(uid=1394,size=28)] [Tensor(uid=1395,size=56)]\n",
      "[<operator-2571, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1393, gelu_forward>] [Tensor(uid=1395,size=56)] [Tensor(uid=1396,size=56)]\n",
      "[<operator-2577, gelu_forward_branch_offload>] None None\n",
      "[<operator-1394, linear_2_forward>] [Tensor(uid=1396,size=56)] [Tensor(uid=1397,size=28)]\n",
      "[<operator-2583, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1395, allreduce_forward>] [Tensor(uid=1397,size=28)] []\n",
      "[<operator-1396, dropout_forward>] [Tensor(uid=1397,size=28)] [Tensor(uid=1398,size=28), Tensor(uid=1399,size=14)]\n",
      "[<operator-1397, add_forward>] [Tensor(uid=1393,size=28), Tensor(uid=1398,size=28)] [Tensor(uid=1400,size=28)]\n",
      "[<operator-2589, add_forward_branch_offload>] None None\n",
      "[<operator-1398, layernorm_forward>] [Tensor(uid=1400,size=28)] [Tensor(uid=1401,size=28)]\n",
      "[<operator-1399, linear_qkv>] [Tensor(uid=1401,size=28)] [Tensor(uid=1402,size=42)]\n",
      "[<operator-2595, linear_qkv_branch_offload>] None None\n",
      "[<operator-1400, matmul_qk>] [Tensor(uid=1402,size=42)] [Tensor(uid=1403,size=128)]\n",
      "[<operator-1401, softmax_forward>] [Tensor(uid=1403,size=128)] [Tensor(uid=1404,size=128)]\n",
      "[<operator-1402, dropout_forward>] [Tensor(uid=1404,size=128)] [Tensor(uid=1405,size=128), Tensor(uid=1406,size=64)]\n",
      "[<operator-2601, dropout_forward_branch_offload>] None None\n",
      "[<operator-1403, matmul_v>] [Tensor(uid=1405,size=128), Tensor(uid=1402,size=42)] [Tensor(uid=1407,size=14)]\n",
      "[<operator-2607, matmul_v_branch_offload>] None None\n",
      "[<operator-1404, linear_forward>] [Tensor(uid=1407,size=14)] [Tensor(uid=1408,size=28)]\n",
      "[<operator-2613, linear_forward_branch_offload>] None None\n",
      "[<operator-1405, allreduce_forward>] [Tensor(uid=1408,size=28)] []\n",
      "[<operator-1406, output_dropout>] [Tensor(uid=1408,size=28)] [Tensor(uid=1409,size=28), Tensor(uid=1410,size=14)]\n",
      "[<operator-1407, add_forward>] [Tensor(uid=1400,size=28), Tensor(uid=1409,size=28)] [Tensor(uid=1411,size=28)]\n",
      "[<operator-2619, add_forward_branch_offload>] None None\n",
      "[<operator-1408, layernorm_forward>] [Tensor(uid=1411,size=28)] [Tensor(uid=1412,size=28)]\n",
      "[<operator-1409, linear_1_forward>] [Tensor(uid=1412,size=28)] [Tensor(uid=1413,size=56)]\n",
      "[<operator-2625, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1410, gelu_forward>] [Tensor(uid=1413,size=56)] [Tensor(uid=1414,size=56)]\n",
      "[<operator-2631, gelu_forward_branch_offload>] None None\n",
      "[<operator-1411, linear_2_forward>] [Tensor(uid=1414,size=56)] [Tensor(uid=1415,size=28)]\n",
      "[<operator-2637, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1412, allreduce_forward>] [Tensor(uid=1415,size=28)] []\n",
      "[<operator-1413, dropout_forward>] [Tensor(uid=1415,size=28)] [Tensor(uid=1416,size=28), Tensor(uid=1417,size=14)]\n",
      "[<operator-1414, add_forward>] [Tensor(uid=1411,size=28), Tensor(uid=1416,size=28)] [Tensor(uid=1418,size=28)]\n",
      "[<operator-2643, add_forward_branch_offload>] None None\n",
      "[<operator-1415, layernorm_forward>] [Tensor(uid=1418,size=28)] [Tensor(uid=1419,size=28)]\n",
      "[<operator-1416, linear_qkv>] [Tensor(uid=1419,size=28)] [Tensor(uid=1420,size=42)]\n",
      "[<operator-2649, linear_qkv_branch_offload>] None None\n",
      "[<operator-1417, matmul_qk>] [Tensor(uid=1420,size=42)] [Tensor(uid=1421,size=128)]\n",
      "[<operator-1418, softmax_forward>] [Tensor(uid=1421,size=128)] [Tensor(uid=1422,size=128)]\n",
      "[<operator-1419, dropout_forward>] [Tensor(uid=1422,size=128)] [Tensor(uid=1423,size=128), Tensor(uid=1424,size=64)]\n",
      "[<operator-2655, dropout_forward_branch_offload>] None None\n",
      "[<operator-1420, matmul_v>] [Tensor(uid=1423,size=128), Tensor(uid=1420,size=42)] [Tensor(uid=1425,size=14)]\n",
      "[<operator-2661, matmul_v_branch_offload>] None None\n",
      "[<operator-1421, linear_forward>] [Tensor(uid=1425,size=14)] [Tensor(uid=1426,size=28)]\n",
      "[<operator-2667, linear_forward_branch_offload>] None None\n",
      "[<operator-1422, allreduce_forward>] [Tensor(uid=1426,size=28)] []\n",
      "[<operator-1423, output_dropout>] [Tensor(uid=1426,size=28)] [Tensor(uid=1427,size=28), Tensor(uid=1428,size=14)]\n",
      "[<operator-1424, add_forward>] [Tensor(uid=1418,size=28), Tensor(uid=1427,size=28)] [Tensor(uid=1429,size=28)]\n",
      "[<operator-2673, add_forward_branch_offload>] None None\n",
      "[<operator-1425, layernorm_forward>] [Tensor(uid=1429,size=28)] [Tensor(uid=1430,size=28)]\n",
      "[<operator-1426, linear_1_forward>] [Tensor(uid=1430,size=28)] [Tensor(uid=1431,size=56)]\n",
      "[<operator-2679, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1427, gelu_forward>] [Tensor(uid=1431,size=56)] [Tensor(uid=1432,size=56)]\n",
      "[<operator-2685, gelu_forward_branch_offload>] None None\n",
      "[<operator-1428, linear_2_forward>] [Tensor(uid=1432,size=56)] [Tensor(uid=1433,size=28)]\n",
      "[<operator-2691, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1429, allreduce_forward>] [Tensor(uid=1433,size=28)] []\n",
      "[<operator-1430, dropout_forward>] [Tensor(uid=1433,size=28)] [Tensor(uid=1434,size=28), Tensor(uid=1435,size=14)]\n",
      "[<operator-1431, add_forward>] [Tensor(uid=1429,size=28), Tensor(uid=1434,size=28)] [Tensor(uid=1436,size=28)]\n",
      "[<operator-2697, add_forward_branch_offload>] None None\n",
      "[<operator-1432, layernorm_forward>] [Tensor(uid=1436,size=28)] [Tensor(uid=1437,size=28)]\n",
      "[<operator-1433, linear_qkv>] [Tensor(uid=1437,size=28)] [Tensor(uid=1438,size=42)]\n",
      "[<operator-2703, linear_qkv_branch_offload>] None None\n",
      "[<operator-1434, matmul_qk>] [Tensor(uid=1438,size=42)] [Tensor(uid=1439,size=128)]\n",
      "[<operator-1435, softmax_forward>] [Tensor(uid=1439,size=128)] [Tensor(uid=1440,size=128)]\n",
      "[<operator-1436, dropout_forward>] [Tensor(uid=1440,size=128)] [Tensor(uid=1441,size=128), Tensor(uid=1442,size=64)]\n",
      "[<operator-2709, dropout_forward_branch_offload>] None None\n",
      "[<operator-1437, matmul_v>] [Tensor(uid=1441,size=128), Tensor(uid=1438,size=42)] [Tensor(uid=1443,size=14)]\n",
      "[<operator-2715, matmul_v_branch_offload>] None None\n",
      "[<operator-1438, linear_forward>] [Tensor(uid=1443,size=14)] [Tensor(uid=1444,size=28)]\n",
      "[<operator-2721, linear_forward_branch_offload>] None None\n",
      "[<operator-1439, allreduce_forward>] [Tensor(uid=1444,size=28)] []\n",
      "[<operator-1440, output_dropout>] [Tensor(uid=1444,size=28)] [Tensor(uid=1445,size=28), Tensor(uid=1446,size=14)]\n",
      "[<operator-1441, add_forward>] [Tensor(uid=1436,size=28), Tensor(uid=1445,size=28)] [Tensor(uid=1447,size=28)]\n",
      "[<operator-2727, add_forward_branch_offload>] None None\n",
      "[<operator-1442, layernorm_forward>] [Tensor(uid=1447,size=28)] [Tensor(uid=1448,size=28)]\n",
      "[<operator-1443, linear_1_forward>] [Tensor(uid=1448,size=28)] [Tensor(uid=1449,size=56)]\n",
      "[<operator-2733, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1444, gelu_forward>] [Tensor(uid=1449,size=56)] [Tensor(uid=1450,size=56)]\n",
      "[<operator-2739, gelu_forward_branch_offload>] None None\n",
      "[<operator-1445, linear_2_forward>] [Tensor(uid=1450,size=56)] [Tensor(uid=1451,size=28)]\n",
      "[<operator-2745, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1446, allreduce_forward>] [Tensor(uid=1451,size=28)] []\n",
      "[<operator-1447, dropout_forward>] [Tensor(uid=1451,size=28)] [Tensor(uid=1452,size=28), Tensor(uid=1453,size=14)]\n",
      "[<operator-1448, add_forward>] [Tensor(uid=1447,size=28), Tensor(uid=1452,size=28)] [Tensor(uid=1454,size=28)]\n",
      "[<operator-2751, add_forward_branch_offload>] None None\n",
      "[<operator-1449, layernorm_forward>] [Tensor(uid=1454,size=28)] [Tensor(uid=1455,size=28)]\n",
      "[<operator-1450, linear_qkv>] [Tensor(uid=1455,size=28)] [Tensor(uid=1456,size=42)]\n",
      "[<operator-2757, linear_qkv_branch_offload>] None None\n",
      "[<operator-1451, matmul_qk>] [Tensor(uid=1456,size=42)] [Tensor(uid=1457,size=128)]\n",
      "[<operator-1452, softmax_forward>] [Tensor(uid=1457,size=128)] [Tensor(uid=1458,size=128)]\n",
      "[<operator-1453, dropout_forward>] [Tensor(uid=1458,size=128)] [Tensor(uid=1459,size=128), Tensor(uid=1460,size=64)]\n",
      "[<operator-2763, dropout_forward_branch_offload>] None None\n",
      "[<operator-1454, matmul_v>] [Tensor(uid=1459,size=128), Tensor(uid=1456,size=42)] [Tensor(uid=1461,size=14)]\n",
      "[<operator-2769, matmul_v_branch_offload>] None None\n",
      "[<operator-1455, linear_forward>] [Tensor(uid=1461,size=14)] [Tensor(uid=1462,size=28)]\n",
      "[<operator-2775, linear_forward_branch_offload>] None None\n",
      "[<operator-1456, allreduce_forward>] [Tensor(uid=1462,size=28)] []\n",
      "[<operator-1457, output_dropout>] [Tensor(uid=1462,size=28)] [Tensor(uid=1463,size=28), Tensor(uid=1464,size=14)]\n",
      "[<operator-1458, add_forward>] [Tensor(uid=1454,size=28), Tensor(uid=1463,size=28)] [Tensor(uid=1465,size=28)]\n",
      "[<operator-2781, add_forward_branch_offload>] None None\n",
      "[<operator-1459, layernorm_forward>] [Tensor(uid=1465,size=28)] [Tensor(uid=1466,size=28)]\n",
      "[<operator-1460, linear_1_forward>] [Tensor(uid=1466,size=28)] [Tensor(uid=1467,size=56)]\n",
      "[<operator-2787, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1461, gelu_forward>] [Tensor(uid=1467,size=56)] [Tensor(uid=1468,size=56)]\n",
      "[<operator-2793, gelu_forward_branch_offload>] None None\n",
      "[<operator-1462, linear_2_forward>] [Tensor(uid=1468,size=56)] [Tensor(uid=1469,size=28)]\n",
      "[<operator-2799, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1463, allreduce_forward>] [Tensor(uid=1469,size=28)] []\n",
      "[<operator-1464, dropout_forward>] [Tensor(uid=1469,size=28)] [Tensor(uid=1470,size=28), Tensor(uid=1471,size=14)]\n",
      "[<operator-1465, add_forward>] [Tensor(uid=1465,size=28), Tensor(uid=1470,size=28)] [Tensor(uid=1472,size=28)]\n",
      "[<operator-2805, add_forward_branch_offload>] None None\n",
      "[<operator-1466, layernorm_forward>] [Tensor(uid=1472,size=28)] [Tensor(uid=1473,size=28)]\n",
      "[<operator-1467, linear_qkv>] [Tensor(uid=1473,size=28)] [Tensor(uid=1474,size=42)]\n",
      "[<operator-2811, linear_qkv_branch_offload>] None None\n",
      "[<operator-1468, matmul_qk>] [Tensor(uid=1474,size=42)] [Tensor(uid=1475,size=128)]\n",
      "[<operator-1469, softmax_forward>] [Tensor(uid=1475,size=128)] [Tensor(uid=1476,size=128)]\n",
      "[<operator-1470, dropout_forward>] [Tensor(uid=1476,size=128)] [Tensor(uid=1477,size=128), Tensor(uid=1478,size=64)]\n",
      "[<operator-2817, dropout_forward_branch_offload>] None None\n",
      "[<operator-1471, matmul_v>] [Tensor(uid=1477,size=128), Tensor(uid=1474,size=42)] [Tensor(uid=1479,size=14)]\n",
      "[<operator-2823, matmul_v_branch_offload>] None None\n",
      "[<operator-1472, linear_forward>] [Tensor(uid=1479,size=14)] [Tensor(uid=1480,size=28)]\n",
      "[<operator-2829, linear_forward_branch_offload>] None None\n",
      "[<operator-1473, allreduce_forward>] [Tensor(uid=1480,size=28)] []\n",
      "[<operator-1474, output_dropout>] [Tensor(uid=1480,size=28)] [Tensor(uid=1481,size=28), Tensor(uid=1482,size=14)]\n",
      "[<operator-1475, add_forward>] [Tensor(uid=1472,size=28), Tensor(uid=1481,size=28)] [Tensor(uid=1483,size=28)]\n",
      "[<operator-2835, add_forward_branch_offload>] None None\n",
      "[<operator-1476, layernorm_forward>] [Tensor(uid=1483,size=28)] [Tensor(uid=1484,size=28)]\n",
      "[<operator-1477, linear_1_forward>] [Tensor(uid=1484,size=28)] [Tensor(uid=1485,size=56)]\n",
      "[<operator-2841, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1478, gelu_forward>] [Tensor(uid=1485,size=56)] [Tensor(uid=1486,size=56)]\n",
      "[<operator-2847, gelu_forward_branch_offload>] None None\n",
      "[<operator-1479, linear_2_forward>] [Tensor(uid=1486,size=56)] [Tensor(uid=1487,size=28)]\n",
      "[<operator-2853, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1480, allreduce_forward>] [Tensor(uid=1487,size=28)] []\n",
      "[<operator-1481, dropout_forward>] [Tensor(uid=1487,size=28)] [Tensor(uid=1488,size=28), Tensor(uid=1489,size=14)]\n",
      "[<operator-1482, add_forward>] [Tensor(uid=1483,size=28), Tensor(uid=1488,size=28)] [Tensor(uid=1490,size=28)]\n",
      "[<operator-2859, add_forward_branch_offload>] None None\n",
      "[<operator-1483, layernorm_forward>] [Tensor(uid=1490,size=28)] [Tensor(uid=1491,size=28)]\n",
      "[<operator-1484, linear_qkv>] [Tensor(uid=1491,size=28)] [Tensor(uid=1492,size=42)]\n",
      "[<operator-2865, linear_qkv_branch_offload>] None None\n",
      "[<operator-1485, matmul_qk>] [Tensor(uid=1492,size=42)] [Tensor(uid=1493,size=128)]\n",
      "[<operator-1486, softmax_forward>] [Tensor(uid=1493,size=128)] [Tensor(uid=1494,size=128)]\n",
      "[<operator-1487, dropout_forward>] [Tensor(uid=1494,size=128)] [Tensor(uid=1495,size=128), Tensor(uid=1496,size=64)]\n",
      "[<operator-2871, dropout_forward_branch_offload>] None None\n",
      "[<operator-1488, matmul_v>] [Tensor(uid=1495,size=128), Tensor(uid=1492,size=42)] [Tensor(uid=1497,size=14)]\n",
      "[<operator-2877, matmul_v_branch_offload>] None None\n",
      "[<operator-1489, linear_forward>] [Tensor(uid=1497,size=14)] [Tensor(uid=1498,size=28)]\n",
      "[<operator-2883, linear_forward_branch_offload>] None None\n",
      "[<operator-1490, allreduce_forward>] [Tensor(uid=1498,size=28)] []\n",
      "[<operator-1491, output_dropout>] [Tensor(uid=1498,size=28)] [Tensor(uid=1499,size=28), Tensor(uid=1500,size=14)]\n",
      "[<operator-1492, add_forward>] [Tensor(uid=1490,size=28), Tensor(uid=1499,size=28)] [Tensor(uid=1501,size=28)]\n",
      "[<operator-2889, add_forward_branch_offload>] None None\n",
      "[<operator-1493, layernorm_forward>] [Tensor(uid=1501,size=28)] [Tensor(uid=1502,size=28)]\n",
      "[<operator-1494, linear_1_forward>] [Tensor(uid=1502,size=28)] [Tensor(uid=1503,size=56)]\n",
      "[<operator-2895, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1495, gelu_forward>] [Tensor(uid=1503,size=56)] [Tensor(uid=1504,size=56)]\n",
      "[<operator-2901, gelu_forward_branch_offload>] None None\n",
      "[<operator-1496, linear_2_forward>] [Tensor(uid=1504,size=56)] [Tensor(uid=1505,size=28)]\n",
      "[<operator-2907, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1497, allreduce_forward>] [Tensor(uid=1505,size=28)] []\n",
      "[<operator-1498, dropout_forward>] [Tensor(uid=1505,size=28)] [Tensor(uid=1506,size=28), Tensor(uid=1507,size=14)]\n",
      "[<operator-1499, add_forward>] [Tensor(uid=1501,size=28), Tensor(uid=1506,size=28)] [Tensor(uid=1508,size=28)]\n",
      "[<operator-2913, add_forward_branch_offload>] None None\n",
      "[<operator-1500, layernorm_forward>] [Tensor(uid=1508,size=28)] [Tensor(uid=1509,size=28)]\n",
      "[<operator-1501, linear_qkv>] [Tensor(uid=1509,size=28)] [Tensor(uid=1510,size=42)]\n",
      "[<operator-2919, linear_qkv_branch_offload>] None None\n",
      "[<operator-1502, matmul_qk>] [Tensor(uid=1510,size=42)] [Tensor(uid=1511,size=128)]\n",
      "[<operator-1503, softmax_forward>] [Tensor(uid=1511,size=128)] [Tensor(uid=1512,size=128)]\n",
      "[<operator-1504, dropout_forward>] [Tensor(uid=1512,size=128)] [Tensor(uid=1513,size=128), Tensor(uid=1514,size=64)]\n",
      "[<operator-2925, dropout_forward_branch_offload>] None None\n",
      "[<operator-1505, matmul_v>] [Tensor(uid=1513,size=128), Tensor(uid=1510,size=42)] [Tensor(uid=1515,size=14)]\n",
      "[<operator-2931, matmul_v_branch_offload>] None None\n",
      "[<operator-1506, linear_forward>] [Tensor(uid=1515,size=14)] [Tensor(uid=1516,size=28)]\n",
      "[<operator-2937, linear_forward_branch_offload>] None None\n",
      "[<operator-1507, allreduce_forward>] [Tensor(uid=1516,size=28)] []\n",
      "[<operator-1508, output_dropout>] [Tensor(uid=1516,size=28)] [Tensor(uid=1517,size=28), Tensor(uid=1518,size=14)]\n",
      "[<operator-1509, add_forward>] [Tensor(uid=1508,size=28), Tensor(uid=1517,size=28)] [Tensor(uid=1519,size=28)]\n",
      "[<operator-2943, add_forward_branch_offload>] None None\n",
      "[<operator-1510, layernorm_forward>] [Tensor(uid=1519,size=28)] [Tensor(uid=1520,size=28)]\n",
      "[<operator-1511, linear_1_forward>] [Tensor(uid=1520,size=28)] [Tensor(uid=1521,size=56)]\n",
      "[<operator-2949, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1512, gelu_forward>] [Tensor(uid=1521,size=56)] [Tensor(uid=1522,size=56)]\n",
      "[<operator-2955, gelu_forward_branch_offload>] None None\n",
      "[<operator-1513, linear_2_forward>] [Tensor(uid=1522,size=56)] [Tensor(uid=1523,size=28)]\n",
      "[<operator-2961, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1514, allreduce_forward>] [Tensor(uid=1523,size=28)] []\n",
      "[<operator-1515, dropout_forward>] [Tensor(uid=1523,size=28)] [Tensor(uid=1524,size=28), Tensor(uid=1525,size=14)]\n",
      "[<operator-1516, add_forward>] [Tensor(uid=1519,size=28), Tensor(uid=1524,size=28)] [Tensor(uid=1526,size=28)]\n",
      "[<operator-2967, add_forward_branch_offload>] None None\n",
      "[<operator-1517, layernorm_forward>] [Tensor(uid=1526,size=28)] [Tensor(uid=1527,size=28)]\n",
      "[<operator-1518, linear_qkv>] [Tensor(uid=1527,size=28)] [Tensor(uid=1528,size=42)]\n",
      "[<operator-2973, linear_qkv_branch_offload>] None None\n",
      "[<operator-1519, matmul_qk>] [Tensor(uid=1528,size=42)] [Tensor(uid=1529,size=128)]\n",
      "[<operator-1520, softmax_forward>] [Tensor(uid=1529,size=128)] [Tensor(uid=1530,size=128)]\n",
      "[<operator-1521, dropout_forward>] [Tensor(uid=1530,size=128)] [Tensor(uid=1531,size=128), Tensor(uid=1532,size=64)]\n",
      "[<operator-2979, dropout_forward_branch_offload>] None None\n",
      "[<operator-1522, matmul_v>] [Tensor(uid=1531,size=128), Tensor(uid=1528,size=42)] [Tensor(uid=1533,size=14)]\n",
      "[<operator-2985, matmul_v_branch_offload>] None None\n",
      "[<operator-1523, linear_forward>] [Tensor(uid=1533,size=14)] [Tensor(uid=1534,size=28)]\n",
      "[<operator-2991, linear_forward_branch_offload>] None None\n",
      "[<operator-1524, allreduce_forward>] [Tensor(uid=1534,size=28)] []\n",
      "[<operator-1525, output_dropout>] [Tensor(uid=1534,size=28)] [Tensor(uid=1535,size=28), Tensor(uid=1536,size=14)]\n",
      "[<operator-1526, add_forward>] [Tensor(uid=1526,size=28), Tensor(uid=1535,size=28)] [Tensor(uid=1537,size=28)]\n",
      "[<operator-2997, add_forward_branch_offload>] None None\n",
      "[<operator-1527, layernorm_forward>] [Tensor(uid=1537,size=28)] [Tensor(uid=1538,size=28)]\n",
      "[<operator-1528, linear_1_forward>] [Tensor(uid=1538,size=28)] [Tensor(uid=1539,size=56)]\n",
      "[<operator-3003, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1529, gelu_forward>] [Tensor(uid=1539,size=56)] [Tensor(uid=1540,size=56)]\n",
      "[<operator-3009, gelu_forward_branch_offload>] None None\n",
      "[<operator-1530, linear_2_forward>] [Tensor(uid=1540,size=56)] [Tensor(uid=1541,size=28)]\n",
      "[<operator-3015, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1531, allreduce_forward>] [Tensor(uid=1541,size=28)] []\n",
      "[<operator-1532, dropout_forward>] [Tensor(uid=1541,size=28)] [Tensor(uid=1542,size=28), Tensor(uid=1543,size=14)]\n",
      "[<operator-1533, add_forward>] [Tensor(uid=1537,size=28), Tensor(uid=1542,size=28)] [Tensor(uid=1544,size=28)]\n",
      "[<operator-3021, add_forward_branch_offload>] None None\n",
      "[<operator-1534, layernorm_forward>] [Tensor(uid=1544,size=28)] [Tensor(uid=1545,size=28)]\n",
      "[<operator-1535, linear_qkv>] [Tensor(uid=1545,size=28)] [Tensor(uid=1546,size=42)]\n",
      "[<operator-3027, linear_qkv_branch_offload>] None None\n",
      "[<operator-1536, matmul_qk>] [Tensor(uid=1546,size=42)] [Tensor(uid=1547,size=128)]\n",
      "[<operator-1537, softmax_forward>] [Tensor(uid=1547,size=128)] [Tensor(uid=1548,size=128)]\n",
      "[<operator-1538, dropout_forward>] [Tensor(uid=1548,size=128)] [Tensor(uid=1549,size=128), Tensor(uid=1550,size=64)]\n",
      "[<operator-3033, dropout_forward_branch_offload>] None None\n",
      "[<operator-1539, matmul_v>] [Tensor(uid=1549,size=128), Tensor(uid=1546,size=42)] [Tensor(uid=1551,size=14)]\n",
      "[<operator-3039, matmul_v_branch_offload>] None None\n",
      "[<operator-1540, linear_forward>] [Tensor(uid=1551,size=14)] [Tensor(uid=1552,size=28)]\n",
      "[<operator-3045, linear_forward_branch_offload>] None None\n",
      "[<operator-1541, allreduce_forward>] [Tensor(uid=1552,size=28)] []\n",
      "[<operator-1542, output_dropout>] [Tensor(uid=1552,size=28)] [Tensor(uid=1553,size=28), Tensor(uid=1554,size=14)]\n",
      "[<operator-1543, add_forward>] [Tensor(uid=1544,size=28), Tensor(uid=1553,size=28)] [Tensor(uid=1555,size=28)]\n",
      "[<operator-3051, add_forward_branch_offload>] None None\n",
      "[<operator-1544, layernorm_forward>] [Tensor(uid=1555,size=28)] [Tensor(uid=1556,size=28)]\n",
      "[<operator-1545, linear_1_forward>] [Tensor(uid=1556,size=28)] [Tensor(uid=1557,size=56)]\n",
      "[<operator-3057, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1546, gelu_forward>] [Tensor(uid=1557,size=56)] [Tensor(uid=1558,size=56)]\n",
      "[<operator-3063, gelu_forward_branch_offload>] None None\n",
      "[<operator-1547, linear_2_forward>] [Tensor(uid=1558,size=56)] [Tensor(uid=1559,size=28)]\n",
      "[<operator-3069, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1548, allreduce_forward>] [Tensor(uid=1559,size=28)] []\n",
      "[<operator-1549, dropout_forward>] [Tensor(uid=1559,size=28)] [Tensor(uid=1560,size=28), Tensor(uid=1561,size=14)]\n",
      "[<operator-1550, add_forward>] [Tensor(uid=1555,size=28), Tensor(uid=1560,size=28)] [Tensor(uid=1562,size=28)]\n",
      "[<operator-3075, add_forward_branch_offload>] None None\n",
      "[<operator-1551, layernorm_forward>] [Tensor(uid=1562,size=28)] [Tensor(uid=1563,size=28)]\n",
      "[<operator-1552, linear_qkv>] [Tensor(uid=1563,size=28)] [Tensor(uid=1564,size=42)]\n",
      "[<operator-3081, linear_qkv_branch_offload>] None None\n",
      "[<operator-1553, matmul_qk>] [Tensor(uid=1564,size=42)] [Tensor(uid=1565,size=128)]\n",
      "[<operator-1554, softmax_forward>] [Tensor(uid=1565,size=128)] [Tensor(uid=1566,size=128)]\n",
      "[<operator-1555, dropout_forward>] [Tensor(uid=1566,size=128)] [Tensor(uid=1567,size=128), Tensor(uid=1568,size=64)]\n",
      "[<operator-3087, dropout_forward_branch_offload>] None None\n",
      "[<operator-1556, matmul_v>] [Tensor(uid=1567,size=128), Tensor(uid=1564,size=42)] [Tensor(uid=1569,size=14)]\n",
      "[<operator-3093, matmul_v_branch_offload>] None None\n",
      "[<operator-1557, linear_forward>] [Tensor(uid=1569,size=14)] [Tensor(uid=1570,size=28)]\n",
      "[<operator-3099, linear_forward_branch_offload>] None None\n",
      "[<operator-1558, allreduce_forward>] [Tensor(uid=1570,size=28)] []\n",
      "[<operator-1559, output_dropout>] [Tensor(uid=1570,size=28)] [Tensor(uid=1571,size=28), Tensor(uid=1572,size=14)]\n",
      "[<operator-1560, add_forward>] [Tensor(uid=1562,size=28), Tensor(uid=1571,size=28)] [Tensor(uid=1573,size=28)]\n",
      "[<operator-3105, add_forward_branch_offload>] None None\n",
      "[<operator-1561, layernorm_forward>] [Tensor(uid=1573,size=28)] [Tensor(uid=1574,size=28)]\n",
      "[<operator-1562, linear_1_forward>] [Tensor(uid=1574,size=28)] [Tensor(uid=1575,size=56)]\n",
      "[<operator-3111, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1563, gelu_forward>] [Tensor(uid=1575,size=56)] [Tensor(uid=1576,size=56)]\n",
      "[<operator-3117, gelu_forward_branch_offload>] None None\n",
      "[<operator-1564, linear_2_forward>] [Tensor(uid=1576,size=56)] [Tensor(uid=1577,size=28)]\n",
      "[<operator-3123, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1565, allreduce_forward>] [Tensor(uid=1577,size=28)] []\n",
      "[<operator-1566, dropout_forward>] [Tensor(uid=1577,size=28)] [Tensor(uid=1578,size=28), Tensor(uid=1579,size=14)]\n",
      "[<operator-1567, add_forward>] [Tensor(uid=1573,size=28), Tensor(uid=1578,size=28)] [Tensor(uid=1580,size=28)]\n",
      "[<operator-3129, add_forward_branch_offload>] None None\n",
      "[<operator-1568, layernorm_forward>] [Tensor(uid=1580,size=28)] [Tensor(uid=1581,size=28)]\n",
      "[<operator-1569, linear_qkv>] [Tensor(uid=1581,size=28)] [Tensor(uid=1582,size=42)]\n",
      "[<operator-3135, linear_qkv_branch_offload>] None None\n",
      "[<operator-1570, matmul_qk>] [Tensor(uid=1582,size=42)] [Tensor(uid=1583,size=128)]\n",
      "[<operator-1571, softmax_forward>] [Tensor(uid=1583,size=128)] [Tensor(uid=1584,size=128)]\n",
      "[<operator-1572, dropout_forward>] [Tensor(uid=1584,size=128)] [Tensor(uid=1585,size=128), Tensor(uid=1586,size=64)]\n",
      "[<operator-3141, dropout_forward_branch_offload>] None None\n",
      "[<operator-1573, matmul_v>] [Tensor(uid=1585,size=128), Tensor(uid=1582,size=42)] [Tensor(uid=1587,size=14)]\n",
      "[<operator-3147, matmul_v_branch_offload>] None None\n",
      "[<operator-1574, linear_forward>] [Tensor(uid=1587,size=14)] [Tensor(uid=1588,size=28)]\n",
      "[<operator-3153, linear_forward_branch_offload>] None None\n",
      "[<operator-1575, allreduce_forward>] [Tensor(uid=1588,size=28)] []\n",
      "[<operator-1576, output_dropout>] [Tensor(uid=1588,size=28)] [Tensor(uid=1589,size=28), Tensor(uid=1590,size=14)]\n",
      "[<operator-1577, add_forward>] [Tensor(uid=1580,size=28), Tensor(uid=1589,size=28)] [Tensor(uid=1591,size=28)]\n",
      "[<operator-3159, add_forward_branch_offload>] None None\n",
      "[<operator-1578, layernorm_forward>] [Tensor(uid=1591,size=28)] [Tensor(uid=1592,size=28)]\n",
      "[<operator-1579, linear_1_forward>] [Tensor(uid=1592,size=28)] [Tensor(uid=1593,size=56)]\n",
      "[<operator-3165, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1580, gelu_forward>] [Tensor(uid=1593,size=56)] [Tensor(uid=1594,size=56)]\n",
      "[<operator-3171, gelu_forward_branch_offload>] None None\n",
      "[<operator-1581, linear_2_forward>] [Tensor(uid=1594,size=56)] [Tensor(uid=1595,size=28)]\n",
      "[<operator-3177, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1582, allreduce_forward>] [Tensor(uid=1595,size=28)] []\n",
      "[<operator-1583, dropout_forward>] [Tensor(uid=1595,size=28)] [Tensor(uid=1596,size=28), Tensor(uid=1597,size=14)]\n",
      "[<operator-1584, add_forward>] [Tensor(uid=1591,size=28), Tensor(uid=1596,size=28)] [Tensor(uid=1598,size=28)]\n",
      "[<operator-3183, add_forward_branch_offload>] None None\n",
      "[<operator-1585, layernorm_forward>] [Tensor(uid=1598,size=28)] [Tensor(uid=1599,size=28)]\n",
      "[<operator-1586, linear_qkv>] [Tensor(uid=1599,size=28)] [Tensor(uid=1600,size=42)]\n",
      "[<operator-3189, linear_qkv_branch_offload>] None None\n",
      "[<operator-1587, matmul_qk>] [Tensor(uid=1600,size=42)] [Tensor(uid=1601,size=128)]\n",
      "[<operator-1588, softmax_forward>] [Tensor(uid=1601,size=128)] [Tensor(uid=1602,size=128)]\n",
      "[<operator-1589, dropout_forward>] [Tensor(uid=1602,size=128)] [Tensor(uid=1603,size=128), Tensor(uid=1604,size=64)]\n",
      "[<operator-3195, dropout_forward_branch_offload>] None None\n",
      "[<operator-1590, matmul_v>] [Tensor(uid=1603,size=128), Tensor(uid=1600,size=42)] [Tensor(uid=1605,size=14)]\n",
      "[<operator-3201, matmul_v_branch_offload>] None None\n",
      "[<operator-1591, linear_forward>] [Tensor(uid=1605,size=14)] [Tensor(uid=1606,size=28)]\n",
      "[<operator-3207, linear_forward_branch_offload>] None None\n",
      "[<operator-1592, allreduce_forward>] [Tensor(uid=1606,size=28)] []\n",
      "[<operator-1593, output_dropout>] [Tensor(uid=1606,size=28)] [Tensor(uid=1607,size=28), Tensor(uid=1608,size=14)]\n",
      "[<operator-1594, add_forward>] [Tensor(uid=1598,size=28), Tensor(uid=1607,size=28)] [Tensor(uid=1609,size=28)]\n",
      "[<operator-3213, add_forward_branch_offload>] None None\n",
      "[<operator-1595, layernorm_forward>] [Tensor(uid=1609,size=28)] [Tensor(uid=1610,size=28)]\n",
      "[<operator-1596, linear_1_forward>] [Tensor(uid=1610,size=28)] [Tensor(uid=1611,size=56)]\n",
      "[<operator-3219, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1597, gelu_forward>] [Tensor(uid=1611,size=56)] [Tensor(uid=1612,size=56)]\n",
      "[<operator-3225, gelu_forward_branch_offload>] None None\n",
      "[<operator-1598, linear_2_forward>] [Tensor(uid=1612,size=56)] [Tensor(uid=1613,size=28)]\n",
      "[<operator-3231, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1599, allreduce_forward>] [Tensor(uid=1613,size=28)] []\n",
      "[<operator-1600, dropout_forward>] [Tensor(uid=1613,size=28)] [Tensor(uid=1614,size=28), Tensor(uid=1615,size=14)]\n",
      "[<operator-1601, add_forward>] [Tensor(uid=1609,size=28), Tensor(uid=1614,size=28)] [Tensor(uid=1616,size=28)]\n",
      "[<operator-3237, add_forward_branch_offload>] None None\n",
      "[<operator-1602, layernorm_forward>] [Tensor(uid=1616,size=28)] [Tensor(uid=1617,size=28)]\n",
      "[<operator-1603, linear_qkv>] [Tensor(uid=1617,size=28)] [Tensor(uid=1618,size=42)]\n",
      "[<operator-3243, linear_qkv_branch_offload>] None None\n",
      "[<operator-1604, matmul_qk>] [Tensor(uid=1618,size=42)] [Tensor(uid=1619,size=128)]\n",
      "[<operator-1605, softmax_forward>] [Tensor(uid=1619,size=128)] [Tensor(uid=1620,size=128)]\n",
      "[<operator-1606, dropout_forward>] [Tensor(uid=1620,size=128)] [Tensor(uid=1621,size=128), Tensor(uid=1622,size=64)]\n",
      "[<operator-3249, dropout_forward_branch_offload>] None None\n",
      "[<operator-1607, matmul_v>] [Tensor(uid=1621,size=128), Tensor(uid=1618,size=42)] [Tensor(uid=1623,size=14)]\n",
      "[<operator-3255, matmul_v_branch_offload>] None None\n",
      "[<operator-1608, linear_forward>] [Tensor(uid=1623,size=14)] [Tensor(uid=1624,size=28)]\n",
      "[<operator-3261, linear_forward_branch_offload>] None None\n",
      "[<operator-1609, allreduce_forward>] [Tensor(uid=1624,size=28)] []\n",
      "[<operator-1610, output_dropout>] [Tensor(uid=1624,size=28)] [Tensor(uid=1625,size=28), Tensor(uid=1626,size=14)]\n",
      "[<operator-1611, add_forward>] [Tensor(uid=1616,size=28), Tensor(uid=1625,size=28)] [Tensor(uid=1627,size=28)]\n",
      "[<operator-3267, add_forward_branch_offload>] None None\n",
      "[<operator-1612, layernorm_forward>] [Tensor(uid=1627,size=28)] [Tensor(uid=1628,size=28)]\n",
      "[<operator-1613, linear_1_forward>] [Tensor(uid=1628,size=28)] [Tensor(uid=1629,size=56)]\n",
      "[<operator-3273, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1614, gelu_forward>] [Tensor(uid=1629,size=56)] [Tensor(uid=1630,size=56)]\n",
      "[<operator-3279, gelu_forward_branch_offload>] None None\n",
      "[<operator-1615, linear_2_forward>] [Tensor(uid=1630,size=56)] [Tensor(uid=1631,size=28)]\n",
      "[<operator-3285, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1616, allreduce_forward>] [Tensor(uid=1631,size=28)] []\n",
      "[<operator-1617, dropout_forward>] [Tensor(uid=1631,size=28)] [Tensor(uid=1632,size=28), Tensor(uid=1633,size=14)]\n",
      "[<operator-1618, add_forward>] [Tensor(uid=1627,size=28), Tensor(uid=1632,size=28)] [Tensor(uid=1634,size=28)]\n",
      "[<operator-3291, add_forward_branch_offload>] None None\n",
      "[<operator-1619, layernorm_forward>] [Tensor(uid=1634,size=28)] [Tensor(uid=1635,size=28)]\n",
      "[<operator-1620, linear_qkv>] [Tensor(uid=1635,size=28)] [Tensor(uid=1636,size=42)]\n",
      "[<operator-3297, linear_qkv_branch_offload>] None None\n",
      "[<operator-1621, matmul_qk>] [Tensor(uid=1636,size=42)] [Tensor(uid=1637,size=128)]\n",
      "[<operator-1622, softmax_forward>] [Tensor(uid=1637,size=128)] [Tensor(uid=1638,size=128)]\n",
      "[<operator-1623, dropout_forward>] [Tensor(uid=1638,size=128)] [Tensor(uid=1639,size=128), Tensor(uid=1640,size=64)]\n",
      "[<operator-3303, dropout_forward_branch_offload>] None None\n",
      "[<operator-1624, matmul_v>] [Tensor(uid=1639,size=128), Tensor(uid=1636,size=42)] [Tensor(uid=1641,size=14)]\n",
      "[<operator-3309, matmul_v_branch_offload>] None None\n",
      "[<operator-1625, linear_forward>] [Tensor(uid=1641,size=14)] [Tensor(uid=1642,size=28)]\n",
      "[<operator-3315, linear_forward_branch_offload>] None None\n",
      "[<operator-1626, allreduce_forward>] [Tensor(uid=1642,size=28)] []\n",
      "[<operator-1627, output_dropout>] [Tensor(uid=1642,size=28)] [Tensor(uid=1643,size=28), Tensor(uid=1644,size=14)]\n",
      "[<operator-1628, add_forward>] [Tensor(uid=1634,size=28), Tensor(uid=1643,size=28)] [Tensor(uid=1645,size=28)]\n",
      "[<operator-3321, add_forward_branch_offload>] None None\n",
      "[<operator-1629, layernorm_forward>] [Tensor(uid=1645,size=28)] [Tensor(uid=1646,size=28)]\n",
      "[<operator-1630, linear_1_forward>] [Tensor(uid=1646,size=28)] [Tensor(uid=1647,size=56)]\n",
      "[<operator-3327, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1631, gelu_forward>] [Tensor(uid=1647,size=56)] [Tensor(uid=1648,size=56)]\n",
      "[<operator-3333, gelu_forward_branch_offload>] None None\n",
      "[<operator-1632, linear_2_forward>] [Tensor(uid=1648,size=56)] [Tensor(uid=1649,size=28)]\n",
      "[<operator-3339, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1633, allreduce_forward>] [Tensor(uid=1649,size=28)] []\n",
      "[<operator-1634, dropout_forward>] [Tensor(uid=1649,size=28)] [Tensor(uid=1650,size=28), Tensor(uid=1651,size=14)]\n",
      "[<operator-1635, add_forward>] [Tensor(uid=1645,size=28), Tensor(uid=1650,size=28)] [Tensor(uid=1652,size=28)]\n",
      "[<operator-3345, add_forward_branch_offload>] None None\n",
      "[<operator-1636, layernorm_forward>] [Tensor(uid=1652,size=28)] [Tensor(uid=1653,size=28)]\n",
      "[<operator-1637, linear_qkv>] [Tensor(uid=1653,size=28)] [Tensor(uid=1654,size=42)]\n",
      "[<operator-3351, linear_qkv_branch_offload>] None None\n",
      "[<operator-1638, matmul_qk>] [Tensor(uid=1654,size=42)] [Tensor(uid=1655,size=128)]\n",
      "[<operator-1639, softmax_forward>] [Tensor(uid=1655,size=128)] [Tensor(uid=1656,size=128)]\n",
      "[<operator-1640, dropout_forward>] [Tensor(uid=1656,size=128)] [Tensor(uid=1657,size=128), Tensor(uid=1658,size=64)]\n",
      "[<operator-3357, dropout_forward_branch_offload>] None None\n",
      "[<operator-1641, matmul_v>] [Tensor(uid=1657,size=128), Tensor(uid=1654,size=42)] [Tensor(uid=1659,size=14)]\n",
      "[<operator-3363, matmul_v_branch_offload>] None None\n",
      "[<operator-1642, linear_forward>] [Tensor(uid=1659,size=14)] [Tensor(uid=1660,size=28)]\n",
      "[<operator-3369, linear_forward_branch_offload>] None None\n",
      "[<operator-1643, allreduce_forward>] [Tensor(uid=1660,size=28)] []\n",
      "[<operator-1644, output_dropout>] [Tensor(uid=1660,size=28)] [Tensor(uid=1661,size=28), Tensor(uid=1662,size=14)]\n",
      "[<operator-1645, add_forward>] [Tensor(uid=1652,size=28), Tensor(uid=1661,size=28)] [Tensor(uid=1663,size=28)]\n",
      "[<operator-3375, add_forward_branch_offload>] None None\n",
      "[<operator-1646, layernorm_forward>] [Tensor(uid=1663,size=28)] [Tensor(uid=1664,size=28)]\n",
      "[<operator-1647, linear_1_forward>] [Tensor(uid=1664,size=28)] [Tensor(uid=1665,size=56)]\n",
      "[<operator-3381, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1648, gelu_forward>] [Tensor(uid=1665,size=56)] [Tensor(uid=1666,size=56)]\n",
      "[<operator-3387, gelu_forward_branch_offload>] None None\n",
      "[<operator-1649, linear_2_forward>] [Tensor(uid=1666,size=56)] [Tensor(uid=1667,size=28)]\n",
      "[<operator-3393, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1650, allreduce_forward>] [Tensor(uid=1667,size=28)] []\n",
      "[<operator-1651, dropout_forward>] [Tensor(uid=1667,size=28)] [Tensor(uid=1668,size=28), Tensor(uid=1669,size=14)]\n",
      "[<operator-1652, add_forward>] [Tensor(uid=1663,size=28), Tensor(uid=1668,size=28)] [Tensor(uid=1670,size=28)]\n",
      "[<operator-3399, add_forward_branch_offload>] None None\n",
      "[<operator-1653, layernorm_forward>] [Tensor(uid=1670,size=28)] [Tensor(uid=1671,size=28)]\n",
      "[<operator-1654, linear_qkv>] [Tensor(uid=1671,size=28)] [Tensor(uid=1672,size=42)]\n",
      "[<operator-3405, linear_qkv_branch_offload>] None None\n",
      "[<operator-1655, matmul_qk>] [Tensor(uid=1672,size=42)] [Tensor(uid=1673,size=128)]\n",
      "[<operator-1656, softmax_forward>] [Tensor(uid=1673,size=128)] [Tensor(uid=1674,size=128)]\n",
      "[<operator-1657, dropout_forward>] [Tensor(uid=1674,size=128)] [Tensor(uid=1675,size=128), Tensor(uid=1676,size=64)]\n",
      "[<operator-3411, dropout_forward_branch_offload>] None None\n",
      "[<operator-1658, matmul_v>] [Tensor(uid=1675,size=128), Tensor(uid=1672,size=42)] [Tensor(uid=1677,size=14)]\n",
      "[<operator-3417, matmul_v_branch_offload>] None None\n",
      "[<operator-1659, linear_forward>] [Tensor(uid=1677,size=14)] [Tensor(uid=1678,size=28)]\n",
      "[<operator-3423, linear_forward_branch_offload>] None None\n",
      "[<operator-1660, allreduce_forward>] [Tensor(uid=1678,size=28)] []\n",
      "[<operator-1661, output_dropout>] [Tensor(uid=1678,size=28)] [Tensor(uid=1679,size=28), Tensor(uid=1680,size=14)]\n",
      "[<operator-1662, add_forward>] [Tensor(uid=1670,size=28), Tensor(uid=1679,size=28)] [Tensor(uid=1681,size=28)]\n",
      "[<operator-3429, add_forward_branch_offload>] None None\n",
      "[<operator-1663, layernorm_forward>] [Tensor(uid=1681,size=28)] [Tensor(uid=1682,size=28)]\n",
      "[<operator-1664, linear_1_forward>] [Tensor(uid=1682,size=28)] [Tensor(uid=1683,size=56)]\n",
      "[<operator-3435, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1665, gelu_forward>] [Tensor(uid=1683,size=56)] [Tensor(uid=1684,size=56)]\n",
      "[<operator-3441, gelu_forward_branch_offload>] None None\n",
      "[<operator-1666, linear_2_forward>] [Tensor(uid=1684,size=56)] [Tensor(uid=1685,size=28)]\n",
      "[<operator-3447, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1667, allreduce_forward>] [Tensor(uid=1685,size=28)] []\n",
      "[<operator-1668, dropout_forward>] [Tensor(uid=1685,size=28)] [Tensor(uid=1686,size=28), Tensor(uid=1687,size=14)]\n",
      "[<operator-1669, add_forward>] [Tensor(uid=1681,size=28), Tensor(uid=1686,size=28)] [Tensor(uid=1688,size=28)]\n",
      "[<operator-3453, add_forward_branch_offload>] None None\n",
      "[<operator-1670, layernorm_forward>] [Tensor(uid=1688,size=28)] [Tensor(uid=1689,size=28)]\n",
      "[<operator-1671, linear_qkv>] [Tensor(uid=1689,size=28)] [Tensor(uid=1690,size=42)]\n",
      "[<operator-3459, linear_qkv_branch_offload>] None None\n",
      "[<operator-1672, matmul_qk>] [Tensor(uid=1690,size=42)] [Tensor(uid=1691,size=128)]\n",
      "[<operator-1673, softmax_forward>] [Tensor(uid=1691,size=128)] [Tensor(uid=1692,size=128)]\n",
      "[<operator-1674, dropout_forward>] [Tensor(uid=1692,size=128)] [Tensor(uid=1693,size=128), Tensor(uid=1694,size=64)]\n",
      "[<operator-3465, dropout_forward_branch_offload>] None None\n",
      "[<operator-1675, matmul_v>] [Tensor(uid=1693,size=128), Tensor(uid=1690,size=42)] [Tensor(uid=1695,size=14)]\n",
      "[<operator-3471, matmul_v_branch_offload>] None None\n",
      "[<operator-1676, linear_forward>] [Tensor(uid=1695,size=14)] [Tensor(uid=1696,size=28)]\n",
      "[<operator-3477, linear_forward_branch_offload>] None None\n",
      "[<operator-1677, allreduce_forward>] [Tensor(uid=1696,size=28)] []\n",
      "[<operator-1678, output_dropout>] [Tensor(uid=1696,size=28)] [Tensor(uid=1697,size=28), Tensor(uid=1698,size=14)]\n",
      "[<operator-1679, add_forward>] [Tensor(uid=1688,size=28), Tensor(uid=1697,size=28)] [Tensor(uid=1699,size=28)]\n",
      "[<operator-3483, add_forward_branch_offload>] None None\n",
      "[<operator-1680, layernorm_forward>] [Tensor(uid=1699,size=28)] [Tensor(uid=1700,size=28)]\n",
      "[<operator-1681, linear_1_forward>] [Tensor(uid=1700,size=28)] [Tensor(uid=1701,size=56)]\n",
      "[<operator-3489, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1682, gelu_forward>] [Tensor(uid=1701,size=56)] [Tensor(uid=1702,size=56)]\n",
      "[<operator-3495, gelu_forward_branch_offload>] None None\n",
      "[<operator-1683, linear_2_forward>] [Tensor(uid=1702,size=56)] [Tensor(uid=1703,size=28)]\n",
      "[<operator-3501, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1684, allreduce_forward>] [Tensor(uid=1703,size=28)] []\n",
      "[<operator-1685, dropout_forward>] [Tensor(uid=1703,size=28)] [Tensor(uid=1704,size=28), Tensor(uid=1705,size=14)]\n",
      "[<operator-1686, add_forward>] [Tensor(uid=1699,size=28), Tensor(uid=1704,size=28)] [Tensor(uid=1706,size=28)]\n",
      "[<operator-3507, add_forward_branch_offload>] None None\n",
      "[<operator-1687, layernorm_forward>] [Tensor(uid=1706,size=28)] [Tensor(uid=1707,size=28)]\n",
      "[<operator-1688, linear_qkv>] [Tensor(uid=1707,size=28)] [Tensor(uid=1708,size=42)]\n",
      "[<operator-3513, linear_qkv_branch_offload>] None None\n",
      "[<operator-1689, matmul_qk>] [Tensor(uid=1708,size=42)] [Tensor(uid=1709,size=128)]\n",
      "[<operator-1690, softmax_forward>] [Tensor(uid=1709,size=128)] [Tensor(uid=1710,size=128)]\n",
      "[<operator-1691, dropout_forward>] [Tensor(uid=1710,size=128)] [Tensor(uid=1711,size=128), Tensor(uid=1712,size=64)]\n",
      "[<operator-3519, dropout_forward_branch_offload>] None None\n",
      "[<operator-1692, matmul_v>] [Tensor(uid=1711,size=128), Tensor(uid=1708,size=42)] [Tensor(uid=1713,size=14)]\n",
      "[<operator-3525, matmul_v_branch_offload>] None None\n",
      "[<operator-1693, linear_forward>] [Tensor(uid=1713,size=14)] [Tensor(uid=1714,size=28)]\n",
      "[<operator-3531, linear_forward_branch_offload>] None None\n",
      "[<operator-1694, allreduce_forward>] [Tensor(uid=1714,size=28)] []\n",
      "[<operator-1695, output_dropout>] [Tensor(uid=1714,size=28)] [Tensor(uid=1715,size=28), Tensor(uid=1716,size=14)]\n",
      "[<operator-1696, add_forward>] [Tensor(uid=1706,size=28), Tensor(uid=1715,size=28)] [Tensor(uid=1717,size=28)]\n",
      "[<operator-3537, add_forward_branch_offload>] None None\n",
      "[<operator-1697, layernorm_forward>] [Tensor(uid=1717,size=28)] [Tensor(uid=1718,size=28)]\n",
      "[<operator-1698, linear_1_forward>] [Tensor(uid=1718,size=28)] [Tensor(uid=1719,size=56)]\n",
      "[<operator-3543, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1699, gelu_forward>] [Tensor(uid=1719,size=56)] [Tensor(uid=1720,size=56)]\n",
      "[<operator-3549, gelu_forward_branch_offload>] None None\n",
      "[<operator-1700, linear_2_forward>] [Tensor(uid=1720,size=56)] [Tensor(uid=1721,size=28)]\n",
      "[<operator-3555, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1701, allreduce_forward>] [Tensor(uid=1721,size=28)] []\n",
      "[<operator-1702, dropout_forward>] [Tensor(uid=1721,size=28)] [Tensor(uid=1722,size=28), Tensor(uid=1723,size=14)]\n",
      "[<operator-1703, add_forward>] [Tensor(uid=1717,size=28), Tensor(uid=1722,size=28)] [Tensor(uid=1724,size=28)]\n",
      "[<operator-3561, add_forward_branch_offload>] None None\n",
      "[<operator-1704, layernorm_forward>] [Tensor(uid=1724,size=28)] [Tensor(uid=1725,size=28)]\n",
      "[<operator-1705, linear_qkv>] [Tensor(uid=1725,size=28)] [Tensor(uid=1726,size=42)]\n",
      "[<operator-3567, linear_qkv_branch_offload>] None None\n",
      "[<operator-1706, matmul_qk>] [Tensor(uid=1726,size=42)] [Tensor(uid=1727,size=128)]\n",
      "[<operator-1707, softmax_forward>] [Tensor(uid=1727,size=128)] [Tensor(uid=1728,size=128)]\n",
      "[<operator-1708, dropout_forward>] [Tensor(uid=1728,size=128)] [Tensor(uid=1729,size=128), Tensor(uid=1730,size=64)]\n",
      "[<operator-3573, dropout_forward_branch_offload>] None None\n",
      "[<operator-1709, matmul_v>] [Tensor(uid=1729,size=128), Tensor(uid=1726,size=42)] [Tensor(uid=1731,size=14)]\n",
      "[<operator-3579, matmul_v_branch_offload>] None None\n",
      "[<operator-1710, linear_forward>] [Tensor(uid=1731,size=14)] [Tensor(uid=1732,size=28)]\n",
      "[<operator-3585, linear_forward_branch_offload>] None None\n",
      "[<operator-1711, allreduce_forward>] [Tensor(uid=1732,size=28)] []\n",
      "[<operator-1712, output_dropout>] [Tensor(uid=1732,size=28)] [Tensor(uid=1733,size=28), Tensor(uid=1734,size=14)]\n",
      "[<operator-1713, add_forward>] [Tensor(uid=1724,size=28), Tensor(uid=1733,size=28)] [Tensor(uid=1735,size=28)]\n",
      "[<operator-3591, add_forward_branch_offload>] None None\n",
      "[<operator-1714, layernorm_forward>] [Tensor(uid=1735,size=28)] [Tensor(uid=1736,size=28)]\n",
      "[<operator-1715, linear_1_forward>] [Tensor(uid=1736,size=28)] [Tensor(uid=1737,size=56)]\n",
      "[<operator-3597, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1716, gelu_forward>] [Tensor(uid=1737,size=56)] [Tensor(uid=1738,size=56)]\n",
      "[<operator-3603, gelu_forward_branch_offload>] None None\n",
      "[<operator-1717, linear_2_forward>] [Tensor(uid=1738,size=56)] [Tensor(uid=1739,size=28)]\n",
      "[<operator-3609, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1718, allreduce_forward>] [Tensor(uid=1739,size=28)] []\n",
      "[<operator-1719, dropout_forward>] [Tensor(uid=1739,size=28)] [Tensor(uid=1740,size=28), Tensor(uid=1741,size=14)]\n",
      "[<operator-1720, add_forward>] [Tensor(uid=1735,size=28), Tensor(uid=1740,size=28)] [Tensor(uid=1742,size=28)]\n",
      "[<operator-3615, add_forward_branch_offload>] None None\n",
      "[<operator-1721, layernorm_forward>] [Tensor(uid=1742,size=28)] [Tensor(uid=1743,size=28)]\n",
      "[<operator-1722, linear_qkv>] [Tensor(uid=1743,size=28)] [Tensor(uid=1744,size=42)]\n",
      "[<operator-1723, matmul_qk>] [Tensor(uid=1744,size=42)] [Tensor(uid=1745,size=128)]\n",
      "[<operator-1724, softmax_forward>] [Tensor(uid=1745,size=128)] [Tensor(uid=1746,size=128)]\n",
      "[<operator-1725, dropout_forward>] [Tensor(uid=1746,size=128)] [Tensor(uid=1747,size=128), Tensor(uid=1748,size=64)]\n",
      "[<operator-1726, matmul_v>] [Tensor(uid=1747,size=128), Tensor(uid=1744,size=42)] [Tensor(uid=1749,size=14)]\n",
      "[<operator-1727, linear_forward>] [Tensor(uid=1749,size=14)] [Tensor(uid=1750,size=28)]\n",
      "[<operator-1728, allreduce_forward>] [Tensor(uid=1750,size=28)] []\n",
      "[<operator-1729, output_dropout>] [Tensor(uid=1750,size=28)] [Tensor(uid=1751,size=28), Tensor(uid=1752,size=14)]\n",
      "[<operator-1730, add_forward>] [Tensor(uid=1742,size=28), Tensor(uid=1751,size=28)] [Tensor(uid=1753,size=28)]\n",
      "[<operator-1731, layernorm_forward>] [Tensor(uid=1753,size=28)] [Tensor(uid=1754,size=28)]\n",
      "[<operator-1732, linear_1_forward>] [Tensor(uid=1754,size=28)] [Tensor(uid=1755,size=56)]\n",
      "[<operator-1733, gelu_forward>] [Tensor(uid=1755,size=56)] [Tensor(uid=1756,size=56)]\n",
      "[<operator-1734, linear_2_forward>] [Tensor(uid=1756,size=56)] [Tensor(uid=1757,size=28)]\n",
      "[<operator-1735, allreduce_forward>] [Tensor(uid=1757,size=28)] []\n",
      "[<operator-1736, dropout_forward>] [Tensor(uid=1757,size=28)] [Tensor(uid=1758,size=28), Tensor(uid=1759,size=14)]\n",
      "[<operator-1737, add_forward>] [Tensor(uid=1753,size=28), Tensor(uid=1758,size=28)] [Tensor(uid=1760,size=28)]\n",
      "[<operator-1738, layernorm_forward>] [Tensor(uid=1760,size=28)] [Tensor(uid=1761,size=28)]\n",
      "[<operator-1739, linear_qkv>] [Tensor(uid=1761,size=28)] [Tensor(uid=1762,size=42)]\n",
      "[<operator-1740, matmul_qk>] [Tensor(uid=1762,size=42)] [Tensor(uid=1763,size=128)]\n",
      "[<operator-1741, softmax_forward>] [Tensor(uid=1763,size=128)] [Tensor(uid=1764,size=128)]\n",
      "[<operator-1742, dropout_forward>] [Tensor(uid=1764,size=128)] [Tensor(uid=1765,size=128), Tensor(uid=1766,size=64)]\n",
      "[<operator-1743, matmul_v>] [Tensor(uid=1765,size=128), Tensor(uid=1762,size=42)] [Tensor(uid=1767,size=14)]\n",
      "[<operator-1744, linear_forward>] [Tensor(uid=1767,size=14)] [Tensor(uid=1768,size=28)]\n",
      "[<operator-1745, allreduce_forward>] [Tensor(uid=1768,size=28)] []\n",
      "[<operator-1746, output_dropout>] [Tensor(uid=1768,size=28)] [Tensor(uid=1769,size=28), Tensor(uid=1770,size=14)]\n",
      "[<operator-1747, add_forward>] [Tensor(uid=1760,size=28), Tensor(uid=1769,size=28)] [Tensor(uid=1771,size=28)]\n",
      "[<operator-1748, layernorm_forward>] [Tensor(uid=1771,size=28)] [Tensor(uid=1772,size=28)]\n",
      "[<operator-1749, linear_1_forward>] [Tensor(uid=1772,size=28)] [Tensor(uid=1773,size=56)]\n",
      "[<operator-1750, gelu_forward>] [Tensor(uid=1773,size=56)] [Tensor(uid=1774,size=56)]\n",
      "[<operator-1751, linear_2_forward>] [Tensor(uid=1774,size=56)] [Tensor(uid=1775,size=28)]\n",
      "[<operator-1752, allreduce_forward>] [Tensor(uid=1775,size=28)] []\n",
      "[<operator-1753, dropout_forward>] [Tensor(uid=1775,size=28)] [Tensor(uid=1776,size=28), Tensor(uid=1777,size=14)]\n",
      "[<operator-1754, add_forward>] [Tensor(uid=1771,size=28), Tensor(uid=1776,size=28)] [Tensor(uid=1778,size=28)]\n",
      "[<operator-1755, layernorm_forward>] [Tensor(uid=1778,size=28)] [Tensor(uid=1779,size=28)]\n",
      "[<operator-1756, linear_qkv>] [Tensor(uid=1779,size=28)] [Tensor(uid=1780,size=42)]\n",
      "[<operator-1757, matmul_qk>] [Tensor(uid=1780,size=42)] [Tensor(uid=1781,size=128)]\n",
      "[<operator-1758, softmax_forward>] [Tensor(uid=1781,size=128)] [Tensor(uid=1782,size=128)]\n",
      "[<operator-1759, dropout_forward>] [Tensor(uid=1782,size=128)] [Tensor(uid=1783,size=128), Tensor(uid=1784,size=64)]\n",
      "[<operator-1760, matmul_v>] [Tensor(uid=1783,size=128), Tensor(uid=1780,size=42)] [Tensor(uid=1785,size=14)]\n",
      "[<operator-1761, linear_forward>] [Tensor(uid=1785,size=14)] [Tensor(uid=1786,size=28)]\n",
      "[<operator-1762, allreduce_forward>] [Tensor(uid=1786,size=28)] []\n",
      "[<operator-1763, output_dropout>] [Tensor(uid=1786,size=28)] [Tensor(uid=1787,size=28), Tensor(uid=1788,size=14)]\n",
      "[<operator-1764, add_forward>] [Tensor(uid=1778,size=28), Tensor(uid=1787,size=28)] [Tensor(uid=1789,size=28)]\n",
      "[<operator-1765, layernorm_forward>] [Tensor(uid=1789,size=28)] [Tensor(uid=1790,size=28)]\n",
      "[<operator-1766, linear_1_forward>] [Tensor(uid=1790,size=28)] [Tensor(uid=1791,size=56)]\n",
      "[<operator-1767, gelu_forward>] [Tensor(uid=1791,size=56)] [Tensor(uid=1792,size=56)]\n",
      "[<operator-1768, linear_2_forward>] [Tensor(uid=1792,size=56)] [Tensor(uid=1793,size=28)]\n",
      "[<operator-1769, allreduce_forward>] [Tensor(uid=1793,size=28)] []\n",
      "[<operator-1770, dropout_forward>] [Tensor(uid=1793,size=28)] [Tensor(uid=1794,size=28), Tensor(uid=1795,size=14)]\n",
      "[<operator-1771, add_forward>] [Tensor(uid=1789,size=28), Tensor(uid=1794,size=28)] [Tensor(uid=1796,size=28)]\n",
      "[<operator-1772, layernorm_forward>] [Tensor(uid=1796,size=28)] [Tensor(uid=1797,size=28)]\n",
      "[<operator-1773, linear_qkv>] [Tensor(uid=1797,size=28)] [Tensor(uid=1798,size=42)]\n",
      "[<operator-1774, matmul_qk>] [Tensor(uid=1798,size=42)] [Tensor(uid=1799,size=128)]\n",
      "[<operator-1775, softmax_forward>] [Tensor(uid=1799,size=128)] [Tensor(uid=1800,size=128)]\n",
      "[<operator-1776, dropout_forward>] [Tensor(uid=1800,size=128)] [Tensor(uid=1801,size=128), Tensor(uid=1802,size=64)]\n",
      "[<operator-1777, matmul_v>] [Tensor(uid=1801,size=128), Tensor(uid=1798,size=42)] [Tensor(uid=1803,size=14)]\n",
      "[<operator-1778, linear_forward>] [Tensor(uid=1803,size=14)] [Tensor(uid=1804,size=28)]\n",
      "[<operator-1779, allreduce_forward>] [Tensor(uid=1804,size=28)] []\n",
      "[<operator-1780, output_dropout>] [Tensor(uid=1804,size=28)] [Tensor(uid=1805,size=28), Tensor(uid=1806,size=14)]\n",
      "[<operator-1781, add_forward>] [Tensor(uid=1796,size=28), Tensor(uid=1805,size=28)] [Tensor(uid=1807,size=28)]\n",
      "[<operator-1782, layernorm_forward>] [Tensor(uid=1807,size=28)] [Tensor(uid=1808,size=28)]\n",
      "[<operator-1783, linear_1_forward>] [Tensor(uid=1808,size=28)] [Tensor(uid=1809,size=56)]\n",
      "[<operator-1784, gelu_forward>] [Tensor(uid=1809,size=56)] [Tensor(uid=1810,size=56)]\n",
      "[<operator-1785, linear_2_forward>] [Tensor(uid=1810,size=56)] [Tensor(uid=1811,size=28)]\n",
      "[<operator-1786, allreduce_forward>] [Tensor(uid=1811,size=28)] []\n",
      "[<operator-1787, dropout_forward>] [Tensor(uid=1811,size=28)] [Tensor(uid=1812,size=28), Tensor(uid=1813,size=14)]\n",
      "[<operator-1788, add_forward>] [Tensor(uid=1807,size=28), Tensor(uid=1812,size=28)] [Tensor(uid=1814,size=28)]\n",
      "[<operator-1789, layernorm_forward>] [Tensor(uid=1814,size=28)] [Tensor(uid=1815,size=28)]\n",
      "[<operator-1790, linear_qkv>] [Tensor(uid=1815,size=28)] [Tensor(uid=1816,size=42)]\n",
      "[<operator-1791, matmul_qk>] [Tensor(uid=1816,size=42)] [Tensor(uid=1817,size=128)]\n",
      "[<operator-1792, softmax_forward>] [Tensor(uid=1817,size=128)] [Tensor(uid=1818,size=128)]\n",
      "[<operator-1793, dropout_forward>] [Tensor(uid=1818,size=128)] [Tensor(uid=1819,size=128), Tensor(uid=1820,size=64)]\n",
      "[<operator-1794, matmul_v>] [Tensor(uid=1819,size=128), Tensor(uid=1816,size=42)] [Tensor(uid=1821,size=14)]\n",
      "[<operator-1795, linear_forward>] [Tensor(uid=1821,size=14)] [Tensor(uid=1822,size=28)]\n",
      "[<operator-1796, allreduce_forward>] [Tensor(uid=1822,size=28)] []\n",
      "[<operator-1797, output_dropout>] [Tensor(uid=1822,size=28)] [Tensor(uid=1823,size=28), Tensor(uid=1824,size=14)]\n",
      "[<operator-1798, add_forward>] [Tensor(uid=1814,size=28), Tensor(uid=1823,size=28)] [Tensor(uid=1825,size=28)]\n",
      "[<operator-1799, layernorm_forward>] [Tensor(uid=1825,size=28)] [Tensor(uid=1826,size=28)]\n",
      "[<operator-1800, linear_1_forward>] [Tensor(uid=1826,size=28)] [Tensor(uid=1827,size=56)]\n",
      "[<operator-1801, gelu_forward>] [Tensor(uid=1827,size=56)] [Tensor(uid=1828,size=56)]\n",
      "[<operator-1802, linear_2_forward>] [Tensor(uid=1828,size=56)] [Tensor(uid=1829,size=28)]\n",
      "[<operator-1803, allreduce_forward>] [Tensor(uid=1829,size=28)] []\n",
      "[<operator-1804, dropout_forward>] [Tensor(uid=1829,size=28)] [Tensor(uid=1830,size=28), Tensor(uid=1831,size=14)]\n",
      "[<operator-1805, add_forward>] [Tensor(uid=1825,size=28), Tensor(uid=1830,size=28)] [Tensor(uid=1832,size=28)]\n",
      "[<operator-1806, layernorm_forward>] [Tensor(uid=1832,size=28)] [Tensor(uid=1833,size=28)]\n",
      "[<operator-1807, linear_qkv>] [Tensor(uid=1833,size=28)] [Tensor(uid=1834,size=42)]\n",
      "[<operator-1808, matmul_qk>] [Tensor(uid=1834,size=42)] [Tensor(uid=1835,size=128)]\n",
      "[<operator-1809, softmax_forward>] [Tensor(uid=1835,size=128)] [Tensor(uid=1836,size=128)]\n",
      "[<operator-1810, dropout_forward>] [Tensor(uid=1836,size=128)] [Tensor(uid=1837,size=128), Tensor(uid=1838,size=64)]\n",
      "[<operator-1811, matmul_v>] [Tensor(uid=1837,size=128), Tensor(uid=1834,size=42)] [Tensor(uid=1839,size=14)]\n",
      "[<operator-1812, linear_forward>] [Tensor(uid=1839,size=14)] [Tensor(uid=1840,size=28)]\n",
      "[<operator-1813, allreduce_forward>] [Tensor(uid=1840,size=28)] []\n",
      "[<operator-1814, output_dropout>] [Tensor(uid=1840,size=28)] [Tensor(uid=1841,size=28), Tensor(uid=1842,size=14)]\n",
      "[<operator-1815, add_forward>] [Tensor(uid=1832,size=28), Tensor(uid=1841,size=28)] [Tensor(uid=1843,size=28)]\n",
      "[<operator-1816, layernorm_forward>] [Tensor(uid=1843,size=28)] [Tensor(uid=1844,size=28)]\n",
      "[<operator-1817, linear_1_forward>] [Tensor(uid=1844,size=28)] [Tensor(uid=1845,size=56)]\n",
      "[<operator-1818, gelu_forward>] [Tensor(uid=1845,size=56)] [Tensor(uid=1846,size=56)]\n",
      "[<operator-1819, linear_2_forward>] [Tensor(uid=1846,size=56)] [Tensor(uid=1847,size=28)]\n",
      "[<operator-1820, allreduce_forward>] [Tensor(uid=1847,size=28)] []\n",
      "[<operator-1821, dropout_forward>] [Tensor(uid=1847,size=28)] [Tensor(uid=1848,size=28), Tensor(uid=1849,size=14)]\n",
      "[<operator-1822, add_forward>] [Tensor(uid=1843,size=28), Tensor(uid=1848,size=28)] [Tensor(uid=1850,size=28)]\n",
      "[<operator-1823, layernorm_forward>] [Tensor(uid=1850,size=28)] [Tensor(uid=1851,size=28)]\n",
      "[<operator-1824, linear_qkv>] [Tensor(uid=1851,size=28)] [Tensor(uid=1852,size=42)]\n",
      "[<operator-1825, matmul_qk>] [Tensor(uid=1852,size=42)] [Tensor(uid=1853,size=128)]\n",
      "[<operator-1826, softmax_forward>] [Tensor(uid=1853,size=128)] [Tensor(uid=1854,size=128)]\n",
      "[<operator-1827, dropout_forward>] [Tensor(uid=1854,size=128)] [Tensor(uid=1855,size=128), Tensor(uid=1856,size=64)]\n",
      "[<operator-1828, matmul_v>] [Tensor(uid=1855,size=128), Tensor(uid=1852,size=42)] [Tensor(uid=1857,size=14)]\n",
      "[<operator-1829, linear_forward>] [Tensor(uid=1857,size=14)] [Tensor(uid=1858,size=28)]\n",
      "[<operator-1830, allreduce_forward>] [Tensor(uid=1858,size=28)] []\n",
      "[<operator-1831, output_dropout>] [Tensor(uid=1858,size=28)] [Tensor(uid=1859,size=28), Tensor(uid=1860,size=14)]\n",
      "[<operator-1832, add_forward>] [Tensor(uid=1850,size=28), Tensor(uid=1859,size=28)] [Tensor(uid=1861,size=28)]\n",
      "[<operator-1833, layernorm_forward>] [Tensor(uid=1861,size=28)] [Tensor(uid=1862,size=28)]\n",
      "[<operator-1834, linear_1_forward>] [Tensor(uid=1862,size=28)] [Tensor(uid=1863,size=56)]\n",
      "[<operator-1835, gelu_forward>] [Tensor(uid=1863,size=56)] [Tensor(uid=1864,size=56)]\n",
      "[<operator-1836, linear_2_forward>] [Tensor(uid=1864,size=56)] [Tensor(uid=1865,size=28)]\n",
      "[<operator-1837, allreduce_forward>] [Tensor(uid=1865,size=28)] []\n",
      "[<operator-1838, dropout_forward>] [Tensor(uid=1865,size=28)] [Tensor(uid=1866,size=28), Tensor(uid=1867,size=14)]\n",
      "[<operator-1839, add_forward>] [Tensor(uid=1861,size=28), Tensor(uid=1866,size=28)] [Tensor(uid=1868,size=28)]\n",
      "[<operator-1840, layernorm_forward>] [Tensor(uid=1868,size=28)] [Tensor(uid=1869,size=28)]\n",
      "[<operator-1841, linear_qkv>] [Tensor(uid=1869,size=28)] [Tensor(uid=1870,size=42)]\n",
      "[<operator-1842, matmul_qk>] [Tensor(uid=1870,size=42)] [Tensor(uid=1871,size=128)]\n",
      "[<operator-1843, softmax_forward>] [Tensor(uid=1871,size=128)] [Tensor(uid=1872,size=128)]\n",
      "[<operator-1844, dropout_forward>] [Tensor(uid=1872,size=128)] [Tensor(uid=1873,size=128), Tensor(uid=1874,size=64)]\n",
      "[<operator-1845, matmul_v>] [Tensor(uid=1873,size=128), Tensor(uid=1870,size=42)] [Tensor(uid=1875,size=14)]\n",
      "[<operator-1846, linear_forward>] [Tensor(uid=1875,size=14)] [Tensor(uid=1876,size=28)]\n",
      "[<operator-1847, allreduce_forward>] [Tensor(uid=1876,size=28)] []\n",
      "[<operator-1848, output_dropout>] [Tensor(uid=1876,size=28)] [Tensor(uid=1877,size=28), Tensor(uid=1878,size=14)]\n",
      "[<operator-1849, add_forward>] [Tensor(uid=1868,size=28), Tensor(uid=1877,size=28)] [Tensor(uid=1879,size=28)]\n",
      "[<operator-1850, layernorm_forward>] [Tensor(uid=1879,size=28)] [Tensor(uid=1880,size=28)]\n",
      "[<operator-1851, linear_1_forward>] [Tensor(uid=1880,size=28)] [Tensor(uid=1881,size=56)]\n",
      "[<operator-1852, gelu_forward>] [Tensor(uid=1881,size=56)] [Tensor(uid=1882,size=56)]\n",
      "[<operator-1853, linear_2_forward>] [Tensor(uid=1882,size=56)] [Tensor(uid=1883,size=28)]\n",
      "[<operator-1854, allreduce_forward>] [Tensor(uid=1883,size=28)] []\n",
      "[<operator-1855, dropout_forward>] [Tensor(uid=1883,size=28)] [Tensor(uid=1884,size=28), Tensor(uid=1885,size=14)]\n",
      "[<operator-1856, add_forward>] [Tensor(uid=1879,size=28), Tensor(uid=1884,size=28)] [Tensor(uid=1886,size=28)]\n",
      "[<operator-1857, layernorm_forward>] [Tensor(uid=1886,size=28)] [Tensor(uid=1887,size=28)]\n",
      "[<operator-1858, linear_qkv>] [Tensor(uid=1887,size=28)] [Tensor(uid=1888,size=42)]\n",
      "[<operator-1859, matmul_qk>] [Tensor(uid=1888,size=42)] [Tensor(uid=1889,size=128)]\n",
      "[<operator-1860, softmax_forward>] [Tensor(uid=1889,size=128)] [Tensor(uid=1890,size=128)]\n",
      "[<operator-1861, dropout_forward>] [Tensor(uid=1890,size=128)] [Tensor(uid=1891,size=128), Tensor(uid=1892,size=64)]\n",
      "[<operator-1862, matmul_v>] [Tensor(uid=1891,size=128), Tensor(uid=1888,size=42)] [Tensor(uid=1893,size=14)]\n",
      "[<operator-1863, linear_forward>] [Tensor(uid=1893,size=14)] [Tensor(uid=1894,size=28)]\n",
      "[<operator-1864, allreduce_forward>] [Tensor(uid=1894,size=28)] []\n",
      "[<operator-1865, output_dropout>] [Tensor(uid=1894,size=28)] [Tensor(uid=1895,size=28), Tensor(uid=1896,size=14)]\n",
      "[<operator-1866, add_forward>] [Tensor(uid=1886,size=28), Tensor(uid=1895,size=28)] [Tensor(uid=1897,size=28)]\n",
      "[<operator-1867, layernorm_forward>] [Tensor(uid=1897,size=28)] [Tensor(uid=1898,size=28)]\n",
      "[<operator-1868, linear_1_forward>] [Tensor(uid=1898,size=28)] [Tensor(uid=1899,size=56)]\n",
      "[<operator-1869, gelu_forward>] [Tensor(uid=1899,size=56)] [Tensor(uid=1900,size=56)]\n",
      "[<operator-1870, linear_2_forward>] [Tensor(uid=1900,size=56)] [Tensor(uid=1901,size=28)]\n",
      "[<operator-1871, allreduce_forward>] [Tensor(uid=1901,size=28)] []\n",
      "[<operator-1872, dropout_forward>] [Tensor(uid=1901,size=28)] [Tensor(uid=1902,size=28), Tensor(uid=1903,size=14)]\n",
      "[<operator-1873, add_forward>] [Tensor(uid=1897,size=28), Tensor(uid=1902,size=28)] [Tensor(uid=1904,size=28)]\n",
      "[<operator-1874, layernorm_forward>] [Tensor(uid=1904,size=28)] [Tensor(uid=1905,size=28)]\n",
      "[<operator-1875, linear_qkv>] [Tensor(uid=1905,size=28)] [Tensor(uid=1906,size=42)]\n",
      "[<operator-1876, matmul_qk>] [Tensor(uid=1906,size=42)] [Tensor(uid=1907,size=128)]\n",
      "[<operator-1877, softmax_forward>] [Tensor(uid=1907,size=128)] [Tensor(uid=1908,size=128)]\n",
      "[<operator-1878, dropout_forward>] [Tensor(uid=1908,size=128)] [Tensor(uid=1909,size=128), Tensor(uid=1910,size=64)]\n",
      "[<operator-1879, matmul_v>] [Tensor(uid=1909,size=128), Tensor(uid=1906,size=42)] [Tensor(uid=1911,size=14)]\n",
      "[<operator-1880, linear_forward>] [Tensor(uid=1911,size=14)] [Tensor(uid=1912,size=28)]\n",
      "[<operator-1881, allreduce_forward>] [Tensor(uid=1912,size=28)] []\n",
      "[<operator-1882, output_dropout>] [Tensor(uid=1912,size=28)] [Tensor(uid=1913,size=28), Tensor(uid=1914,size=14)]\n",
      "[<operator-1883, add_forward>] [Tensor(uid=1904,size=28), Tensor(uid=1913,size=28)] [Tensor(uid=1915,size=28)]\n",
      "[<operator-1884, layernorm_forward>] [Tensor(uid=1915,size=28)] [Tensor(uid=1916,size=28)]\n",
      "[<operator-1885, linear_1_forward>] [Tensor(uid=1916,size=28)] [Tensor(uid=1917,size=56)]\n",
      "[<operator-1886, gelu_forward>] [Tensor(uid=1917,size=56)] [Tensor(uid=1918,size=56)]\n",
      "[<operator-1887, linear_2_forward>] [Tensor(uid=1918,size=56)] [Tensor(uid=1919,size=28)]\n",
      "[<operator-1888, allreduce_forward>] [Tensor(uid=1919,size=28)] []\n",
      "[<operator-1889, dropout_forward>] [Tensor(uid=1919,size=28)] [Tensor(uid=1920,size=28), Tensor(uid=1921,size=14)]\n",
      "[<operator-1890, add_forward>] [Tensor(uid=1915,size=28), Tensor(uid=1920,size=28)] [Tensor(uid=1922,size=28)]\n",
      "[<operator-1891, loss_fn>] [Tensor(uid=1922,size=28)] [Tensor(uid=1923,size=28)]\n",
      "[<operator-3618, loss_fn_sync_merge>] None None\n",
      "[<operator-1892, dropout_backward>] [Tensor(uid=1920,size=28), Tensor(uid=1921,size=14), Tensor(uid=1923,size=28)] [Tensor(uid=1924,size=28)]\n",
      "[<operator-1893, linear_2_backward>] [Tensor(uid=1918,size=56), Tensor(uid=1924,size=28)] [Tensor(uid=1925,size=56)]\n",
      "[<operator-1894, gelu_backward>] [Tensor(uid=1917,size=56), Tensor(uid=1925,size=56)] [Tensor(uid=1926,size=56)]\n",
      "[<operator-1895, linear_1_backward>] [Tensor(uid=1916,size=28), Tensor(uid=1926,size=56)] [Tensor(uid=1927,size=28)]\n",
      "[<operator-1896, allreduce_backward>] [Tensor(uid=1927,size=28)] []\n",
      "[<operator-1897, layernorm_backward>] [Tensor(uid=1915,size=28), Tensor(uid=1927,size=28)] [Tensor(uid=1928,size=28)]\n",
      "[<operator-1898, backward_grad_accumulate_res1>] [Tensor(uid=1928,size=28), Tensor(uid=1923,size=28)] []\n",
      "[<operator-1899, output_dropout_backward>] [Tensor(uid=1913,size=28), Tensor(uid=1914,size=14), Tensor(uid=1928,size=28)] [Tensor(uid=1929,size=28)]\n",
      "[<operator-1900, linear_backward>] [Tensor(uid=1911,size=14), Tensor(uid=1929,size=28)] [Tensor(uid=1930,size=14)]\n",
      "[<operator-1901, matmul_v_backward>] [Tensor(uid=1909,size=128), Tensor(uid=1906,size=42), Tensor(uid=1930,size=14)] [Tensor(uid=1931,size=14), Tensor(uid=1932,size=128)]\n",
      "[<operator-1902, dropout_backward>] [Tensor(uid=1909,size=128), Tensor(uid=1910,size=64), Tensor(uid=1932,size=128)] [Tensor(uid=1933,size=128)]\n",
      "[<operator-1903, softmax_backward>] [Tensor(uid=1908,size=128), Tensor(uid=1933,size=128)] [Tensor(uid=1934,size=128)]\n",
      "[<operator-1904, matmul_qk_backward>] [Tensor(uid=1906,size=42), Tensor(uid=1934,size=128)] [Tensor(uid=1935,size=28)]\n",
      "[<operator-1905, linear_qkv_backward>] [Tensor(uid=1905,size=28), Tensor(uid=1931,size=14), Tensor(uid=1935,size=28)] [Tensor(uid=1936,size=28)]\n",
      "[<operator-1906, allreduce_backward>] [Tensor(uid=1936,size=28)] []\n",
      "[<operator-1907, layernorm_backward>] [Tensor(uid=1904,size=28), Tensor(uid=1936,size=28)] [Tensor(uid=1937,size=28)]\n",
      "[<operator-1908, backward_grad_accumulate_input>] [Tensor(uid=1937,size=28), Tensor(uid=1928,size=28)] []\n",
      "[<operator-1909, dropout_backward>] [Tensor(uid=1902,size=28), Tensor(uid=1903,size=14), Tensor(uid=1937,size=28)] [Tensor(uid=1938,size=28)]\n",
      "[<operator-1910, linear_2_backward>] [Tensor(uid=1900,size=56), Tensor(uid=1938,size=28)] [Tensor(uid=1939,size=56)]\n",
      "[<operator-1911, gelu_backward>] [Tensor(uid=1899,size=56), Tensor(uid=1939,size=56)] [Tensor(uid=1940,size=56)]\n",
      "[<operator-1912, linear_1_backward>] [Tensor(uid=1898,size=28), Tensor(uid=1940,size=56)] [Tensor(uid=1941,size=28)]\n",
      "[<operator-1913, allreduce_backward>] [Tensor(uid=1941,size=28)] []\n",
      "[<operator-1914, layernorm_backward>] [Tensor(uid=1897,size=28), Tensor(uid=1941,size=28)] [Tensor(uid=1942,size=28)]\n",
      "[<operator-1915, backward_grad_accumulate_res1>] [Tensor(uid=1942,size=28), Tensor(uid=1937,size=28)] []\n",
      "[<operator-1916, output_dropout_backward>] [Tensor(uid=1895,size=28), Tensor(uid=1896,size=14), Tensor(uid=1942,size=28)] [Tensor(uid=1943,size=28)]\n",
      "[<operator-1917, linear_backward>] [Tensor(uid=1893,size=14), Tensor(uid=1943,size=28)] [Tensor(uid=1944,size=14)]\n",
      "[<operator-1918, matmul_v_backward>] [Tensor(uid=1891,size=128), Tensor(uid=1888,size=42), Tensor(uid=1944,size=14)] [Tensor(uid=1945,size=14), Tensor(uid=1946,size=128)]\n",
      "[<operator-1919, dropout_backward>] [Tensor(uid=1891,size=128), Tensor(uid=1892,size=64), Tensor(uid=1946,size=128)] [Tensor(uid=1947,size=128)]\n",
      "[<operator-1920, softmax_backward>] [Tensor(uid=1890,size=128), Tensor(uid=1947,size=128)] [Tensor(uid=1948,size=128)]\n",
      "[<operator-1921, matmul_qk_backward>] [Tensor(uid=1888,size=42), Tensor(uid=1948,size=128)] [Tensor(uid=1949,size=28)]\n",
      "[<operator-1922, linear_qkv_backward>] [Tensor(uid=1887,size=28), Tensor(uid=1945,size=14), Tensor(uid=1949,size=28)] [Tensor(uid=1950,size=28)]\n",
      "[<operator-1923, allreduce_backward>] [Tensor(uid=1950,size=28)] []\n",
      "[<operator-1924, layernorm_backward>] [Tensor(uid=1886,size=28), Tensor(uid=1950,size=28)] [Tensor(uid=1951,size=28)]\n",
      "[<operator-1925, backward_grad_accumulate_input>] [Tensor(uid=1951,size=28), Tensor(uid=1942,size=28)] []\n",
      "[<operator-1926, dropout_backward>] [Tensor(uid=1884,size=28), Tensor(uid=1885,size=14), Tensor(uid=1951,size=28)] [Tensor(uid=1952,size=28)]\n",
      "[<operator-1927, linear_2_backward>] [Tensor(uid=1882,size=56), Tensor(uid=1952,size=28)] [Tensor(uid=1953,size=56)]\n",
      "[<operator-1928, gelu_backward>] [Tensor(uid=1881,size=56), Tensor(uid=1953,size=56)] [Tensor(uid=1954,size=56)]\n",
      "[<operator-1929, linear_1_backward>] [Tensor(uid=1880,size=28), Tensor(uid=1954,size=56)] [Tensor(uid=1955,size=28)]\n",
      "[<operator-1930, allreduce_backward>] [Tensor(uid=1955,size=28)] []\n",
      "[<operator-1931, layernorm_backward>] [Tensor(uid=1879,size=28), Tensor(uid=1955,size=28)] [Tensor(uid=1956,size=28)]\n",
      "[<operator-1932, backward_grad_accumulate_res1>] [Tensor(uid=1956,size=28), Tensor(uid=1951,size=28)] []\n",
      "[<operator-1933, output_dropout_backward>] [Tensor(uid=1877,size=28), Tensor(uid=1878,size=14), Tensor(uid=1956,size=28)] [Tensor(uid=1957,size=28)]\n",
      "[<operator-1934, linear_backward>] [Tensor(uid=1875,size=14), Tensor(uid=1957,size=28)] [Tensor(uid=1958,size=14)]\n",
      "[<operator-1935, matmul_v_backward>] [Tensor(uid=1873,size=128), Tensor(uid=1870,size=42), Tensor(uid=1958,size=14)] [Tensor(uid=1959,size=14), Tensor(uid=1960,size=128)]\n",
      "[<operator-1936, dropout_backward>] [Tensor(uid=1873,size=128), Tensor(uid=1874,size=64), Tensor(uid=1960,size=128)] [Tensor(uid=1961,size=128)]\n",
      "[<operator-1937, softmax_backward>] [Tensor(uid=1872,size=128), Tensor(uid=1961,size=128)] [Tensor(uid=1962,size=128)]\n",
      "[<operator-1938, matmul_qk_backward>] [Tensor(uid=1870,size=42), Tensor(uid=1962,size=128)] [Tensor(uid=1963,size=28)]\n",
      "[<operator-1939, linear_qkv_backward>] [Tensor(uid=1869,size=28), Tensor(uid=1959,size=14), Tensor(uid=1963,size=28)] [Tensor(uid=1964,size=28)]\n",
      "[<operator-1940, allreduce_backward>] [Tensor(uid=1964,size=28)] []\n",
      "[<operator-1941, layernorm_backward>] [Tensor(uid=1868,size=28), Tensor(uid=1964,size=28)] [Tensor(uid=1965,size=28)]\n",
      "[<operator-1942, backward_grad_accumulate_input>] [Tensor(uid=1965,size=28), Tensor(uid=1956,size=28)] []\n",
      "[<operator-1943, dropout_backward>] [Tensor(uid=1866,size=28), Tensor(uid=1867,size=14), Tensor(uid=1965,size=28)] [Tensor(uid=1966,size=28)]\n",
      "[<operator-1944, linear_2_backward>] [Tensor(uid=1864,size=56), Tensor(uid=1966,size=28)] [Tensor(uid=1967,size=56)]\n",
      "[<operator-1945, gelu_backward>] [Tensor(uid=1863,size=56), Tensor(uid=1967,size=56)] [Tensor(uid=1968,size=56)]\n",
      "[<operator-1946, linear_1_backward>] [Tensor(uid=1862,size=28), Tensor(uid=1968,size=56)] [Tensor(uid=1969,size=28)]\n",
      "[<operator-1947, allreduce_backward>] [Tensor(uid=1969,size=28)] []\n",
      "[<operator-1948, layernorm_backward>] [Tensor(uid=1861,size=28), Tensor(uid=1969,size=28)] [Tensor(uid=1970,size=28)]\n",
      "[<operator-1949, backward_grad_accumulate_res1>] [Tensor(uid=1970,size=28), Tensor(uid=1965,size=28)] []\n",
      "[<operator-1950, output_dropout_backward>] [Tensor(uid=1859,size=28), Tensor(uid=1860,size=14), Tensor(uid=1970,size=28)] [Tensor(uid=1971,size=28)]\n",
      "[<operator-1951, linear_backward>] [Tensor(uid=1857,size=14), Tensor(uid=1971,size=28)] [Tensor(uid=1972,size=14)]\n",
      "[<operator-1952, matmul_v_backward>] [Tensor(uid=1855,size=128), Tensor(uid=1852,size=42), Tensor(uid=1972,size=14)] [Tensor(uid=1973,size=14), Tensor(uid=1974,size=128)]\n",
      "[<operator-1953, dropout_backward>] [Tensor(uid=1855,size=128), Tensor(uid=1856,size=64), Tensor(uid=1974,size=128)] [Tensor(uid=1975,size=128)]\n",
      "[<operator-1954, softmax_backward>] [Tensor(uid=1854,size=128), Tensor(uid=1975,size=128)] [Tensor(uid=1976,size=128)]\n",
      "[<operator-1955, matmul_qk_backward>] [Tensor(uid=1852,size=42), Tensor(uid=1976,size=128)] [Tensor(uid=1977,size=28)]\n",
      "[<operator-1956, linear_qkv_backward>] [Tensor(uid=1851,size=28), Tensor(uid=1973,size=14), Tensor(uid=1977,size=28)] [Tensor(uid=1978,size=28)]\n",
      "[<operator-1957, allreduce_backward>] [Tensor(uid=1978,size=28)] []\n",
      "[<operator-1958, layernorm_backward>] [Tensor(uid=1850,size=28), Tensor(uid=1978,size=28)] [Tensor(uid=1979,size=28)]\n",
      "[<operator-1959, backward_grad_accumulate_input>] [Tensor(uid=1979,size=28), Tensor(uid=1970,size=28)] []\n",
      "[<operator-1960, dropout_backward>] [Tensor(uid=1848,size=28), Tensor(uid=1849,size=14), Tensor(uid=1979,size=28)] [Tensor(uid=1980,size=28)]\n",
      "[<operator-1961, linear_2_backward>] [Tensor(uid=1846,size=56), Tensor(uid=1980,size=28)] [Tensor(uid=1981,size=56)]\n",
      "[<operator-1962, gelu_backward>] [Tensor(uid=1845,size=56), Tensor(uid=1981,size=56)] [Tensor(uid=1982,size=56)]\n",
      "[<operator-1963, linear_1_backward>] [Tensor(uid=1844,size=28), Tensor(uid=1982,size=56)] [Tensor(uid=1983,size=28)]\n",
      "[<operator-1964, allreduce_backward>] [Tensor(uid=1983,size=28)] []\n",
      "[<operator-1965, layernorm_backward>] [Tensor(uid=1843,size=28), Tensor(uid=1983,size=28)] [Tensor(uid=1984,size=28)]\n",
      "[<operator-1966, backward_grad_accumulate_res1>] [Tensor(uid=1984,size=28), Tensor(uid=1979,size=28)] []\n",
      "[<operator-1967, output_dropout_backward>] [Tensor(uid=1841,size=28), Tensor(uid=1842,size=14), Tensor(uid=1984,size=28)] [Tensor(uid=1985,size=28)]\n",
      "[<operator-1968, linear_backward>] [Tensor(uid=1839,size=14), Tensor(uid=1985,size=28)] [Tensor(uid=1986,size=14)]\n",
      "[<operator-1969, matmul_v_backward>] [Tensor(uid=1837,size=128), Tensor(uid=1834,size=42), Tensor(uid=1986,size=14)] [Tensor(uid=1987,size=14), Tensor(uid=1988,size=128)]\n",
      "[<operator-1970, dropout_backward>] [Tensor(uid=1837,size=128), Tensor(uid=1838,size=64), Tensor(uid=1988,size=128)] [Tensor(uid=1989,size=128)]\n",
      "[<operator-1971, softmax_backward>] [Tensor(uid=1836,size=128), Tensor(uid=1989,size=128)] [Tensor(uid=1990,size=128)]\n",
      "[<operator-1972, matmul_qk_backward>] [Tensor(uid=1834,size=42), Tensor(uid=1990,size=128)] [Tensor(uid=1991,size=28)]\n",
      "[<operator-1973, linear_qkv_backward>] [Tensor(uid=1833,size=28), Tensor(uid=1987,size=14), Tensor(uid=1991,size=28)] [Tensor(uid=1992,size=28)]\n",
      "[<operator-1974, allreduce_backward>] [Tensor(uid=1992,size=28)] []\n",
      "[<operator-1975, layernorm_backward>] [Tensor(uid=1832,size=28), Tensor(uid=1992,size=28)] [Tensor(uid=1993,size=28)]\n",
      "[<operator-1976, backward_grad_accumulate_input>] [Tensor(uid=1993,size=28), Tensor(uid=1984,size=28)] []\n",
      "[<operator-1977, dropout_backward>] [Tensor(uid=1830,size=28), Tensor(uid=1831,size=14), Tensor(uid=1993,size=28)] [Tensor(uid=1994,size=28)]\n",
      "[<operator-1978, linear_2_backward>] [Tensor(uid=1828,size=56), Tensor(uid=1994,size=28)] [Tensor(uid=1995,size=56)]\n",
      "[<operator-1979, gelu_backward>] [Tensor(uid=1827,size=56), Tensor(uid=1995,size=56)] [Tensor(uid=1996,size=56)]\n",
      "[<operator-1980, linear_1_backward>] [Tensor(uid=1826,size=28), Tensor(uid=1996,size=56)] [Tensor(uid=1997,size=28)]\n",
      "[<operator-1981, allreduce_backward>] [Tensor(uid=1997,size=28)] []\n",
      "[<operator-1982, layernorm_backward>] [Tensor(uid=1825,size=28), Tensor(uid=1997,size=28)] [Tensor(uid=1998,size=28)]\n",
      "[<operator-1983, backward_grad_accumulate_res1>] [Tensor(uid=1998,size=28), Tensor(uid=1993,size=28)] []\n",
      "[<operator-1984, output_dropout_backward>] [Tensor(uid=1823,size=28), Tensor(uid=1824,size=14), Tensor(uid=1998,size=28)] [Tensor(uid=1999,size=28)]\n",
      "[<operator-1985, linear_backward>] [Tensor(uid=1821,size=14), Tensor(uid=1999,size=28)] [Tensor(uid=2000,size=14)]\n",
      "[<operator-1986, matmul_v_backward>] [Tensor(uid=1819,size=128), Tensor(uid=1816,size=42), Tensor(uid=2000,size=14)] [Tensor(uid=2001,size=14), Tensor(uid=2002,size=128)]\n",
      "[<operator-1987, dropout_backward>] [Tensor(uid=1819,size=128), Tensor(uid=1820,size=64), Tensor(uid=2002,size=128)] [Tensor(uid=2003,size=128)]\n",
      "[<operator-1988, softmax_backward>] [Tensor(uid=1818,size=128), Tensor(uid=2003,size=128)] [Tensor(uid=2004,size=128)]\n",
      "[<operator-1989, matmul_qk_backward>] [Tensor(uid=1816,size=42), Tensor(uid=2004,size=128)] [Tensor(uid=2005,size=28)]\n",
      "[<operator-1990, linear_qkv_backward>] [Tensor(uid=1815,size=28), Tensor(uid=2001,size=14), Tensor(uid=2005,size=28)] [Tensor(uid=2006,size=28)]\n",
      "[<operator-1991, allreduce_backward>] [Tensor(uid=2006,size=28)] []\n",
      "[<operator-1992, layernorm_backward>] [Tensor(uid=1814,size=28), Tensor(uid=2006,size=28)] [Tensor(uid=2007,size=28)]\n",
      "[<operator-1993, backward_grad_accumulate_input>] [Tensor(uid=2007,size=28), Tensor(uid=1998,size=28)] []\n",
      "[<operator-1994, dropout_backward>] [Tensor(uid=1812,size=28), Tensor(uid=1813,size=14), Tensor(uid=2007,size=28)] [Tensor(uid=2008,size=28)]\n",
      "[<operator-1995, linear_2_backward>] [Tensor(uid=1810,size=56), Tensor(uid=2008,size=28)] [Tensor(uid=2009,size=56)]\n",
      "[<operator-1996, gelu_backward>] [Tensor(uid=1809,size=56), Tensor(uid=2009,size=56)] [Tensor(uid=2010,size=56)]\n",
      "[<operator-1997, linear_1_backward>] [Tensor(uid=1808,size=28), Tensor(uid=2010,size=56)] [Tensor(uid=2011,size=28)]\n",
      "[<operator-1998, allreduce_backward>] [Tensor(uid=2011,size=28)] []\n",
      "[<operator-1999, layernorm_backward>] [Tensor(uid=1807,size=28), Tensor(uid=2011,size=28)] [Tensor(uid=2012,size=28)]\n",
      "[<operator-2000, backward_grad_accumulate_res1>] [Tensor(uid=2012,size=28), Tensor(uid=2007,size=28)] []\n",
      "[<operator-2001, output_dropout_backward>] [Tensor(uid=1805,size=28), Tensor(uid=1806,size=14), Tensor(uid=2012,size=28)] [Tensor(uid=2013,size=28)]\n",
      "[<operator-2002, linear_backward>] [Tensor(uid=1803,size=14), Tensor(uid=2013,size=28)] [Tensor(uid=2014,size=14)]\n",
      "[<operator-2003, matmul_v_backward>] [Tensor(uid=1801,size=128), Tensor(uid=1798,size=42), Tensor(uid=2014,size=14)] [Tensor(uid=2015,size=14), Tensor(uid=2016,size=128)]\n",
      "[<operator-2004, dropout_backward>] [Tensor(uid=1801,size=128), Tensor(uid=1802,size=64), Tensor(uid=2016,size=128)] [Tensor(uid=2017,size=128)]\n",
      "[<operator-2005, softmax_backward>] [Tensor(uid=1800,size=128), Tensor(uid=2017,size=128)] [Tensor(uid=2018,size=128)]\n",
      "[<operator-2006, matmul_qk_backward>] [Tensor(uid=1798,size=42), Tensor(uid=2018,size=128)] [Tensor(uid=2019,size=28)]\n",
      "[<operator-2007, linear_qkv_backward>] [Tensor(uid=1797,size=28), Tensor(uid=2015,size=14), Tensor(uid=2019,size=28)] [Tensor(uid=2020,size=28)]\n",
      "[<operator-2008, allreduce_backward>] [Tensor(uid=2020,size=28)] []\n",
      "[<operator-2009, layernorm_backward>] [Tensor(uid=1796,size=28), Tensor(uid=2020,size=28)] [Tensor(uid=2021,size=28)]\n",
      "[<operator-2010, backward_grad_accumulate_input>] [Tensor(uid=2021,size=28), Tensor(uid=2012,size=28)] []\n",
      "[<operator-2011, dropout_backward>] [Tensor(uid=1794,size=28), Tensor(uid=1795,size=14), Tensor(uid=2021,size=28)] [Tensor(uid=2022,size=28)]\n",
      "[<operator-2012, linear_2_backward>] [Tensor(uid=1792,size=56), Tensor(uid=2022,size=28)] [Tensor(uid=2023,size=56)]\n",
      "[<operator-2013, gelu_backward>] [Tensor(uid=1791,size=56), Tensor(uid=2023,size=56)] [Tensor(uid=2024,size=56)]\n",
      "[<operator-2014, linear_1_backward>] [Tensor(uid=1790,size=28), Tensor(uid=2024,size=56)] [Tensor(uid=2025,size=28)]\n",
      "[<operator-2015, allreduce_backward>] [Tensor(uid=2025,size=28)] []\n",
      "[<operator-2016, layernorm_backward>] [Tensor(uid=1789,size=28), Tensor(uid=2025,size=28)] [Tensor(uid=2026,size=28)]\n",
      "[<operator-2017, backward_grad_accumulate_res1>] [Tensor(uid=2026,size=28), Tensor(uid=2021,size=28)] []\n",
      "[<operator-2018, output_dropout_backward>] [Tensor(uid=1787,size=28), Tensor(uid=1788,size=14), Tensor(uid=2026,size=28)] [Tensor(uid=2027,size=28)]\n",
      "[<operator-2019, linear_backward>] [Tensor(uid=1785,size=14), Tensor(uid=2027,size=28)] [Tensor(uid=2028,size=14)]\n",
      "[<operator-2020, matmul_v_backward>] [Tensor(uid=1783,size=128), Tensor(uid=1780,size=42), Tensor(uid=2028,size=14)] [Tensor(uid=2029,size=14), Tensor(uid=2030,size=128)]\n",
      "[<operator-2021, dropout_backward>] [Tensor(uid=1783,size=128), Tensor(uid=1784,size=64), Tensor(uid=2030,size=128)] [Tensor(uid=2031,size=128)]\n",
      "[<operator-2022, softmax_backward>] [Tensor(uid=1782,size=128), Tensor(uid=2031,size=128)] [Tensor(uid=2032,size=128)]\n",
      "[<operator-2023, matmul_qk_backward>] [Tensor(uid=1780,size=42), Tensor(uid=2032,size=128)] [Tensor(uid=2033,size=28)]\n",
      "[<operator-2024, linear_qkv_backward>] [Tensor(uid=1779,size=28), Tensor(uid=2029,size=14), Tensor(uid=2033,size=28)] [Tensor(uid=2034,size=28)]\n",
      "[<operator-2025, allreduce_backward>] [Tensor(uid=2034,size=28)] []\n",
      "[<operator-2026, layernorm_backward>] [Tensor(uid=1778,size=28), Tensor(uid=2034,size=28)] [Tensor(uid=2035,size=28)]\n",
      "[<operator-2027, backward_grad_accumulate_input>] [Tensor(uid=2035,size=28), Tensor(uid=2026,size=28)] []\n",
      "[<operator-2028, dropout_backward>] [Tensor(uid=1776,size=28), Tensor(uid=1777,size=14), Tensor(uid=2035,size=28)] [Tensor(uid=2036,size=28)]\n",
      "[<operator-2029, linear_2_backward>] [Tensor(uid=1774,size=56), Tensor(uid=2036,size=28)] [Tensor(uid=2037,size=56)]\n",
      "[<operator-2030, gelu_backward>] [Tensor(uid=1773,size=56), Tensor(uid=2037,size=56)] [Tensor(uid=2038,size=56)]\n",
      "[<operator-2031, linear_1_backward>] [Tensor(uid=1772,size=28), Tensor(uid=2038,size=56)] [Tensor(uid=2039,size=28)]\n",
      "[<operator-2032, allreduce_backward>] [Tensor(uid=2039,size=28)] []\n",
      "[<operator-2033, layernorm_backward>] [Tensor(uid=1771,size=28), Tensor(uid=2039,size=28)] [Tensor(uid=2040,size=28)]\n",
      "[<operator-2034, backward_grad_accumulate_res1>] [Tensor(uid=2040,size=28), Tensor(uid=2035,size=28)] []\n",
      "[<operator-2035, output_dropout_backward>] [Tensor(uid=1769,size=28), Tensor(uid=1770,size=14), Tensor(uid=2040,size=28)] [Tensor(uid=2041,size=28)]\n",
      "[<operator-2036, linear_backward>] [Tensor(uid=1767,size=14), Tensor(uid=2041,size=28)] [Tensor(uid=2042,size=14)]\n",
      "[<operator-2037, matmul_v_backward>] [Tensor(uid=1765,size=128), Tensor(uid=1762,size=42), Tensor(uid=2042,size=14)] [Tensor(uid=2043,size=14), Tensor(uid=2044,size=128)]\n",
      "[<operator-2038, dropout_backward>] [Tensor(uid=1765,size=128), Tensor(uid=1766,size=64), Tensor(uid=2044,size=128)] [Tensor(uid=2045,size=128)]\n",
      "[<operator-2039, softmax_backward>] [Tensor(uid=1764,size=128), Tensor(uid=2045,size=128)] [Tensor(uid=2046,size=128)]\n",
      "[<operator-2040, matmul_qk_backward>] [Tensor(uid=1762,size=42), Tensor(uid=2046,size=128)] [Tensor(uid=2047,size=28)]\n",
      "[<operator-2041, linear_qkv_backward>] [Tensor(uid=1761,size=28), Tensor(uid=2043,size=14), Tensor(uid=2047,size=28)] [Tensor(uid=2048,size=28)]\n",
      "[<operator-2042, allreduce_backward>] [Tensor(uid=2048,size=28)] []\n",
      "[<operator-2043, layernorm_backward>] [Tensor(uid=1760,size=28), Tensor(uid=2048,size=28)] [Tensor(uid=2049,size=28)]\n",
      "[<operator-2044, backward_grad_accumulate_input>] [Tensor(uid=2049,size=28), Tensor(uid=2040,size=28)] []\n",
      "[<operator-2045, dropout_backward>] [Tensor(uid=1758,size=28), Tensor(uid=1759,size=14), Tensor(uid=2049,size=28)] [Tensor(uid=2050,size=28)]\n",
      "[<operator-2046, linear_2_backward>] [Tensor(uid=1756,size=56), Tensor(uid=2050,size=28)] [Tensor(uid=2051,size=56)]\n",
      "[<operator-2047, gelu_backward>] [Tensor(uid=1755,size=56), Tensor(uid=2051,size=56)] [Tensor(uid=2052,size=56)]\n",
      "[<operator-2048, linear_1_backward>] [Tensor(uid=1754,size=28), Tensor(uid=2052,size=56)] [Tensor(uid=2053,size=28)]\n",
      "[<operator-2049, allreduce_backward>] [Tensor(uid=2053,size=28)] []\n",
      "[<operator-2050, layernorm_backward>] [Tensor(uid=1753,size=28), Tensor(uid=2053,size=28)] [Tensor(uid=2054,size=28)]\n",
      "[<operator-2051, backward_grad_accumulate_res1>] [Tensor(uid=2054,size=28), Tensor(uid=2049,size=28)] []\n",
      "[<operator-2052, output_dropout_backward>] [Tensor(uid=1751,size=28), Tensor(uid=1752,size=14), Tensor(uid=2054,size=28)] [Tensor(uid=2055,size=28)]\n",
      "[<operator-2053, linear_backward>] [Tensor(uid=1749,size=14), Tensor(uid=2055,size=28)] [Tensor(uid=2056,size=14)]\n",
      "[<operator-2054, matmul_v_backward>] [Tensor(uid=1747,size=128), Tensor(uid=1744,size=42), Tensor(uid=2056,size=14)] [Tensor(uid=2057,size=14), Tensor(uid=2058,size=128)]\n",
      "[<operator-2055, dropout_backward>] [Tensor(uid=1747,size=128), Tensor(uid=1748,size=64), Tensor(uid=2058,size=128)] [Tensor(uid=2059,size=128)]\n",
      "[<operator-2056, softmax_backward>] [Tensor(uid=1746,size=128), Tensor(uid=2059,size=128)] [Tensor(uid=2060,size=128)]\n",
      "[<operator-2057, matmul_qk_backward>] [Tensor(uid=1744,size=42), Tensor(uid=2060,size=128)] [Tensor(uid=2061,size=28)]\n",
      "[<operator-2058, linear_qkv_backward>] [Tensor(uid=1743,size=28), Tensor(uid=2057,size=14), Tensor(uid=2061,size=28)] [Tensor(uid=2062,size=28)]\n",
      "[<operator-2059, allreduce_backward>] [Tensor(uid=2062,size=28)] []\n",
      "[<operator-2060, layernorm_backward>] [Tensor(uid=1742,size=28), Tensor(uid=2062,size=28)] [Tensor(uid=2063,size=28)]\n",
      "[<operator-2061, backward_grad_accumulate_input>] [Tensor(uid=2063,size=28), Tensor(uid=2054,size=28)] []\n",
      "[<operator-2062, dropout_backward>] [Tensor(uid=1740,size=28), Tensor(uid=1741,size=14), Tensor(uid=2063,size=28)] [Tensor(uid=2064,size=28)]\n",
      "[<operator-3610, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3611, linear_2_forward_merge>] None None\n",
      "[<operator-2063, linear_2_backward>] [Tensor(uid=1738,size=56), Tensor(uid=2064,size=28)] [Tensor(uid=2065,size=56)]\n",
      "[<operator-3604, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3605, gelu_forward_merge>] None None\n",
      "[<operator-2064, gelu_backward>] [Tensor(uid=1737,size=56), Tensor(uid=2065,size=56)] [Tensor(uid=2066,size=56)]\n",
      "[<operator-3598, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3599, linear_1_forward_merge>] None None\n",
      "[<operator-2065, linear_1_backward>] [Tensor(uid=1736,size=28), Tensor(uid=2066,size=56)] [Tensor(uid=2067,size=28)]\n",
      "[<operator-2066, allreduce_backward>] [Tensor(uid=2067,size=28)] []\n",
      "[<operator-3616, add_forward_branch_loadin>] None None\n",
      "[<operator-3617, add_forward_merge>] None None\n",
      "[<operator-2067, layernorm_backward>] [Tensor(uid=1735,size=28), Tensor(uid=2067,size=28)] [Tensor(uid=2068,size=28)]\n",
      "[<operator-2068, backward_grad_accumulate_res1>] [Tensor(uid=2068,size=28), Tensor(uid=2063,size=28)] []\n",
      "[<operator-2069, output_dropout_backward>] [Tensor(uid=1733,size=28), Tensor(uid=1734,size=14), Tensor(uid=2068,size=28)] [Tensor(uid=2069,size=28)]\n",
      "[<operator-3586, linear_forward_branch_loadin>] None None\n",
      "[<operator-3587, linear_forward_merge>] None None\n",
      "[<operator-2070, linear_backward>] [Tensor(uid=1731,size=14), Tensor(uid=2069,size=28)] [Tensor(uid=2070,size=14)]\n",
      "[<operator-3580, matmul_v_branch_loadin>] None None\n",
      "[<operator-3581, matmul_v_merge>] None None\n",
      "[<operator-2071, matmul_v_backward>] [Tensor(uid=1729,size=128), Tensor(uid=1726,size=42), Tensor(uid=2070,size=14)] [Tensor(uid=2071,size=14), Tensor(uid=2072,size=128)]\n",
      "[<operator-2072, dropout_backward>] [Tensor(uid=1729,size=128), Tensor(uid=1730,size=64), Tensor(uid=2072,size=128)] [Tensor(uid=2073,size=128)]\n",
      "[<operator-3574, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3575, dropout_forward_merge>] None None\n",
      "[<operator-2073, softmax_backward>] [Tensor(uid=1728,size=128), Tensor(uid=2073,size=128)] [Tensor(uid=2074,size=128)]\n",
      "[<operator-2074, matmul_qk_backward>] [Tensor(uid=1726,size=42), Tensor(uid=2074,size=128)] [Tensor(uid=2075,size=28)]\n",
      "[<operator-3568, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3569, linear_qkv_merge>] None None\n",
      "[<operator-2075, linear_qkv_backward>] [Tensor(uid=1725,size=28), Tensor(uid=2071,size=14), Tensor(uid=2075,size=28)] [Tensor(uid=2076,size=28)]\n",
      "[<operator-2076, allreduce_backward>] [Tensor(uid=2076,size=28)] []\n",
      "[<operator-3592, add_forward_branch_loadin>] None None\n",
      "[<operator-3593, add_forward_merge>] None None\n",
      "[<operator-2077, layernorm_backward>] [Tensor(uid=1724,size=28), Tensor(uid=2076,size=28)] [Tensor(uid=2077,size=28)]\n",
      "[<operator-2078, backward_grad_accumulate_input>] [Tensor(uid=2077,size=28), Tensor(uid=2068,size=28)] []\n",
      "[<operator-2079, dropout_backward>] [Tensor(uid=1722,size=28), Tensor(uid=1723,size=14), Tensor(uid=2077,size=28)] [Tensor(uid=2078,size=28)]\n",
      "[<operator-3556, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3557, linear_2_forward_merge>] None None\n",
      "[<operator-2080, linear_2_backward>] [Tensor(uid=1720,size=56), Tensor(uid=2078,size=28)] [Tensor(uid=2079,size=56)]\n",
      "[<operator-3550, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3551, gelu_forward_merge>] None None\n",
      "[<operator-2081, gelu_backward>] [Tensor(uid=1719,size=56), Tensor(uid=2079,size=56)] [Tensor(uid=2080,size=56)]\n",
      "[<operator-3544, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3545, linear_1_forward_merge>] None None\n",
      "[<operator-2082, linear_1_backward>] [Tensor(uid=1718,size=28), Tensor(uid=2080,size=56)] [Tensor(uid=2081,size=28)]\n",
      "[<operator-2083, allreduce_backward>] [Tensor(uid=2081,size=28)] []\n",
      "[<operator-3562, add_forward_branch_loadin>] None None\n",
      "[<operator-3563, add_forward_merge>] None None\n",
      "[<operator-2084, layernorm_backward>] [Tensor(uid=1717,size=28), Tensor(uid=2081,size=28)] [Tensor(uid=2082,size=28)]\n",
      "[<operator-2085, backward_grad_accumulate_res1>] [Tensor(uid=2082,size=28), Tensor(uid=2077,size=28)] []\n",
      "[<operator-2086, output_dropout_backward>] [Tensor(uid=1715,size=28), Tensor(uid=1716,size=14), Tensor(uid=2082,size=28)] [Tensor(uid=2083,size=28)]\n",
      "[<operator-3532, linear_forward_branch_loadin>] None None\n",
      "[<operator-3533, linear_forward_merge>] None None\n",
      "[<operator-2087, linear_backward>] [Tensor(uid=1713,size=14), Tensor(uid=2083,size=28)] [Tensor(uid=2084,size=14)]\n",
      "[<operator-3526, matmul_v_branch_loadin>] None None\n",
      "[<operator-3527, matmul_v_merge>] None None\n",
      "[<operator-2088, matmul_v_backward>] [Tensor(uid=1711,size=128), Tensor(uid=1708,size=42), Tensor(uid=2084,size=14)] [Tensor(uid=2085,size=14), Tensor(uid=2086,size=128)]\n",
      "[<operator-2089, dropout_backward>] [Tensor(uid=1711,size=128), Tensor(uid=1712,size=64), Tensor(uid=2086,size=128)] [Tensor(uid=2087,size=128)]\n",
      "[<operator-3520, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3521, dropout_forward_merge>] None None\n",
      "[<operator-2090, softmax_backward>] [Tensor(uid=1710,size=128), Tensor(uid=2087,size=128)] [Tensor(uid=2088,size=128)]\n",
      "[<operator-2091, matmul_qk_backward>] [Tensor(uid=1708,size=42), Tensor(uid=2088,size=128)] [Tensor(uid=2089,size=28)]\n",
      "[<operator-3514, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3515, linear_qkv_merge>] None None\n",
      "[<operator-2092, linear_qkv_backward>] [Tensor(uid=1707,size=28), Tensor(uid=2085,size=14), Tensor(uid=2089,size=28)] [Tensor(uid=2090,size=28)]\n",
      "[<operator-2093, allreduce_backward>] [Tensor(uid=2090,size=28)] []\n",
      "[<operator-3538, add_forward_branch_loadin>] None None\n",
      "[<operator-3539, add_forward_merge>] None None\n",
      "[<operator-2094, layernorm_backward>] [Tensor(uid=1706,size=28), Tensor(uid=2090,size=28)] [Tensor(uid=2091,size=28)]\n",
      "[<operator-2095, backward_grad_accumulate_input>] [Tensor(uid=2091,size=28), Tensor(uid=2082,size=28)] []\n",
      "[<operator-2096, dropout_backward>] [Tensor(uid=1704,size=28), Tensor(uid=1705,size=14), Tensor(uid=2091,size=28)] [Tensor(uid=2092,size=28)]\n",
      "[<operator-3502, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3503, linear_2_forward_merge>] None None\n",
      "[<operator-2097, linear_2_backward>] [Tensor(uid=1702,size=56), Tensor(uid=2092,size=28)] [Tensor(uid=2093,size=56)]\n",
      "[<operator-3496, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3497, gelu_forward_merge>] None None\n",
      "[<operator-2098, gelu_backward>] [Tensor(uid=1701,size=56), Tensor(uid=2093,size=56)] [Tensor(uid=2094,size=56)]\n",
      "[<operator-3490, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3491, linear_1_forward_merge>] None None\n",
      "[<operator-2099, linear_1_backward>] [Tensor(uid=1700,size=28), Tensor(uid=2094,size=56)] [Tensor(uid=2095,size=28)]\n",
      "[<operator-2100, allreduce_backward>] [Tensor(uid=2095,size=28)] []\n",
      "[<operator-3508, add_forward_branch_loadin>] None None\n",
      "[<operator-3509, add_forward_merge>] None None\n",
      "[<operator-2101, layernorm_backward>] [Tensor(uid=1699,size=28), Tensor(uid=2095,size=28)] [Tensor(uid=2096,size=28)]\n",
      "[<operator-2102, backward_grad_accumulate_res1>] [Tensor(uid=2096,size=28), Tensor(uid=2091,size=28)] []\n",
      "[<operator-2103, output_dropout_backward>] [Tensor(uid=1697,size=28), Tensor(uid=1698,size=14), Tensor(uid=2096,size=28)] [Tensor(uid=2097,size=28)]\n",
      "[<operator-3478, linear_forward_branch_loadin>] None None\n",
      "[<operator-3479, linear_forward_merge>] None None\n",
      "[<operator-2104, linear_backward>] [Tensor(uid=1695,size=14), Tensor(uid=2097,size=28)] [Tensor(uid=2098,size=14)]\n",
      "[<operator-3472, matmul_v_branch_loadin>] None None\n",
      "[<operator-3473, matmul_v_merge>] None None\n",
      "[<operator-2105, matmul_v_backward>] [Tensor(uid=1693,size=128), Tensor(uid=1690,size=42), Tensor(uid=2098,size=14)] [Tensor(uid=2099,size=14), Tensor(uid=2100,size=128)]\n",
      "[<operator-2106, dropout_backward>] [Tensor(uid=1693,size=128), Tensor(uid=1694,size=64), Tensor(uid=2100,size=128)] [Tensor(uid=2101,size=128)]\n",
      "[<operator-3466, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3467, dropout_forward_merge>] None None\n",
      "[<operator-2107, softmax_backward>] [Tensor(uid=1692,size=128), Tensor(uid=2101,size=128)] [Tensor(uid=2102,size=128)]\n",
      "[<operator-2108, matmul_qk_backward>] [Tensor(uid=1690,size=42), Tensor(uid=2102,size=128)] [Tensor(uid=2103,size=28)]\n",
      "[<operator-3460, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3461, linear_qkv_merge>] None None\n",
      "[<operator-2109, linear_qkv_backward>] [Tensor(uid=1689,size=28), Tensor(uid=2099,size=14), Tensor(uid=2103,size=28)] [Tensor(uid=2104,size=28)]\n",
      "[<operator-2110, allreduce_backward>] [Tensor(uid=2104,size=28)] []\n",
      "[<operator-3484, add_forward_branch_loadin>] None None\n",
      "[<operator-3485, add_forward_merge>] None None\n",
      "[<operator-2111, layernorm_backward>] [Tensor(uid=1688,size=28), Tensor(uid=2104,size=28)] [Tensor(uid=2105,size=28)]\n",
      "[<operator-2112, backward_grad_accumulate_input>] [Tensor(uid=2105,size=28), Tensor(uid=2096,size=28)] []\n",
      "[<operator-2113, dropout_backward>] [Tensor(uid=1686,size=28), Tensor(uid=1687,size=14), Tensor(uid=2105,size=28)] [Tensor(uid=2106,size=28)]\n",
      "[<operator-3448, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3449, linear_2_forward_merge>] None None\n",
      "[<operator-2114, linear_2_backward>] [Tensor(uid=1684,size=56), Tensor(uid=2106,size=28)] [Tensor(uid=2107,size=56)]\n",
      "[<operator-3442, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3443, gelu_forward_merge>] None None\n",
      "[<operator-2115, gelu_backward>] [Tensor(uid=1683,size=56), Tensor(uid=2107,size=56)] [Tensor(uid=2108,size=56)]\n",
      "[<operator-3436, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3437, linear_1_forward_merge>] None None\n",
      "[<operator-2116, linear_1_backward>] [Tensor(uid=1682,size=28), Tensor(uid=2108,size=56)] [Tensor(uid=2109,size=28)]\n",
      "[<operator-2117, allreduce_backward>] [Tensor(uid=2109,size=28)] []\n",
      "[<operator-3454, add_forward_branch_loadin>] None None\n",
      "[<operator-3455, add_forward_merge>] None None\n",
      "[<operator-2118, layernorm_backward>] [Tensor(uid=1681,size=28), Tensor(uid=2109,size=28)] [Tensor(uid=2110,size=28)]\n",
      "[<operator-2119, backward_grad_accumulate_res1>] [Tensor(uid=2110,size=28), Tensor(uid=2105,size=28)] []\n",
      "[<operator-2120, output_dropout_backward>] [Tensor(uid=1679,size=28), Tensor(uid=1680,size=14), Tensor(uid=2110,size=28)] [Tensor(uid=2111,size=28)]\n",
      "[<operator-3424, linear_forward_branch_loadin>] None None\n",
      "[<operator-3425, linear_forward_merge>] None None\n",
      "[<operator-2121, linear_backward>] [Tensor(uid=1677,size=14), Tensor(uid=2111,size=28)] [Tensor(uid=2112,size=14)]\n",
      "[<operator-3418, matmul_v_branch_loadin>] None None\n",
      "[<operator-3419, matmul_v_merge>] None None\n",
      "[<operator-2122, matmul_v_backward>] [Tensor(uid=1675,size=128), Tensor(uid=1672,size=42), Tensor(uid=2112,size=14)] [Tensor(uid=2113,size=14), Tensor(uid=2114,size=128)]\n",
      "[<operator-2123, dropout_backward>] [Tensor(uid=1675,size=128), Tensor(uid=1676,size=64), Tensor(uid=2114,size=128)] [Tensor(uid=2115,size=128)]\n",
      "[<operator-3412, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3413, dropout_forward_merge>] None None\n",
      "[<operator-2124, softmax_backward>] [Tensor(uid=1674,size=128), Tensor(uid=2115,size=128)] [Tensor(uid=2116,size=128)]\n",
      "[<operator-2125, matmul_qk_backward>] [Tensor(uid=1672,size=42), Tensor(uid=2116,size=128)] [Tensor(uid=2117,size=28)]\n",
      "[<operator-3406, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3407, linear_qkv_merge>] None None\n",
      "[<operator-2126, linear_qkv_backward>] [Tensor(uid=1671,size=28), Tensor(uid=2113,size=14), Tensor(uid=2117,size=28)] [Tensor(uid=2118,size=28)]\n",
      "[<operator-2127, allreduce_backward>] [Tensor(uid=2118,size=28)] []\n",
      "[<operator-3430, add_forward_branch_loadin>] None None\n",
      "[<operator-3431, add_forward_merge>] None None\n",
      "[<operator-2128, layernorm_backward>] [Tensor(uid=1670,size=28), Tensor(uid=2118,size=28)] [Tensor(uid=2119,size=28)]\n",
      "[<operator-2129, backward_grad_accumulate_input>] [Tensor(uid=2119,size=28), Tensor(uid=2110,size=28)] []\n",
      "[<operator-2130, dropout_backward>] [Tensor(uid=1668,size=28), Tensor(uid=1669,size=14), Tensor(uid=2119,size=28)] [Tensor(uid=2120,size=28)]\n",
      "[<operator-3394, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3395, linear_2_forward_merge>] None None\n",
      "[<operator-2131, linear_2_backward>] [Tensor(uid=1666,size=56), Tensor(uid=2120,size=28)] [Tensor(uid=2121,size=56)]\n",
      "[<operator-3388, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3389, gelu_forward_merge>] None None\n",
      "[<operator-2132, gelu_backward>] [Tensor(uid=1665,size=56), Tensor(uid=2121,size=56)] [Tensor(uid=2122,size=56)]\n",
      "[<operator-3382, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3383, linear_1_forward_merge>] None None\n",
      "[<operator-2133, linear_1_backward>] [Tensor(uid=1664,size=28), Tensor(uid=2122,size=56)] [Tensor(uid=2123,size=28)]\n",
      "[<operator-2134, allreduce_backward>] [Tensor(uid=2123,size=28)] []\n",
      "[<operator-3400, add_forward_branch_loadin>] None None\n",
      "[<operator-3401, add_forward_merge>] None None\n",
      "[<operator-2135, layernorm_backward>] [Tensor(uid=1663,size=28), Tensor(uid=2123,size=28)] [Tensor(uid=2124,size=28)]\n",
      "[<operator-2136, backward_grad_accumulate_res1>] [Tensor(uid=2124,size=28), Tensor(uid=2119,size=28)] []\n",
      "[<operator-2137, output_dropout_backward>] [Tensor(uid=1661,size=28), Tensor(uid=1662,size=14), Tensor(uid=2124,size=28)] [Tensor(uid=2125,size=28)]\n",
      "[<operator-3370, linear_forward_branch_loadin>] None None\n",
      "[<operator-3371, linear_forward_merge>] None None\n",
      "[<operator-2138, linear_backward>] [Tensor(uid=1659,size=14), Tensor(uid=2125,size=28)] [Tensor(uid=2126,size=14)]\n",
      "[<operator-3364, matmul_v_branch_loadin>] None None\n",
      "[<operator-3365, matmul_v_merge>] None None\n",
      "[<operator-2139, matmul_v_backward>] [Tensor(uid=1657,size=128), Tensor(uid=1654,size=42), Tensor(uid=2126,size=14)] [Tensor(uid=2127,size=14), Tensor(uid=2128,size=128)]\n",
      "[<operator-2140, dropout_backward>] [Tensor(uid=1657,size=128), Tensor(uid=1658,size=64), Tensor(uid=2128,size=128)] [Tensor(uid=2129,size=128)]\n",
      "[<operator-3358, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3359, dropout_forward_merge>] None None\n",
      "[<operator-2141, softmax_backward>] [Tensor(uid=1656,size=128), Tensor(uid=2129,size=128)] [Tensor(uid=2130,size=128)]\n",
      "[<operator-2142, matmul_qk_backward>] [Tensor(uid=1654,size=42), Tensor(uid=2130,size=128)] [Tensor(uid=2131,size=28)]\n",
      "[<operator-3352, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3353, linear_qkv_merge>] None None\n",
      "[<operator-2143, linear_qkv_backward>] [Tensor(uid=1653,size=28), Tensor(uid=2127,size=14), Tensor(uid=2131,size=28)] [Tensor(uid=2132,size=28)]\n",
      "[<operator-2144, allreduce_backward>] [Tensor(uid=2132,size=28)] []\n",
      "[<operator-3376, add_forward_branch_loadin>] None None\n",
      "[<operator-3377, add_forward_merge>] None None\n",
      "[<operator-2145, layernorm_backward>] [Tensor(uid=1652,size=28), Tensor(uid=2132,size=28)] [Tensor(uid=2133,size=28)]\n",
      "[<operator-2146, backward_grad_accumulate_input>] [Tensor(uid=2133,size=28), Tensor(uid=2124,size=28)] []\n",
      "[<operator-2147, dropout_backward>] [Tensor(uid=1650,size=28), Tensor(uid=1651,size=14), Tensor(uid=2133,size=28)] [Tensor(uid=2134,size=28)]\n",
      "[<operator-3340, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3341, linear_2_forward_merge>] None None\n",
      "[<operator-2148, linear_2_backward>] [Tensor(uid=1648,size=56), Tensor(uid=2134,size=28)] [Tensor(uid=2135,size=56)]\n",
      "[<operator-3334, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3335, gelu_forward_merge>] None None\n",
      "[<operator-2149, gelu_backward>] [Tensor(uid=1647,size=56), Tensor(uid=2135,size=56)] [Tensor(uid=2136,size=56)]\n",
      "[<operator-3328, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3329, linear_1_forward_merge>] None None\n",
      "[<operator-2150, linear_1_backward>] [Tensor(uid=1646,size=28), Tensor(uid=2136,size=56)] [Tensor(uid=2137,size=28)]\n",
      "[<operator-2151, allreduce_backward>] [Tensor(uid=2137,size=28)] []\n",
      "[<operator-3346, add_forward_branch_loadin>] None None\n",
      "[<operator-3347, add_forward_merge>] None None\n",
      "[<operator-2152, layernorm_backward>] [Tensor(uid=1645,size=28), Tensor(uid=2137,size=28)] [Tensor(uid=2138,size=28)]\n",
      "[<operator-2153, backward_grad_accumulate_res1>] [Tensor(uid=2138,size=28), Tensor(uid=2133,size=28)] []\n",
      "[<operator-2154, output_dropout_backward>] [Tensor(uid=1643,size=28), Tensor(uid=1644,size=14), Tensor(uid=2138,size=28)] [Tensor(uid=2139,size=28)]\n",
      "[<operator-3316, linear_forward_branch_loadin>] None None\n",
      "[<operator-3317, linear_forward_merge>] None None\n",
      "[<operator-2155, linear_backward>] [Tensor(uid=1641,size=14), Tensor(uid=2139,size=28)] [Tensor(uid=2140,size=14)]\n",
      "[<operator-3310, matmul_v_branch_loadin>] None None\n",
      "[<operator-3311, matmul_v_merge>] None None\n",
      "[<operator-2156, matmul_v_backward>] [Tensor(uid=1639,size=128), Tensor(uid=1636,size=42), Tensor(uid=2140,size=14)] [Tensor(uid=2141,size=14), Tensor(uid=2142,size=128)]\n",
      "[<operator-2157, dropout_backward>] [Tensor(uid=1639,size=128), Tensor(uid=1640,size=64), Tensor(uid=2142,size=128)] [Tensor(uid=2143,size=128)]\n",
      "[<operator-3304, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3305, dropout_forward_merge>] None None\n",
      "[<operator-2158, softmax_backward>] [Tensor(uid=1638,size=128), Tensor(uid=2143,size=128)] [Tensor(uid=2144,size=128)]\n",
      "[<operator-2159, matmul_qk_backward>] [Tensor(uid=1636,size=42), Tensor(uid=2144,size=128)] [Tensor(uid=2145,size=28)]\n",
      "[<operator-3298, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3299, linear_qkv_merge>] None None\n",
      "[<operator-2160, linear_qkv_backward>] [Tensor(uid=1635,size=28), Tensor(uid=2141,size=14), Tensor(uid=2145,size=28)] [Tensor(uid=2146,size=28)]\n",
      "[<operator-2161, allreduce_backward>] [Tensor(uid=2146,size=28)] []\n",
      "[<operator-3322, add_forward_branch_loadin>] None None\n",
      "[<operator-3323, add_forward_merge>] None None\n",
      "[<operator-2162, layernorm_backward>] [Tensor(uid=1634,size=28), Tensor(uid=2146,size=28)] [Tensor(uid=2147,size=28)]\n",
      "[<operator-2163, backward_grad_accumulate_input>] [Tensor(uid=2147,size=28), Tensor(uid=2138,size=28)] []\n",
      "[<operator-2164, dropout_backward>] [Tensor(uid=1632,size=28), Tensor(uid=1633,size=14), Tensor(uid=2147,size=28)] [Tensor(uid=2148,size=28)]\n",
      "[<operator-3286, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3287, linear_2_forward_merge>] None None\n",
      "[<operator-2165, linear_2_backward>] [Tensor(uid=1630,size=56), Tensor(uid=2148,size=28)] [Tensor(uid=2149,size=56)]\n",
      "[<operator-3280, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3281, gelu_forward_merge>] None None\n",
      "[<operator-2166, gelu_backward>] [Tensor(uid=1629,size=56), Tensor(uid=2149,size=56)] [Tensor(uid=2150,size=56)]\n",
      "[<operator-3274, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3275, linear_1_forward_merge>] None None\n",
      "[<operator-2167, linear_1_backward>] [Tensor(uid=1628,size=28), Tensor(uid=2150,size=56)] [Tensor(uid=2151,size=28)]\n",
      "[<operator-2168, allreduce_backward>] [Tensor(uid=2151,size=28)] []\n",
      "[<operator-3292, add_forward_branch_loadin>] None None\n",
      "[<operator-3293, add_forward_merge>] None None\n",
      "[<operator-2169, layernorm_backward>] [Tensor(uid=1627,size=28), Tensor(uid=2151,size=28)] [Tensor(uid=2152,size=28)]\n",
      "[<operator-2170, backward_grad_accumulate_res1>] [Tensor(uid=2152,size=28), Tensor(uid=2147,size=28)] []\n",
      "[<operator-2171, output_dropout_backward>] [Tensor(uid=1625,size=28), Tensor(uid=1626,size=14), Tensor(uid=2152,size=28)] [Tensor(uid=2153,size=28)]\n",
      "[<operator-3262, linear_forward_branch_loadin>] None None\n",
      "[<operator-3263, linear_forward_merge>] None None\n",
      "[<operator-2172, linear_backward>] [Tensor(uid=1623,size=14), Tensor(uid=2153,size=28)] [Tensor(uid=2154,size=14)]\n",
      "[<operator-3256, matmul_v_branch_loadin>] None None\n",
      "[<operator-3257, matmul_v_merge>] None None\n",
      "[<operator-2173, matmul_v_backward>] [Tensor(uid=1621,size=128), Tensor(uid=1618,size=42), Tensor(uid=2154,size=14)] [Tensor(uid=2155,size=14), Tensor(uid=2156,size=128)]\n",
      "[<operator-2174, dropout_backward>] [Tensor(uid=1621,size=128), Tensor(uid=1622,size=64), Tensor(uid=2156,size=128)] [Tensor(uid=2157,size=128)]\n",
      "[<operator-3250, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3251, dropout_forward_merge>] None None\n",
      "[<operator-2175, softmax_backward>] [Tensor(uid=1620,size=128), Tensor(uid=2157,size=128)] [Tensor(uid=2158,size=128)]\n",
      "[<operator-2176, matmul_qk_backward>] [Tensor(uid=1618,size=42), Tensor(uid=2158,size=128)] [Tensor(uid=2159,size=28)]\n",
      "[<operator-3244, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3245, linear_qkv_merge>] None None\n",
      "[<operator-2177, linear_qkv_backward>] [Tensor(uid=1617,size=28), Tensor(uid=2155,size=14), Tensor(uid=2159,size=28)] [Tensor(uid=2160,size=28)]\n",
      "[<operator-2178, allreduce_backward>] [Tensor(uid=2160,size=28)] []\n",
      "[<operator-3268, add_forward_branch_loadin>] None None\n",
      "[<operator-3269, add_forward_merge>] None None\n",
      "[<operator-2179, layernorm_backward>] [Tensor(uid=1616,size=28), Tensor(uid=2160,size=28)] [Tensor(uid=2161,size=28)]\n",
      "[<operator-2180, backward_grad_accumulate_input>] [Tensor(uid=2161,size=28), Tensor(uid=2152,size=28)] []\n",
      "[<operator-2181, dropout_backward>] [Tensor(uid=1614,size=28), Tensor(uid=1615,size=14), Tensor(uid=2161,size=28)] [Tensor(uid=2162,size=28)]\n",
      "[<operator-3232, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3233, linear_2_forward_merge>] None None\n",
      "[<operator-2182, linear_2_backward>] [Tensor(uid=1612,size=56), Tensor(uid=2162,size=28)] [Tensor(uid=2163,size=56)]\n",
      "[<operator-3226, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3227, gelu_forward_merge>] None None\n",
      "[<operator-2183, gelu_backward>] [Tensor(uid=1611,size=56), Tensor(uid=2163,size=56)] [Tensor(uid=2164,size=56)]\n",
      "[<operator-3220, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3221, linear_1_forward_merge>] None None\n",
      "[<operator-2184, linear_1_backward>] [Tensor(uid=1610,size=28), Tensor(uid=2164,size=56)] [Tensor(uid=2165,size=28)]\n",
      "[<operator-2185, allreduce_backward>] [Tensor(uid=2165,size=28)] []\n",
      "[<operator-3238, add_forward_branch_loadin>] None None\n",
      "[<operator-3239, add_forward_merge>] None None\n",
      "[<operator-2186, layernorm_backward>] [Tensor(uid=1609,size=28), Tensor(uid=2165,size=28)] [Tensor(uid=2166,size=28)]\n",
      "[<operator-2187, backward_grad_accumulate_res1>] [Tensor(uid=2166,size=28), Tensor(uid=2161,size=28)] []\n",
      "[<operator-2188, output_dropout_backward>] [Tensor(uid=1607,size=28), Tensor(uid=1608,size=14), Tensor(uid=2166,size=28)] [Tensor(uid=2167,size=28)]\n",
      "[<operator-3208, linear_forward_branch_loadin>] None None\n",
      "[<operator-3209, linear_forward_merge>] None None\n",
      "[<operator-2189, linear_backward>] [Tensor(uid=1605,size=14), Tensor(uid=2167,size=28)] [Tensor(uid=2168,size=14)]\n",
      "[<operator-3202, matmul_v_branch_loadin>] None None\n",
      "[<operator-3203, matmul_v_merge>] None None\n",
      "[<operator-2190, matmul_v_backward>] [Tensor(uid=1603,size=128), Tensor(uid=1600,size=42), Tensor(uid=2168,size=14)] [Tensor(uid=2169,size=14), Tensor(uid=2170,size=128)]\n",
      "[<operator-2191, dropout_backward>] [Tensor(uid=1603,size=128), Tensor(uid=1604,size=64), Tensor(uid=2170,size=128)] [Tensor(uid=2171,size=128)]\n",
      "[<operator-3196, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3197, dropout_forward_merge>] None None\n",
      "[<operator-2192, softmax_backward>] [Tensor(uid=1602,size=128), Tensor(uid=2171,size=128)] [Tensor(uid=2172,size=128)]\n",
      "[<operator-2193, matmul_qk_backward>] [Tensor(uid=1600,size=42), Tensor(uid=2172,size=128)] [Tensor(uid=2173,size=28)]\n",
      "[<operator-3190, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3191, linear_qkv_merge>] None None\n",
      "[<operator-2194, linear_qkv_backward>] [Tensor(uid=1599,size=28), Tensor(uid=2169,size=14), Tensor(uid=2173,size=28)] [Tensor(uid=2174,size=28)]\n",
      "[<operator-2195, allreduce_backward>] [Tensor(uid=2174,size=28)] []\n",
      "[<operator-3214, add_forward_branch_loadin>] None None\n",
      "[<operator-3215, add_forward_merge>] None None\n",
      "[<operator-2196, layernorm_backward>] [Tensor(uid=1598,size=28), Tensor(uid=2174,size=28)] [Tensor(uid=2175,size=28)]\n",
      "[<operator-2197, backward_grad_accumulate_input>] [Tensor(uid=2175,size=28), Tensor(uid=2166,size=28)] []\n",
      "[<operator-2198, dropout_backward>] [Tensor(uid=1596,size=28), Tensor(uid=1597,size=14), Tensor(uid=2175,size=28)] [Tensor(uid=2176,size=28)]\n",
      "[<operator-3178, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3179, linear_2_forward_merge>] None None\n",
      "[<operator-2199, linear_2_backward>] [Tensor(uid=1594,size=56), Tensor(uid=2176,size=28)] [Tensor(uid=2177,size=56)]\n",
      "[<operator-3172, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3173, gelu_forward_merge>] None None\n",
      "[<operator-2200, gelu_backward>] [Tensor(uid=1593,size=56), Tensor(uid=2177,size=56)] [Tensor(uid=2178,size=56)]\n",
      "[<operator-3166, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3167, linear_1_forward_merge>] None None\n",
      "[<operator-2201, linear_1_backward>] [Tensor(uid=1592,size=28), Tensor(uid=2178,size=56)] [Tensor(uid=2179,size=28)]\n",
      "[<operator-2202, allreduce_backward>] [Tensor(uid=2179,size=28)] []\n",
      "[<operator-3184, add_forward_branch_loadin>] None None\n",
      "[<operator-3185, add_forward_merge>] None None\n",
      "[<operator-2203, layernorm_backward>] [Tensor(uid=1591,size=28), Tensor(uid=2179,size=28)] [Tensor(uid=2180,size=28)]\n",
      "[<operator-2204, backward_grad_accumulate_res1>] [Tensor(uid=2180,size=28), Tensor(uid=2175,size=28)] []\n",
      "[<operator-2205, output_dropout_backward>] [Tensor(uid=1589,size=28), Tensor(uid=1590,size=14), Tensor(uid=2180,size=28)] [Tensor(uid=2181,size=28)]\n",
      "[<operator-3154, linear_forward_branch_loadin>] None None\n",
      "[<operator-3155, linear_forward_merge>] None None\n",
      "[<operator-2206, linear_backward>] [Tensor(uid=1587,size=14), Tensor(uid=2181,size=28)] [Tensor(uid=2182,size=14)]\n",
      "[<operator-3148, matmul_v_branch_loadin>] None None\n",
      "[<operator-3149, matmul_v_merge>] None None\n",
      "[<operator-2207, matmul_v_backward>] [Tensor(uid=1585,size=128), Tensor(uid=1582,size=42), Tensor(uid=2182,size=14)] [Tensor(uid=2183,size=14), Tensor(uid=2184,size=128)]\n",
      "[<operator-2208, dropout_backward>] [Tensor(uid=1585,size=128), Tensor(uid=1586,size=64), Tensor(uid=2184,size=128)] [Tensor(uid=2185,size=128)]\n",
      "[<operator-3142, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3143, dropout_forward_merge>] None None\n",
      "[<operator-2209, softmax_backward>] [Tensor(uid=1584,size=128), Tensor(uid=2185,size=128)] [Tensor(uid=2186,size=128)]\n",
      "[<operator-2210, matmul_qk_backward>] [Tensor(uid=1582,size=42), Tensor(uid=2186,size=128)] [Tensor(uid=2187,size=28)]\n",
      "[<operator-3136, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3137, linear_qkv_merge>] None None\n",
      "[<operator-2211, linear_qkv_backward>] [Tensor(uid=1581,size=28), Tensor(uid=2183,size=14), Tensor(uid=2187,size=28)] [Tensor(uid=2188,size=28)]\n",
      "[<operator-2212, allreduce_backward>] [Tensor(uid=2188,size=28)] []\n",
      "[<operator-3160, add_forward_branch_loadin>] None None\n",
      "[<operator-3161, add_forward_merge>] None None\n",
      "[<operator-2213, layernorm_backward>] [Tensor(uid=1580,size=28), Tensor(uid=2188,size=28)] [Tensor(uid=2189,size=28)]\n",
      "[<operator-2214, backward_grad_accumulate_input>] [Tensor(uid=2189,size=28), Tensor(uid=2180,size=28)] []\n",
      "[<operator-2215, dropout_backward>] [Tensor(uid=1578,size=28), Tensor(uid=1579,size=14), Tensor(uid=2189,size=28)] [Tensor(uid=2190,size=28)]\n",
      "[<operator-3124, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3125, linear_2_forward_merge>] None None\n",
      "[<operator-2216, linear_2_backward>] [Tensor(uid=1576,size=56), Tensor(uid=2190,size=28)] [Tensor(uid=2191,size=56)]\n",
      "[<operator-3118, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3119, gelu_forward_merge>] None None\n",
      "[<operator-2217, gelu_backward>] [Tensor(uid=1575,size=56), Tensor(uid=2191,size=56)] [Tensor(uid=2192,size=56)]\n",
      "[<operator-3112, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3113, linear_1_forward_merge>] None None\n",
      "[<operator-2218, linear_1_backward>] [Tensor(uid=1574,size=28), Tensor(uid=2192,size=56)] [Tensor(uid=2193,size=28)]\n",
      "[<operator-2219, allreduce_backward>] [Tensor(uid=2193,size=28)] []\n",
      "[<operator-3130, add_forward_branch_loadin>] None None\n",
      "[<operator-3131, add_forward_merge>] None None\n",
      "[<operator-2220, layernorm_backward>] [Tensor(uid=1573,size=28), Tensor(uid=2193,size=28)] [Tensor(uid=2194,size=28)]\n",
      "[<operator-2221, backward_grad_accumulate_res1>] [Tensor(uid=2194,size=28), Tensor(uid=2189,size=28)] []\n",
      "[<operator-2222, output_dropout_backward>] [Tensor(uid=1571,size=28), Tensor(uid=1572,size=14), Tensor(uid=2194,size=28)] [Tensor(uid=2195,size=28)]\n",
      "[<operator-3100, linear_forward_branch_loadin>] None None\n",
      "[<operator-3101, linear_forward_merge>] None None\n",
      "[<operator-2223, linear_backward>] [Tensor(uid=1569,size=14), Tensor(uid=2195,size=28)] [Tensor(uid=2196,size=14)]\n",
      "[<operator-3094, matmul_v_branch_loadin>] None None\n",
      "[<operator-3095, matmul_v_merge>] None None\n",
      "[<operator-2224, matmul_v_backward>] [Tensor(uid=1567,size=128), Tensor(uid=1564,size=42), Tensor(uid=2196,size=14)] [Tensor(uid=2197,size=14), Tensor(uid=2198,size=128)]\n",
      "[<operator-2225, dropout_backward>] [Tensor(uid=1567,size=128), Tensor(uid=1568,size=64), Tensor(uid=2198,size=128)] [Tensor(uid=2199,size=128)]\n",
      "[<operator-3088, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3089, dropout_forward_merge>] None None\n",
      "[<operator-2226, softmax_backward>] [Tensor(uid=1566,size=128), Tensor(uid=2199,size=128)] [Tensor(uid=2200,size=128)]\n",
      "[<operator-2227, matmul_qk_backward>] [Tensor(uid=1564,size=42), Tensor(uid=2200,size=128)] [Tensor(uid=2201,size=28)]\n",
      "[<operator-3082, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3083, linear_qkv_merge>] None None\n",
      "[<operator-2228, linear_qkv_backward>] [Tensor(uid=1563,size=28), Tensor(uid=2197,size=14), Tensor(uid=2201,size=28)] [Tensor(uid=2202,size=28)]\n",
      "[<operator-2229, allreduce_backward>] [Tensor(uid=2202,size=28)] []\n",
      "[<operator-3106, add_forward_branch_loadin>] None None\n",
      "[<operator-3107, add_forward_merge>] None None\n",
      "[<operator-2230, layernorm_backward>] [Tensor(uid=1562,size=28), Tensor(uid=2202,size=28)] [Tensor(uid=2203,size=28)]\n",
      "[<operator-2231, backward_grad_accumulate_input>] [Tensor(uid=2203,size=28), Tensor(uid=2194,size=28)] []\n",
      "[<operator-2232, dropout_backward>] [Tensor(uid=1560,size=28), Tensor(uid=1561,size=14), Tensor(uid=2203,size=28)] [Tensor(uid=2204,size=28)]\n",
      "[<operator-3070, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3071, linear_2_forward_merge>] None None\n",
      "[<operator-2233, linear_2_backward>] [Tensor(uid=1558,size=56), Tensor(uid=2204,size=28)] [Tensor(uid=2205,size=56)]\n",
      "[<operator-3064, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3065, gelu_forward_merge>] None None\n",
      "[<operator-2234, gelu_backward>] [Tensor(uid=1557,size=56), Tensor(uid=2205,size=56)] [Tensor(uid=2206,size=56)]\n",
      "[<operator-3058, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3059, linear_1_forward_merge>] None None\n",
      "[<operator-2235, linear_1_backward>] [Tensor(uid=1556,size=28), Tensor(uid=2206,size=56)] [Tensor(uid=2207,size=28)]\n",
      "[<operator-2236, allreduce_backward>] [Tensor(uid=2207,size=28)] []\n",
      "[<operator-3076, add_forward_branch_loadin>] None None\n",
      "[<operator-3077, add_forward_merge>] None None\n",
      "[<operator-2237, layernorm_backward>] [Tensor(uid=1555,size=28), Tensor(uid=2207,size=28)] [Tensor(uid=2208,size=28)]\n",
      "[<operator-2238, backward_grad_accumulate_res1>] [Tensor(uid=2208,size=28), Tensor(uid=2203,size=28)] []\n",
      "[<operator-2239, output_dropout_backward>] [Tensor(uid=1553,size=28), Tensor(uid=1554,size=14), Tensor(uid=2208,size=28)] [Tensor(uid=2209,size=28)]\n",
      "[<operator-3046, linear_forward_branch_loadin>] None None\n",
      "[<operator-3047, linear_forward_merge>] None None\n",
      "[<operator-2240, linear_backward>] [Tensor(uid=1551,size=14), Tensor(uid=2209,size=28)] [Tensor(uid=2210,size=14)]\n",
      "[<operator-3040, matmul_v_branch_loadin>] None None\n",
      "[<operator-3041, matmul_v_merge>] None None\n",
      "[<operator-2241, matmul_v_backward>] [Tensor(uid=1549,size=128), Tensor(uid=1546,size=42), Tensor(uid=2210,size=14)] [Tensor(uid=2211,size=14), Tensor(uid=2212,size=128)]\n",
      "[<operator-2242, dropout_backward>] [Tensor(uid=1549,size=128), Tensor(uid=1550,size=64), Tensor(uid=2212,size=128)] [Tensor(uid=2213,size=128)]\n",
      "[<operator-3034, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3035, dropout_forward_merge>] None None\n",
      "[<operator-2243, softmax_backward>] [Tensor(uid=1548,size=128), Tensor(uid=2213,size=128)] [Tensor(uid=2214,size=128)]\n",
      "[<operator-2244, matmul_qk_backward>] [Tensor(uid=1546,size=42), Tensor(uid=2214,size=128)] [Tensor(uid=2215,size=28)]\n",
      "[<operator-3028, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3029, linear_qkv_merge>] None None\n",
      "[<operator-2245, linear_qkv_backward>] [Tensor(uid=1545,size=28), Tensor(uid=2211,size=14), Tensor(uid=2215,size=28)] [Tensor(uid=2216,size=28)]\n",
      "[<operator-2246, allreduce_backward>] [Tensor(uid=2216,size=28)] []\n",
      "[<operator-3052, add_forward_branch_loadin>] None None\n",
      "[<operator-3053, add_forward_merge>] None None\n",
      "[<operator-2247, layernorm_backward>] [Tensor(uid=1544,size=28), Tensor(uid=2216,size=28)] [Tensor(uid=2217,size=28)]\n",
      "[<operator-2248, backward_grad_accumulate_input>] [Tensor(uid=2217,size=28), Tensor(uid=2208,size=28)] []\n",
      "[<operator-2249, dropout_backward>] [Tensor(uid=1542,size=28), Tensor(uid=1543,size=14), Tensor(uid=2217,size=28)] [Tensor(uid=2218,size=28)]\n",
      "[<operator-3016, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3017, linear_2_forward_merge>] None None\n",
      "[<operator-2250, linear_2_backward>] [Tensor(uid=1540,size=56), Tensor(uid=2218,size=28)] [Tensor(uid=2219,size=56)]\n",
      "[<operator-3010, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3011, gelu_forward_merge>] None None\n",
      "[<operator-2251, gelu_backward>] [Tensor(uid=1539,size=56), Tensor(uid=2219,size=56)] [Tensor(uid=2220,size=56)]\n",
      "[<operator-3004, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3005, linear_1_forward_merge>] None None\n",
      "[<operator-2252, linear_1_backward>] [Tensor(uid=1538,size=28), Tensor(uid=2220,size=56)] [Tensor(uid=2221,size=28)]\n",
      "[<operator-2253, allreduce_backward>] [Tensor(uid=2221,size=28)] []\n",
      "[<operator-3022, add_forward_branch_loadin>] None None\n",
      "[<operator-3023, add_forward_merge>] None None\n",
      "[<operator-2254, layernorm_backward>] [Tensor(uid=1537,size=28), Tensor(uid=2221,size=28)] [Tensor(uid=2222,size=28)]\n",
      "[<operator-2255, backward_grad_accumulate_res1>] [Tensor(uid=2222,size=28), Tensor(uid=2217,size=28)] []\n",
      "[<operator-2256, output_dropout_backward>] [Tensor(uid=1535,size=28), Tensor(uid=1536,size=14), Tensor(uid=2222,size=28)] [Tensor(uid=2223,size=28)]\n",
      "[<operator-2992, linear_forward_branch_loadin>] None None\n",
      "[<operator-2993, linear_forward_merge>] None None\n",
      "[<operator-2257, linear_backward>] [Tensor(uid=1533,size=14), Tensor(uid=2223,size=28)] [Tensor(uid=2224,size=14)]\n",
      "[<operator-2986, matmul_v_branch_loadin>] None None\n",
      "[<operator-2987, matmul_v_merge>] None None\n",
      "[<operator-2258, matmul_v_backward>] [Tensor(uid=1531,size=128), Tensor(uid=1528,size=42), Tensor(uid=2224,size=14)] [Tensor(uid=2225,size=14), Tensor(uid=2226,size=128)]\n",
      "[<operator-2259, dropout_backward>] [Tensor(uid=1531,size=128), Tensor(uid=1532,size=64), Tensor(uid=2226,size=128)] [Tensor(uid=2227,size=128)]\n",
      "[<operator-2980, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2981, dropout_forward_merge>] None None\n",
      "[<operator-2260, softmax_backward>] [Tensor(uid=1530,size=128), Tensor(uid=2227,size=128)] [Tensor(uid=2228,size=128)]\n",
      "[<operator-2261, matmul_qk_backward>] [Tensor(uid=1528,size=42), Tensor(uid=2228,size=128)] [Tensor(uid=2229,size=28)]\n",
      "[<operator-2974, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2975, linear_qkv_merge>] None None\n",
      "[<operator-2262, linear_qkv_backward>] [Tensor(uid=1527,size=28), Tensor(uid=2225,size=14), Tensor(uid=2229,size=28)] [Tensor(uid=2230,size=28)]\n",
      "[<operator-2263, allreduce_backward>] [Tensor(uid=2230,size=28)] []\n",
      "[<operator-2998, add_forward_branch_loadin>] None None\n",
      "[<operator-2999, add_forward_merge>] None None\n",
      "[<operator-2264, layernorm_backward>] [Tensor(uid=1526,size=28), Tensor(uid=2230,size=28)] [Tensor(uid=2231,size=28)]\n",
      "[<operator-2265, backward_grad_accumulate_input>] [Tensor(uid=2231,size=28), Tensor(uid=2222,size=28)] []\n",
      "[<operator-2266, dropout_backward>] [Tensor(uid=1524,size=28), Tensor(uid=1525,size=14), Tensor(uid=2231,size=28)] [Tensor(uid=2232,size=28)]\n",
      "[<operator-2962, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2963, linear_2_forward_merge>] None None\n",
      "[<operator-2267, linear_2_backward>] [Tensor(uid=1522,size=56), Tensor(uid=2232,size=28)] [Tensor(uid=2233,size=56)]\n",
      "[<operator-2956, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2957, gelu_forward_merge>] None None\n",
      "[<operator-2268, gelu_backward>] [Tensor(uid=1521,size=56), Tensor(uid=2233,size=56)] [Tensor(uid=2234,size=56)]\n",
      "[<operator-2950, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2951, linear_1_forward_merge>] None None\n",
      "[<operator-2269, linear_1_backward>] [Tensor(uid=1520,size=28), Tensor(uid=2234,size=56)] [Tensor(uid=2235,size=28)]\n",
      "[<operator-2270, allreduce_backward>] [Tensor(uid=2235,size=28)] []\n",
      "[<operator-2968, add_forward_branch_loadin>] None None\n",
      "[<operator-2969, add_forward_merge>] None None\n",
      "[<operator-2271, layernorm_backward>] [Tensor(uid=1519,size=28), Tensor(uid=2235,size=28)] [Tensor(uid=2236,size=28)]\n",
      "[<operator-2272, backward_grad_accumulate_res1>] [Tensor(uid=2236,size=28), Tensor(uid=2231,size=28)] []\n",
      "[<operator-2273, output_dropout_backward>] [Tensor(uid=1517,size=28), Tensor(uid=1518,size=14), Tensor(uid=2236,size=28)] [Tensor(uid=2237,size=28)]\n",
      "[<operator-2938, linear_forward_branch_loadin>] None None\n",
      "[<operator-2939, linear_forward_merge>] None None\n",
      "[<operator-2274, linear_backward>] [Tensor(uid=1515,size=14), Tensor(uid=2237,size=28)] [Tensor(uid=2238,size=14)]\n",
      "[<operator-2932, matmul_v_branch_loadin>] None None\n",
      "[<operator-2933, matmul_v_merge>] None None\n",
      "[<operator-2275, matmul_v_backward>] [Tensor(uid=1513,size=128), Tensor(uid=1510,size=42), Tensor(uid=2238,size=14)] [Tensor(uid=2239,size=14), Tensor(uid=2240,size=128)]\n",
      "[<operator-2276, dropout_backward>] [Tensor(uid=1513,size=128), Tensor(uid=1514,size=64), Tensor(uid=2240,size=128)] [Tensor(uid=2241,size=128)]\n",
      "[<operator-2926, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2927, dropout_forward_merge>] None None\n",
      "[<operator-2277, softmax_backward>] [Tensor(uid=1512,size=128), Tensor(uid=2241,size=128)] [Tensor(uid=2242,size=128)]\n",
      "[<operator-2278, matmul_qk_backward>] [Tensor(uid=1510,size=42), Tensor(uid=2242,size=128)] [Tensor(uid=2243,size=28)]\n",
      "[<operator-2920, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2921, linear_qkv_merge>] None None\n",
      "[<operator-2279, linear_qkv_backward>] [Tensor(uid=1509,size=28), Tensor(uid=2239,size=14), Tensor(uid=2243,size=28)] [Tensor(uid=2244,size=28)]\n",
      "[<operator-2280, allreduce_backward>] [Tensor(uid=2244,size=28)] []\n",
      "[<operator-2944, add_forward_branch_loadin>] None None\n",
      "[<operator-2945, add_forward_merge>] None None\n",
      "[<operator-2281, layernorm_backward>] [Tensor(uid=1508,size=28), Tensor(uid=2244,size=28)] [Tensor(uid=2245,size=28)]\n",
      "[<operator-2282, backward_grad_accumulate_input>] [Tensor(uid=2245,size=28), Tensor(uid=2236,size=28)] []\n",
      "[<operator-2283, dropout_backward>] [Tensor(uid=1506,size=28), Tensor(uid=1507,size=14), Tensor(uid=2245,size=28)] [Tensor(uid=2246,size=28)]\n",
      "[<operator-2908, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2909, linear_2_forward_merge>] None None\n",
      "[<operator-2284, linear_2_backward>] [Tensor(uid=1504,size=56), Tensor(uid=2246,size=28)] [Tensor(uid=2247,size=56)]\n",
      "[<operator-2902, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2903, gelu_forward_merge>] None None\n",
      "[<operator-2285, gelu_backward>] [Tensor(uid=1503,size=56), Tensor(uid=2247,size=56)] [Tensor(uid=2248,size=56)]\n",
      "[<operator-2896, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2897, linear_1_forward_merge>] None None\n",
      "[<operator-2286, linear_1_backward>] [Tensor(uid=1502,size=28), Tensor(uid=2248,size=56)] [Tensor(uid=2249,size=28)]\n",
      "[<operator-2287, allreduce_backward>] [Tensor(uid=2249,size=28)] []\n",
      "[<operator-2914, add_forward_branch_loadin>] None None\n",
      "[<operator-2915, add_forward_merge>] None None\n",
      "[<operator-2288, layernorm_backward>] [Tensor(uid=1501,size=28), Tensor(uid=2249,size=28)] [Tensor(uid=2250,size=28)]\n",
      "[<operator-2289, backward_grad_accumulate_res1>] [Tensor(uid=2250,size=28), Tensor(uid=2245,size=28)] []\n",
      "[<operator-2290, output_dropout_backward>] [Tensor(uid=1499,size=28), Tensor(uid=1500,size=14), Tensor(uid=2250,size=28)] [Tensor(uid=2251,size=28)]\n",
      "[<operator-2884, linear_forward_branch_loadin>] None None\n",
      "[<operator-2885, linear_forward_merge>] None None\n",
      "[<operator-2291, linear_backward>] [Tensor(uid=1497,size=14), Tensor(uid=2251,size=28)] [Tensor(uid=2252,size=14)]\n",
      "[<operator-2878, matmul_v_branch_loadin>] None None\n",
      "[<operator-2879, matmul_v_merge>] None None\n",
      "[<operator-2292, matmul_v_backward>] [Tensor(uid=1495,size=128), Tensor(uid=1492,size=42), Tensor(uid=2252,size=14)] [Tensor(uid=2253,size=14), Tensor(uid=2254,size=128)]\n",
      "[<operator-2293, dropout_backward>] [Tensor(uid=1495,size=128), Tensor(uid=1496,size=64), Tensor(uid=2254,size=128)] [Tensor(uid=2255,size=128)]\n",
      "[<operator-2872, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2873, dropout_forward_merge>] None None\n",
      "[<operator-2294, softmax_backward>] [Tensor(uid=1494,size=128), Tensor(uid=2255,size=128)] [Tensor(uid=2256,size=128)]\n",
      "[<operator-2295, matmul_qk_backward>] [Tensor(uid=1492,size=42), Tensor(uid=2256,size=128)] [Tensor(uid=2257,size=28)]\n",
      "[<operator-2866, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2867, linear_qkv_merge>] None None\n",
      "[<operator-2296, linear_qkv_backward>] [Tensor(uid=1491,size=28), Tensor(uid=2253,size=14), Tensor(uid=2257,size=28)] [Tensor(uid=2258,size=28)]\n",
      "[<operator-2297, allreduce_backward>] [Tensor(uid=2258,size=28)] []\n",
      "[<operator-2890, add_forward_branch_loadin>] None None\n",
      "[<operator-2891, add_forward_merge>] None None\n",
      "[<operator-2298, layernorm_backward>] [Tensor(uid=1490,size=28), Tensor(uid=2258,size=28)] [Tensor(uid=2259,size=28)]\n",
      "[<operator-2299, backward_grad_accumulate_input>] [Tensor(uid=2259,size=28), Tensor(uid=2250,size=28)] []\n",
      "[<operator-2300, dropout_backward>] [Tensor(uid=1488,size=28), Tensor(uid=1489,size=14), Tensor(uid=2259,size=28)] [Tensor(uid=2260,size=28)]\n",
      "[<operator-2854, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2855, linear_2_forward_merge>] None None\n",
      "[<operator-2301, linear_2_backward>] [Tensor(uid=1486,size=56), Tensor(uid=2260,size=28)] [Tensor(uid=2261,size=56)]\n",
      "[<operator-2848, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2849, gelu_forward_merge>] None None\n",
      "[<operator-2302, gelu_backward>] [Tensor(uid=1485,size=56), Tensor(uid=2261,size=56)] [Tensor(uid=2262,size=56)]\n",
      "[<operator-2842, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2843, linear_1_forward_merge>] None None\n",
      "[<operator-2303, linear_1_backward>] [Tensor(uid=1484,size=28), Tensor(uid=2262,size=56)] [Tensor(uid=2263,size=28)]\n",
      "[<operator-2304, allreduce_backward>] [Tensor(uid=2263,size=28)] []\n",
      "[<operator-2860, add_forward_branch_loadin>] None None\n",
      "[<operator-2861, add_forward_merge>] None None\n",
      "[<operator-2305, layernorm_backward>] [Tensor(uid=1483,size=28), Tensor(uid=2263,size=28)] [Tensor(uid=2264,size=28)]\n",
      "[<operator-2306, backward_grad_accumulate_res1>] [Tensor(uid=2264,size=28), Tensor(uid=2259,size=28)] []\n",
      "[<operator-2307, output_dropout_backward>] [Tensor(uid=1481,size=28), Tensor(uid=1482,size=14), Tensor(uid=2264,size=28)] [Tensor(uid=2265,size=28)]\n",
      "[<operator-2830, linear_forward_branch_loadin>] None None\n",
      "[<operator-2831, linear_forward_merge>] None None\n",
      "[<operator-2308, linear_backward>] [Tensor(uid=1479,size=14), Tensor(uid=2265,size=28)] [Tensor(uid=2266,size=14)]\n",
      "[<operator-2824, matmul_v_branch_loadin>] None None\n",
      "[<operator-2825, matmul_v_merge>] None None\n",
      "[<operator-2309, matmul_v_backward>] [Tensor(uid=1477,size=128), Tensor(uid=1474,size=42), Tensor(uid=2266,size=14)] [Tensor(uid=2267,size=14), Tensor(uid=2268,size=128)]\n",
      "[<operator-2310, dropout_backward>] [Tensor(uid=1477,size=128), Tensor(uid=1478,size=64), Tensor(uid=2268,size=128)] [Tensor(uid=2269,size=128)]\n",
      "[<operator-2818, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2819, dropout_forward_merge>] None None\n",
      "[<operator-2311, softmax_backward>] [Tensor(uid=1476,size=128), Tensor(uid=2269,size=128)] [Tensor(uid=2270,size=128)]\n",
      "[<operator-2312, matmul_qk_backward>] [Tensor(uid=1474,size=42), Tensor(uid=2270,size=128)] [Tensor(uid=2271,size=28)]\n",
      "[<operator-2812, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2813, linear_qkv_merge>] None None\n",
      "[<operator-2313, linear_qkv_backward>] [Tensor(uid=1473,size=28), Tensor(uid=2267,size=14), Tensor(uid=2271,size=28)] [Tensor(uid=2272,size=28)]\n",
      "[<operator-2314, allreduce_backward>] [Tensor(uid=2272,size=28)] []\n",
      "[<operator-2836, add_forward_branch_loadin>] None None\n",
      "[<operator-2837, add_forward_merge>] None None\n",
      "[<operator-2315, layernorm_backward>] [Tensor(uid=1472,size=28), Tensor(uid=2272,size=28)] [Tensor(uid=2273,size=28)]\n",
      "[<operator-2316, backward_grad_accumulate_input>] [Tensor(uid=2273,size=28), Tensor(uid=2264,size=28)] []\n",
      "[<operator-2317, dropout_backward>] [Tensor(uid=1470,size=28), Tensor(uid=1471,size=14), Tensor(uid=2273,size=28)] [Tensor(uid=2274,size=28)]\n",
      "[<operator-2800, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2801, linear_2_forward_merge>] None None\n",
      "[<operator-2318, linear_2_backward>] [Tensor(uid=1468,size=56), Tensor(uid=2274,size=28)] [Tensor(uid=2275,size=56)]\n",
      "[<operator-2794, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2795, gelu_forward_merge>] None None\n",
      "[<operator-2319, gelu_backward>] [Tensor(uid=1467,size=56), Tensor(uid=2275,size=56)] [Tensor(uid=2276,size=56)]\n",
      "[<operator-2788, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2789, linear_1_forward_merge>] None None\n",
      "[<operator-2320, linear_1_backward>] [Tensor(uid=1466,size=28), Tensor(uid=2276,size=56)] [Tensor(uid=2277,size=28)]\n",
      "[<operator-2321, allreduce_backward>] [Tensor(uid=2277,size=28)] []\n",
      "[<operator-2806, add_forward_branch_loadin>] None None\n",
      "[<operator-2807, add_forward_merge>] None None\n",
      "[<operator-2322, layernorm_backward>] [Tensor(uid=1465,size=28), Tensor(uid=2277,size=28)] [Tensor(uid=2278,size=28)]\n",
      "[<operator-2323, backward_grad_accumulate_res1>] [Tensor(uid=2278,size=28), Tensor(uid=2273,size=28)] []\n",
      "[<operator-2324, output_dropout_backward>] [Tensor(uid=1463,size=28), Tensor(uid=1464,size=14), Tensor(uid=2278,size=28)] [Tensor(uid=2279,size=28)]\n",
      "[<operator-2776, linear_forward_branch_loadin>] None None\n",
      "[<operator-2777, linear_forward_merge>] None None\n",
      "[<operator-2325, linear_backward>] [Tensor(uid=1461,size=14), Tensor(uid=2279,size=28)] [Tensor(uid=2280,size=14)]\n",
      "[<operator-2770, matmul_v_branch_loadin>] None None\n",
      "[<operator-2771, matmul_v_merge>] None None\n",
      "[<operator-2326, matmul_v_backward>] [Tensor(uid=1459,size=128), Tensor(uid=1456,size=42), Tensor(uid=2280,size=14)] [Tensor(uid=2281,size=14), Tensor(uid=2282,size=128)]\n",
      "[<operator-2327, dropout_backward>] [Tensor(uid=1459,size=128), Tensor(uid=1460,size=64), Tensor(uid=2282,size=128)] [Tensor(uid=2283,size=128)]\n",
      "[<operator-2764, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2765, dropout_forward_merge>] None None\n",
      "[<operator-2328, softmax_backward>] [Tensor(uid=1458,size=128), Tensor(uid=2283,size=128)] [Tensor(uid=2284,size=128)]\n",
      "[<operator-2329, matmul_qk_backward>] [Tensor(uid=1456,size=42), Tensor(uid=2284,size=128)] [Tensor(uid=2285,size=28)]\n",
      "[<operator-2758, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2759, linear_qkv_merge>] None None\n",
      "[<operator-2330, linear_qkv_backward>] [Tensor(uid=1455,size=28), Tensor(uid=2281,size=14), Tensor(uid=2285,size=28)] [Tensor(uid=2286,size=28)]\n",
      "[<operator-2331, allreduce_backward>] [Tensor(uid=2286,size=28)] []\n",
      "[<operator-2782, add_forward_branch_loadin>] None None\n",
      "[<operator-2783, add_forward_merge>] None None\n",
      "[<operator-2332, layernorm_backward>] [Tensor(uid=1454,size=28), Tensor(uid=2286,size=28)] [Tensor(uid=2287,size=28)]\n",
      "[<operator-2333, backward_grad_accumulate_input>] [Tensor(uid=2287,size=28), Tensor(uid=2278,size=28)] []\n",
      "[<operator-2334, dropout_backward>] [Tensor(uid=1452,size=28), Tensor(uid=1453,size=14), Tensor(uid=2287,size=28)] [Tensor(uid=2288,size=28)]\n",
      "[<operator-2746, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2747, linear_2_forward_merge>] None None\n",
      "[<operator-2335, linear_2_backward>] [Tensor(uid=1450,size=56), Tensor(uid=2288,size=28)] [Tensor(uid=2289,size=56)]\n",
      "[<operator-2740, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2741, gelu_forward_merge>] None None\n",
      "[<operator-2336, gelu_backward>] [Tensor(uid=1449,size=56), Tensor(uid=2289,size=56)] [Tensor(uid=2290,size=56)]\n",
      "[<operator-2734, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2735, linear_1_forward_merge>] None None\n",
      "[<operator-2337, linear_1_backward>] [Tensor(uid=1448,size=28), Tensor(uid=2290,size=56)] [Tensor(uid=2291,size=28)]\n",
      "[<operator-2338, allreduce_backward>] [Tensor(uid=2291,size=28)] []\n",
      "[<operator-2752, add_forward_branch_loadin>] None None\n",
      "[<operator-2753, add_forward_merge>] None None\n",
      "[<operator-2339, layernorm_backward>] [Tensor(uid=1447,size=28), Tensor(uid=2291,size=28)] [Tensor(uid=2292,size=28)]\n",
      "[<operator-2340, backward_grad_accumulate_res1>] [Tensor(uid=2292,size=28), Tensor(uid=2287,size=28)] []\n",
      "[<operator-2341, output_dropout_backward>] [Tensor(uid=1445,size=28), Tensor(uid=1446,size=14), Tensor(uid=2292,size=28)] [Tensor(uid=2293,size=28)]\n",
      "[<operator-2722, linear_forward_branch_loadin>] None None\n",
      "[<operator-2723, linear_forward_merge>] None None\n",
      "[<operator-2342, linear_backward>] [Tensor(uid=1443,size=14), Tensor(uid=2293,size=28)] [Tensor(uid=2294,size=14)]\n",
      "[<operator-2716, matmul_v_branch_loadin>] None None\n",
      "[<operator-2717, matmul_v_merge>] None None\n",
      "[<operator-2343, matmul_v_backward>] [Tensor(uid=1441,size=128), Tensor(uid=1438,size=42), Tensor(uid=2294,size=14)] [Tensor(uid=2295,size=14), Tensor(uid=2296,size=128)]\n",
      "[<operator-2344, dropout_backward>] [Tensor(uid=1441,size=128), Tensor(uid=1442,size=64), Tensor(uid=2296,size=128)] [Tensor(uid=2297,size=128)]\n",
      "[<operator-2710, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2711, dropout_forward_merge>] None None\n",
      "[<operator-2345, softmax_backward>] [Tensor(uid=1440,size=128), Tensor(uid=2297,size=128)] [Tensor(uid=2298,size=128)]\n",
      "[<operator-2346, matmul_qk_backward>] [Tensor(uid=1438,size=42), Tensor(uid=2298,size=128)] [Tensor(uid=2299,size=28)]\n",
      "[<operator-2704, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2705, linear_qkv_merge>] None None\n",
      "[<operator-2347, linear_qkv_backward>] [Tensor(uid=1437,size=28), Tensor(uid=2295,size=14), Tensor(uid=2299,size=28)] [Tensor(uid=2300,size=28)]\n",
      "[<operator-2348, allreduce_backward>] [Tensor(uid=2300,size=28)] []\n",
      "[<operator-2728, add_forward_branch_loadin>] None None\n",
      "[<operator-2729, add_forward_merge>] None None\n",
      "[<operator-2349, layernorm_backward>] [Tensor(uid=1436,size=28), Tensor(uid=2300,size=28)] [Tensor(uid=2301,size=28)]\n",
      "[<operator-2350, backward_grad_accumulate_input>] [Tensor(uid=2301,size=28), Tensor(uid=2292,size=28)] []\n",
      "[<operator-2351, dropout_backward>] [Tensor(uid=1434,size=28), Tensor(uid=1435,size=14), Tensor(uid=2301,size=28)] [Tensor(uid=2302,size=28)]\n",
      "[<operator-2692, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2693, linear_2_forward_merge>] None None\n",
      "[<operator-2352, linear_2_backward>] [Tensor(uid=1432,size=56), Tensor(uid=2302,size=28)] [Tensor(uid=2303,size=56)]\n",
      "[<operator-2686, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2687, gelu_forward_merge>] None None\n",
      "[<operator-2353, gelu_backward>] [Tensor(uid=1431,size=56), Tensor(uid=2303,size=56)] [Tensor(uid=2304,size=56)]\n",
      "[<operator-2680, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2681, linear_1_forward_merge>] None None\n",
      "[<operator-2354, linear_1_backward>] [Tensor(uid=1430,size=28), Tensor(uid=2304,size=56)] [Tensor(uid=2305,size=28)]\n",
      "[<operator-2355, allreduce_backward>] [Tensor(uid=2305,size=28)] []\n",
      "[<operator-2698, add_forward_branch_loadin>] None None\n",
      "[<operator-2699, add_forward_merge>] None None\n",
      "[<operator-2356, layernorm_backward>] [Tensor(uid=1429,size=28), Tensor(uid=2305,size=28)] [Tensor(uid=2306,size=28)]\n",
      "[<operator-2357, backward_grad_accumulate_res1>] [Tensor(uid=2306,size=28), Tensor(uid=2301,size=28)] []\n",
      "[<operator-2358, output_dropout_backward>] [Tensor(uid=1427,size=28), Tensor(uid=1428,size=14), Tensor(uid=2306,size=28)] [Tensor(uid=2307,size=28)]\n",
      "[<operator-2668, linear_forward_branch_loadin>] None None\n",
      "[<operator-2669, linear_forward_merge>] None None\n",
      "[<operator-2359, linear_backward>] [Tensor(uid=1425,size=14), Tensor(uid=2307,size=28)] [Tensor(uid=2308,size=14)]\n",
      "[<operator-2662, matmul_v_branch_loadin>] None None\n",
      "[<operator-2663, matmul_v_merge>] None None\n",
      "[<operator-2360, matmul_v_backward>] [Tensor(uid=1423,size=128), Tensor(uid=1420,size=42), Tensor(uid=2308,size=14)] [Tensor(uid=2309,size=14), Tensor(uid=2310,size=128)]\n",
      "[<operator-2361, dropout_backward>] [Tensor(uid=1423,size=128), Tensor(uid=1424,size=64), Tensor(uid=2310,size=128)] [Tensor(uid=2311,size=128)]\n",
      "[<operator-2656, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2657, dropout_forward_merge>] None None\n",
      "[<operator-2362, softmax_backward>] [Tensor(uid=1422,size=128), Tensor(uid=2311,size=128)] [Tensor(uid=2312,size=128)]\n",
      "[<operator-2363, matmul_qk_backward>] [Tensor(uid=1420,size=42), Tensor(uid=2312,size=128)] [Tensor(uid=2313,size=28)]\n",
      "[<operator-2650, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2651, linear_qkv_merge>] None None\n",
      "[<operator-2364, linear_qkv_backward>] [Tensor(uid=1419,size=28), Tensor(uid=2309,size=14), Tensor(uid=2313,size=28)] [Tensor(uid=2314,size=28)]\n",
      "[<operator-2365, allreduce_backward>] [Tensor(uid=2314,size=28)] []\n",
      "[<operator-2674, add_forward_branch_loadin>] None None\n",
      "[<operator-2675, add_forward_merge>] None None\n",
      "[<operator-2366, layernorm_backward>] [Tensor(uid=1418,size=28), Tensor(uid=2314,size=28)] [Tensor(uid=2315,size=28)]\n",
      "[<operator-2367, backward_grad_accumulate_input>] [Tensor(uid=2315,size=28), Tensor(uid=2306,size=28)] []\n",
      "[<operator-2368, dropout_backward>] [Tensor(uid=1416,size=28), Tensor(uid=1417,size=14), Tensor(uid=2315,size=28)] [Tensor(uid=2316,size=28)]\n",
      "[<operator-2638, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2639, linear_2_forward_merge>] None None\n",
      "[<operator-2369, linear_2_backward>] [Tensor(uid=1414,size=56), Tensor(uid=2316,size=28)] [Tensor(uid=2317,size=56)]\n",
      "[<operator-2632, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2633, gelu_forward_merge>] None None\n",
      "[<operator-2370, gelu_backward>] [Tensor(uid=1413,size=56), Tensor(uid=2317,size=56)] [Tensor(uid=2318,size=56)]\n",
      "[<operator-2626, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2627, linear_1_forward_merge>] None None\n",
      "[<operator-2371, linear_1_backward>] [Tensor(uid=1412,size=28), Tensor(uid=2318,size=56)] [Tensor(uid=2319,size=28)]\n",
      "[<operator-2372, allreduce_backward>] [Tensor(uid=2319,size=28)] []\n",
      "[<operator-2644, add_forward_branch_loadin>] None None\n",
      "[<operator-2645, add_forward_merge>] None None\n",
      "[<operator-2373, layernorm_backward>] [Tensor(uid=1411,size=28), Tensor(uid=2319,size=28)] [Tensor(uid=2320,size=28)]\n",
      "[<operator-2374, backward_grad_accumulate_res1>] [Tensor(uid=2320,size=28), Tensor(uid=2315,size=28)] []\n",
      "[<operator-2375, output_dropout_backward>] [Tensor(uid=1409,size=28), Tensor(uid=1410,size=14), Tensor(uid=2320,size=28)] [Tensor(uid=2321,size=28)]\n",
      "[<operator-2614, linear_forward_branch_loadin>] None None\n",
      "[<operator-2615, linear_forward_merge>] None None\n",
      "[<operator-2376, linear_backward>] [Tensor(uid=1407,size=14), Tensor(uid=2321,size=28)] [Tensor(uid=2322,size=14)]\n",
      "[<operator-2608, matmul_v_branch_loadin>] None None\n",
      "[<operator-2609, matmul_v_merge>] None None\n",
      "[<operator-2377, matmul_v_backward>] [Tensor(uid=1405,size=128), Tensor(uid=1402,size=42), Tensor(uid=2322,size=14)] [Tensor(uid=2323,size=14), Tensor(uid=2324,size=128)]\n",
      "[<operator-2378, dropout_backward>] [Tensor(uid=1405,size=128), Tensor(uid=1406,size=64), Tensor(uid=2324,size=128)] [Tensor(uid=2325,size=128)]\n",
      "[<operator-2602, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2603, dropout_forward_merge>] None None\n",
      "[<operator-2379, softmax_backward>] [Tensor(uid=1404,size=128), Tensor(uid=2325,size=128)] [Tensor(uid=2326,size=128)]\n",
      "[<operator-2380, matmul_qk_backward>] [Tensor(uid=1402,size=42), Tensor(uid=2326,size=128)] [Tensor(uid=2327,size=28)]\n",
      "[<operator-2596, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2597, linear_qkv_merge>] None None\n",
      "[<operator-2381, linear_qkv_backward>] [Tensor(uid=1401,size=28), Tensor(uid=2323,size=14), Tensor(uid=2327,size=28)] [Tensor(uid=2328,size=28)]\n",
      "[<operator-2382, allreduce_backward>] [Tensor(uid=2328,size=28)] []\n",
      "[<operator-2620, add_forward_branch_loadin>] None None\n",
      "[<operator-2621, add_forward_merge>] None None\n",
      "[<operator-2383, layernorm_backward>] [Tensor(uid=1400,size=28), Tensor(uid=2328,size=28)] [Tensor(uid=2329,size=28)]\n",
      "[<operator-2384, backward_grad_accumulate_input>] [Tensor(uid=2329,size=28), Tensor(uid=2320,size=28)] []\n",
      "[<operator-2385, dropout_backward>] [Tensor(uid=1398,size=28), Tensor(uid=1399,size=14), Tensor(uid=2329,size=28)] [Tensor(uid=2330,size=28)]\n",
      "[<operator-2584, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2585, linear_2_forward_merge>] None None\n",
      "[<operator-2386, linear_2_backward>] [Tensor(uid=1396,size=56), Tensor(uid=2330,size=28)] [Tensor(uid=2331,size=56)]\n",
      "[<operator-2578, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2579, gelu_forward_merge>] None None\n",
      "[<operator-2387, gelu_backward>] [Tensor(uid=1395,size=56), Tensor(uid=2331,size=56)] [Tensor(uid=2332,size=56)]\n",
      "[<operator-2572, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2573, linear_1_forward_merge>] None None\n",
      "[<operator-2388, linear_1_backward>] [Tensor(uid=1394,size=28), Tensor(uid=2332,size=56)] [Tensor(uid=2333,size=28)]\n",
      "[<operator-2389, allreduce_backward>] [Tensor(uid=2333,size=28)] []\n",
      "[<operator-2590, add_forward_branch_loadin>] None None\n",
      "[<operator-2591, add_forward_merge>] None None\n",
      "[<operator-2390, layernorm_backward>] [Tensor(uid=1393,size=28), Tensor(uid=2333,size=28)] [Tensor(uid=2334,size=28)]\n",
      "[<operator-2391, backward_grad_accumulate_res1>] [Tensor(uid=2334,size=28), Tensor(uid=2329,size=28)] []\n",
      "[<operator-2392, output_dropout_backward>] [Tensor(uid=1391,size=28), Tensor(uid=1392,size=14), Tensor(uid=2334,size=28)] [Tensor(uid=2335,size=28)]\n",
      "[<operator-2560, linear_forward_branch_loadin>] None None\n",
      "[<operator-2561, linear_forward_merge>] None None\n",
      "[<operator-2393, linear_backward>] [Tensor(uid=1389,size=14), Tensor(uid=2335,size=28)] [Tensor(uid=2336,size=14)]\n",
      "[<operator-2554, matmul_v_branch_loadin>] None None\n",
      "[<operator-2555, matmul_v_merge>] None None\n",
      "[<operator-2394, matmul_v_backward>] [Tensor(uid=1387,size=128), Tensor(uid=1384,size=42), Tensor(uid=2336,size=14)] [Tensor(uid=2337,size=14), Tensor(uid=2338,size=128)]\n",
      "[<operator-2395, dropout_backward>] [Tensor(uid=1387,size=128), Tensor(uid=1388,size=64), Tensor(uid=2338,size=128)] [Tensor(uid=2339,size=128)]\n",
      "[<operator-2548, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2549, dropout_forward_merge>] None None\n",
      "[<operator-2396, softmax_backward>] [Tensor(uid=1386,size=128), Tensor(uid=2339,size=128)] [Tensor(uid=2340,size=128)]\n",
      "[<operator-2397, matmul_qk_backward>] [Tensor(uid=1384,size=42), Tensor(uid=2340,size=128)] [Tensor(uid=2341,size=28)]\n",
      "[<operator-2542, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2543, linear_qkv_merge>] None None\n",
      "[<operator-2398, linear_qkv_backward>] [Tensor(uid=1383,size=28), Tensor(uid=2337,size=14), Tensor(uid=2341,size=28)] [Tensor(uid=2342,size=28)]\n",
      "[<operator-2399, allreduce_backward>] [Tensor(uid=2342,size=28)] []\n",
      "[<operator-2566, add_forward_branch_loadin>] None None\n",
      "[<operator-2567, add_forward_merge>] None None\n",
      "[<operator-2400, layernorm_backward>] [Tensor(uid=1382,size=28), Tensor(uid=2342,size=28)] [Tensor(uid=2343,size=28)]\n",
      "[<operator-2401, backward_grad_accumulate_input>] [Tensor(uid=2343,size=28), Tensor(uid=2334,size=28)] []\n",
      "[<operator-2402, dropout_backward>] [Tensor(uid=1380,size=28), Tensor(uid=1381,size=14), Tensor(uid=2343,size=28)] [Tensor(uid=2344,size=28)]\n",
      "[<operator-2530, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2531, linear_2_forward_merge>] None None\n",
      "[<operator-2403, linear_2_backward>] [Tensor(uid=1378,size=56), Tensor(uid=2344,size=28)] [Tensor(uid=2345,size=56)]\n",
      "[<operator-2524, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2525, gelu_forward_merge>] None None\n",
      "[<operator-2404, gelu_backward>] [Tensor(uid=1377,size=56), Tensor(uid=2345,size=56)] [Tensor(uid=2346,size=56)]\n",
      "[<operator-2518, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2519, linear_1_forward_merge>] None None\n",
      "[<operator-2405, linear_1_backward>] [Tensor(uid=1376,size=28), Tensor(uid=2346,size=56)] [Tensor(uid=2347,size=28)]\n",
      "[<operator-2406, allreduce_backward>] [Tensor(uid=2347,size=28)] []\n",
      "[<operator-2536, add_forward_branch_loadin>] None None\n",
      "[<operator-2537, add_forward_merge>] None None\n",
      "[<operator-2407, layernorm_backward>] [Tensor(uid=1375,size=28), Tensor(uid=2347,size=28)] [Tensor(uid=2348,size=28)]\n",
      "[<operator-2408, backward_grad_accumulate_res1>] [Tensor(uid=2348,size=28), Tensor(uid=2343,size=28)] []\n",
      "[<operator-2409, output_dropout_backward>] [Tensor(uid=1373,size=28), Tensor(uid=1374,size=14), Tensor(uid=2348,size=28)] [Tensor(uid=2349,size=28)]\n",
      "[<operator-2506, linear_forward_branch_loadin>] None None\n",
      "[<operator-2507, linear_forward_merge>] None None\n",
      "[<operator-2410, linear_backward>] [Tensor(uid=1371,size=14), Tensor(uid=2349,size=28)] [Tensor(uid=2350,size=14)]\n",
      "[<operator-2500, matmul_v_branch_loadin>] None None\n",
      "[<operator-2501, matmul_v_merge>] None None\n",
      "[<operator-2411, matmul_v_backward>] [Tensor(uid=1369,size=128), Tensor(uid=1366,size=42), Tensor(uid=2350,size=14)] [Tensor(uid=2351,size=14), Tensor(uid=2352,size=128)]\n",
      "[<operator-2412, dropout_backward>] [Tensor(uid=1369,size=128), Tensor(uid=1370,size=64), Tensor(uid=2352,size=128)] [Tensor(uid=2353,size=128)]\n",
      "[<operator-2494, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2495, dropout_forward_merge>] None None\n",
      "[<operator-2413, softmax_backward>] [Tensor(uid=1368,size=128), Tensor(uid=2353,size=128)] [Tensor(uid=2354,size=128)]\n",
      "[<operator-2414, matmul_qk_backward>] [Tensor(uid=1366,size=42), Tensor(uid=2354,size=128)] [Tensor(uid=2355,size=28)]\n",
      "[<operator-2488, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2489, linear_qkv_merge>] None None\n",
      "[<operator-2415, linear_qkv_backward>] [Tensor(uid=1365,size=28), Tensor(uid=2351,size=14), Tensor(uid=2355,size=28)] [Tensor(uid=2356,size=28)]\n",
      "[<operator-2416, allreduce_backward>] [Tensor(uid=2356,size=28)] []\n",
      "[<operator-2512, add_forward_branch_loadin>] None None\n",
      "[<operator-2513, add_forward_merge>] None None\n",
      "[<operator-2417, layernorm_backward>] [Tensor(uid=1364,size=28), Tensor(uid=2356,size=28)] [Tensor(uid=2357,size=28)]\n",
      "[<operator-2418, backward_grad_accumulate_input>] [Tensor(uid=2357,size=28), Tensor(uid=2348,size=28)] []\n",
      "[<operator-2419, dropout_backward>] [Tensor(uid=1362,size=28), Tensor(uid=1363,size=14), Tensor(uid=2357,size=28)] [Tensor(uid=2358,size=28)]\n",
      "[<operator-2476, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2477, linear_2_forward_merge>] None None\n",
      "[<operator-2420, linear_2_backward>] [Tensor(uid=1360,size=56), Tensor(uid=2358,size=28)] [Tensor(uid=2359,size=56)]\n",
      "[<operator-2470, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2471, gelu_forward_merge>] None None\n",
      "[<operator-2421, gelu_backward>] [Tensor(uid=1359,size=56), Tensor(uid=2359,size=56)] [Tensor(uid=2360,size=56)]\n",
      "[<operator-2464, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2465, linear_1_forward_merge>] None None\n",
      "[<operator-2422, linear_1_backward>] [Tensor(uid=1358,size=28), Tensor(uid=2360,size=56)] [Tensor(uid=2361,size=28)]\n",
      "[<operator-2423, allreduce_backward>] [Tensor(uid=2361,size=28)] []\n",
      "[<operator-2482, add_forward_branch_loadin>] None None\n",
      "[<operator-2483, add_forward_merge>] None None\n",
      "[<operator-2424, layernorm_backward>] [Tensor(uid=1357,size=28), Tensor(uid=2361,size=28)] [Tensor(uid=2362,size=28)]\n",
      "[<operator-2425, backward_grad_accumulate_res1>] [Tensor(uid=2362,size=28), Tensor(uid=2357,size=28)] []\n",
      "[<operator-2426, output_dropout_backward>] [Tensor(uid=1355,size=28), Tensor(uid=1356,size=14), Tensor(uid=2362,size=28)] [Tensor(uid=2363,size=28)]\n",
      "[<operator-2458, linear_forward_branch_loadin>] None None\n",
      "[<operator-2459, linear_forward_merge>] None None\n",
      "[<operator-2427, linear_backward>] [Tensor(uid=1353,size=14), Tensor(uid=2363,size=28)] [Tensor(uid=2364,size=14)]\n",
      "[<operator-2452, matmul_v_branch_loadin>] None None\n",
      "[<operator-2453, matmul_v_merge>] None None\n",
      "[<operator-2428, matmul_v_backward>] [Tensor(uid=1351,size=128), Tensor(uid=1348,size=42), Tensor(uid=2364,size=14)] [Tensor(uid=2365,size=14), Tensor(uid=2366,size=128)]\n",
      "[<operator-2429, dropout_backward>] [Tensor(uid=1351,size=128), Tensor(uid=1352,size=64), Tensor(uid=2366,size=128)] [Tensor(uid=2367,size=128)]\n",
      "[<operator-2446, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2447, dropout_forward_merge>] None None\n",
      "[<operator-2430, softmax_backward>] [Tensor(uid=1350,size=128), Tensor(uid=2367,size=128)] [Tensor(uid=2368,size=128)]\n",
      "[<operator-2431, matmul_qk_backward>] [Tensor(uid=1348,size=42), Tensor(uid=2368,size=128)] [Tensor(uid=2369,size=28)]\n",
      "[<operator-2440, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2441, linear_qkv_merge>] None None\n",
      "[<operator-2432, linear_qkv_backward>] [Tensor(uid=1347,size=28), Tensor(uid=2365,size=14), Tensor(uid=2369,size=28)] [Tensor(uid=2370,size=28)]\n",
      "[<operator-2433, allreduce_backward>] [Tensor(uid=2370,size=28)] []\n",
      "[<operator-2434, layernorm_backward>] [Tensor(uid=1218,size=28.0), Tensor(uid=2370,size=28)] [Tensor(uid=2371,size=28.0)]\n",
      "[<operator-2435, backward_grad_accumulate_input>] [Tensor(uid=2371,size=28.0), Tensor(uid=2362,size=28)] []\n"
     ]
    }
   ],
   "source": [
    "for _op in stream_0._flat_seq:\n",
    "        print([_op], \n",
    "              _op._input if isinstance(_op, FlattenOperator) else None,\n",
    "              _op._output if isinstance(_op, FlattenOperator) else None)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print(_interval_tot)\n",
    "# print(FlattenEngine()._interval_tot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_2_0_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
