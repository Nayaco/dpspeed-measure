{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2023, ISCS, Wenjie Zhang.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import argparse\n",
    "\n",
    "import builtins\n",
    "import datetime\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dsmeasure2.core.dsm_device_mng   import DeviceManager\n",
    "from dsmeasure2.core.dsm_operator_mng import OperatorManager\n",
    "\n",
    "from dsmeasure2.core.dsm_tensor   import AbstractTensor\n",
    "from dsmeasure2.core.dsm_device   import AbstractDeviceConfig, AbstractDevice\n",
    "from dsmeasure2.core.dsm_operator import AbstractOperatorConfig, \\\n",
    "                                         AbstractOperator, \\\n",
    "                                         OperatorComputationalConfig, \\\n",
    "                                         OperatorNonComputationalConfig , \\\n",
    "                                         OperatorCustomConfig , \\\n",
    "                                         OpStaticComputational , \\\n",
    "                                         OpStaticNonComputational, \\\n",
    "                                         OpStaticDerivative\n",
    "\n",
    "from dsmeasure2.device.device_cuda import DeviceCUDA, DeviceCUDAConfig\n",
    "from dsmeasure2.device.device_pcie import DevicePCIE4, DevicePCIEConfig\n",
    "\n",
    "from dsmeasure2.core.dsm_tensor_mng    import TensorManager\n",
    "from dsmeasure2.graph.tensor_define    import ActivationTensor, WeightTensor, TensorState\n",
    "from dsmeasure2.graph.operator_graph   import UnaryOperator, BinaryOperator, TernaryOperator, InitiateOperator\n",
    "from dsmeasure2.graph.unary_operator   import make_linear, make_layernorm, make_dropout, make_gelu, make_softmax\n",
    "from dsmeasure2.graph.binary_operator  import make_add, make_matmul\n",
    "from dsmeasure2.graph.operator_attn    import make_attn_tp, AttentionTPCRParallel, AttentionTPCRParallelBackward\n",
    "from dsmeasure2.graph.dsm2_transformer import make_ffn_gpt2, FeedForwardGPT2, FeedForwardGPT2Backward, \\\n",
    "                                              make_transformer_block, TransformerBlockGPT2, TransformerBlockGPT2Backward\n",
    "from dsmeasure2.graph.gpt2_sequence    import make_gpt_2\n",
    "from dsmeasure2.engine import CostEngine\n",
    "\n",
    "from dsmeasure2.flatten.flatten import flatten, convert_graph_to_flatten_seq\n",
    "from dsmeasure2.flatten.flatten_engine import FlattenEngine\n",
    "from dsmeasure2.flatten.flatten_stream import FlattenStream, stream_synchronize\n",
    "from dsmeasure2.flatten.flatten_offload import make_passive_offload\n",
    "from dsmeasure2.flatten.flatten_checkpoint import make_entire_checkpoint\n",
    "from dsmeasure2.flatten.flatten_operator import FlattenInitiate, FlattenOperator\n",
    "TRANSFORMER_BLOCKS = 32\n",
    "gpt2 = make_gpt_2(\n",
    "        compute_time_linear_qkv=490,\n",
    "        compute_time_matmul_kq=214, \n",
    "        compute_time_sm=163,\n",
    "        compute_time_attention_dropout=286,\n",
    "        compute_time_matmul_v=191,\n",
    "        compute_time_linear=146,\n",
    "        compute_time_dropout_attn=140,\n",
    "\n",
    "        compute_time_linear_qkv_backward=340,\n",
    "        compute_time_matmul_kq_backward=531,\n",
    "        compute_time_sm_backward=212,\n",
    "        compute_time_attention_dropout_backward=248,\n",
    "        compute_time_matmul_v_backward=360,\n",
    "        compute_time_linear_backward=250,\n",
    "        compute_time_dropout_attn_backward=155,\n",
    "\n",
    "        compute_time_allreduce_attn=2200,\n",
    "\n",
    "        compute_time_linear_1=512,\n",
    "        compute_time_gelu=428,\n",
    "        compute_time_linear_2=483,\n",
    "        compute_time_dropout_ffn=75,\n",
    "        \n",
    "        compute_time_linear_1_backward=442,\n",
    "        compute_time_gelu_backward=210,\n",
    "        compute_time_linear_2_backward=100,\n",
    "        compute_time_dropout_ffn_backward=102,\n",
    "\n",
    "        compute_time_allreduce_ffn=2200,\n",
    "        \n",
    "        compute_time_layernorm_1=67,\n",
    "        compute_time_layernorm_2=67,\n",
    "        compute_time_residual_add_1=67,\n",
    "        compute_time_residual_add_2=67,\n",
    "\n",
    "        compute_time_layernorm_1_backward=236,\n",
    "        compute_time_layernorm_2_backward=236,\n",
    "\n",
    "        compute_time_loss_with_backward=20000,\n",
    "\n",
    "        batch_size=8,\n",
    "        seq_len=1024,\n",
    "        hidden_size=1792,\n",
    "        head_num=16,\n",
    "        head_hidden_size=112,\n",
    "        tensor_parallel=2,\n",
    "        precision=2,\n",
    "\n",
    "        transfomer_block_num=TRANSFORMER_BLOCKS,\n",
    "    )\n",
    "for _op in gpt2:\n",
    "        OperatorManager().register(_op)\n",
    "DeviceManager().register(DeviceCUDAConfig(memory_max_capacity=80000, memory_limit_capacity=80000))\n",
    "DeviceManager().register(DevicePCIEConfig())\n",
    "# CostEngine().evaluation(10, [_op._config.op_uid for _op in gpt2])\n",
    "seq2 = flatten([_op._config.op_uid for _op in gpt2], [0], False)\n",
    "seq2 = convert_graph_to_flatten_seq([_op._config.op_uid for _op in gpt2], [0])\n",
    "stream_0 = FlattenStream(seq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlattenEngine().evaluation([stream_0], 10)\n",
    "a = FlattenEngine()._cuda_mem_trace.copy()\n",
    "_ref_count = FlattenEngine()._tensor_ref_cnt.copy()\n",
    "_interval_tot = FlattenEngine()._interval_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL OFFLOAD (~1/2)\n",
    "offload_streams = []\n",
    "_i = 2\n",
    "_end = int(len(stream_0._flat_seq) / 2) - 1\n",
    "_tensor_seen = {}\n",
    "while _i < _end:\n",
    "    if isinstance(stream_0[_i], FlattenOperator) and 'backward' not in stream_0[_i]._config.op_name:\n",
    "        _T = stream_0[_i]._input[0]\n",
    "        if _T.tensor_uid not in _tensor_seen:\n",
    "            _tensor_seen[_T.tensor_uid] = 0\n",
    "        else:\n",
    "            _tensor_seen[_T.tensor_uid] += 1\n",
    "        if _tensor_seen[_T.tensor_uid] < len(_ref_count[_T.tensor_uid]) - 1 and \\\n",
    "            _ref_count[_T.tensor_uid][_tensor_seen[_T.tensor_uid] + 1] - _ref_count[_T.tensor_uid][_tensor_seen[_T.tensor_uid]] > _interval_tot / 3:\n",
    "            # if _T.tensor_uid == 1641:\n",
    "            #     print(_ref_count[_T.tensor_uid][_tensor_seen[_T.tensor_uid] + 1] - _ref_count[_T.tensor_uid][_tensor_seen[_T.tensor_uid]])\n",
    "            offload_streams.append(make_passive_offload(stream_0, _i, _T.tensor_uid))\n",
    "            _end += 1\n",
    "    _i += 1\n",
    "# stream_offload_linear_qkv_148 = make_passive_offload(stream_0, 2, 107)\n",
    "# FlattenEngine().evaluation([stream_0, stream_offload_linear_qkv_148], 10)\n",
    "# print(len(offload_streams))\n",
    "while _i < len(stream_0._flat_seq):\n",
    "    if stream_0[_i]._config.op_name == 'loss_fn':\n",
    "        break\n",
    "    _i += 1\n",
    "stream_synchronize(stream_0, offload_streams, _i)\n",
    "FlattenEngine().evaluation([stream_0, *offload_streams], 10, verbose=False)\n",
    "b = FlattenEngine()._cuda_mem_trace.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdb928d44c0>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FULL CHECKPOINT\n",
    "checkpoint_streams = []\n",
    "tot_length = len(stream_0._flat_seq)\n",
    "origin_indices = [(i*17+1,i*17+16,tot_length-(i*17+17)) for i in range(TRANSFORMER_BLOCKS-1)]\n",
    "# origin_indices = [(i*17+1,i*17+9,tot_length-(i*17+10)) for i in range(TRANSFORMER_BLOCKS)]\n",
    "# origin_indices = [(i*17+1,i*17+13,tot_length-(i*17+14)) for i in range(TRANSFORMER_BLOCKS)]\n",
    "origin_uids = [(stream_0[_indices[0]]._config.op_uid, \n",
    "                stream_0[_indices[1]]._config.op_uid, \n",
    "                stream_0[_indices[2]]._config.op_uid) for _indices in origin_indices]\n",
    "for _i, _indices in enumerate(origin_indices):\n",
    "    _indices_0 = [*_indices]\n",
    "    for _j in range(_indices_0[0], len(stream_0._flat_seq)):\n",
    "        if stream_0._flat_seq[_j]._config.op_uid == origin_uids[_i][0]:\n",
    "            _indices_0[0] = _j\n",
    "            break\n",
    "    for _j in range(_indices_0[1], len(stream_0._flat_seq)):\n",
    "        if stream_0._flat_seq[_j]._config.op_uid == origin_uids[_i][1]:\n",
    "            _indices_0[1] = _j\n",
    "            break\n",
    "    for _j in range(_indices_0[2], len(stream_0._flat_seq)):\n",
    "        if stream_0._flat_seq[_j]._config.op_uid == origin_uids[_i][2]:\n",
    "            _indices_0[2] = _j\n",
    "            break\n",
    "    checkpoint_streams.append(make_entire_checkpoint(stream_0, _indices_0[0], _indices_0[1], _indices_0[2]))\n",
    "\n",
    "_i = 0\n",
    "while _i < len(stream_0._flat_seq):\n",
    "    if stream_0[_i]._config.op_name == 'loss_fn':\n",
    "        break\n",
    "    _i += 1\n",
    "\n",
    "stream_synchronize(stream_0, checkpoint_streams, _i)\n",
    "\n",
    "# for _i, _op in enumerate(stream_0._flat_seq):\n",
    "#     print(_i, [_op], \n",
    "#             _op._input if isinstance(_op, FlattenOperator) else None,\n",
    "#             _op._output if isinstance(_op, FlattenOperator) else None)\n",
    "FlattenEngine().evaluation([stream_0, *checkpoint_streams], 10, verbose=False)\n",
    "b = FlattenEngine()._cuda_mem_trace.copy()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(100,40))\n",
    "plt.plot(list(range(len(FlattenEngine()._cuda_mem_trace))), FlattenEngine()._cuda_mem_trace, '.-', markersize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(100,40))\n",
    "plt.plot(list(range(len(FlattenEngine()._cuda_mem_trace))), FlattenEngine()._cuda_mem_trace, '.-', markersize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1f028d8280>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(100,40))\n",
    "plt.plot(list(range(len(a))), a, '.-', markersize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<operator-1346, init_fn>] None None\n",
      "[<operator-1347, layernorm_forward>] [Tensor(uid=1218,size=28.0)] [Tensor(uid=1347,size=28)]\n",
      "[<operator-1348, linear_qkv>] [Tensor(uid=1347,size=28)] [Tensor(uid=1348,size=42)]\n",
      "[<operator-2439, linear_qkv_branch_offload>] None None\n",
      "[<operator-1349, matmul_qk>] [Tensor(uid=1348,size=42)] [Tensor(uid=1349,size=128)]\n",
      "[<operator-1350, softmax_forward>] [Tensor(uid=1349,size=128)] [Tensor(uid=1350,size=128)]\n",
      "[<operator-1351, dropout_forward>] [Tensor(uid=1350,size=128)] [Tensor(uid=1351,size=128), Tensor(uid=1352,size=64)]\n",
      "[<operator-2445, dropout_forward_branch_offload>] None None\n",
      "[<operator-1352, matmul_v>] [Tensor(uid=1351,size=128), Tensor(uid=1348,size=42)] [Tensor(uid=1353,size=14)]\n",
      "[<operator-2451, matmul_v_branch_offload>] None None\n",
      "[<operator-1353, linear_forward>] [Tensor(uid=1353,size=14)] [Tensor(uid=1354,size=28)]\n",
      "[<operator-2457, linear_forward_branch_offload>] None None\n",
      "[<operator-1354, allreduce_forward>] [Tensor(uid=1354,size=28)] []\n",
      "[<operator-1355, output_dropout>] [Tensor(uid=1354,size=28)] [Tensor(uid=1355,size=28), Tensor(uid=1356,size=14)]\n",
      "[<operator-1356, add_forward>] [Tensor(uid=1218,size=28.0), Tensor(uid=1355,size=28)] [Tensor(uid=1357,size=28)]\n",
      "[<operator-1357, layernorm_forward>] [Tensor(uid=1357,size=28)] [Tensor(uid=1358,size=28)]\n",
      "[<operator-1358, linear_1_forward>] [Tensor(uid=1358,size=28)] [Tensor(uid=1359,size=56)]\n",
      "[<operator-2463, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1359, gelu_forward>] [Tensor(uid=1359,size=56)] [Tensor(uid=1360,size=56)]\n",
      "[<operator-2469, gelu_forward_branch_offload>] None None\n",
      "[<operator-1360, linear_2_forward>] [Tensor(uid=1360,size=56)] [Tensor(uid=1361,size=28)]\n",
      "[<operator-2475, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1361, allreduce_forward>] [Tensor(uid=1361,size=28)] []\n",
      "[<operator-1362, dropout_forward>] [Tensor(uid=1361,size=28)] [Tensor(uid=1362,size=28), Tensor(uid=1363,size=14)]\n",
      "[<operator-1363, add_forward>] [Tensor(uid=1357,size=28), Tensor(uid=1362,size=28)] [Tensor(uid=1364,size=28)]\n",
      "[<operator-2481, add_forward_branch_offload>] None None\n",
      "[<operator-1364, layernorm_forward>] [Tensor(uid=1364,size=28)] [Tensor(uid=1365,size=28)]\n",
      "[<operator-1365, linear_qkv>] [Tensor(uid=1365,size=28)] [Tensor(uid=1366,size=42)]\n",
      "[<operator-2487, linear_qkv_branch_offload>] None None\n",
      "[<operator-1366, matmul_qk>] [Tensor(uid=1366,size=42)] [Tensor(uid=1367,size=128)]\n",
      "[<operator-1367, softmax_forward>] [Tensor(uid=1367,size=128)] [Tensor(uid=1368,size=128)]\n",
      "[<operator-1368, dropout_forward>] [Tensor(uid=1368,size=128)] [Tensor(uid=1369,size=128), Tensor(uid=1370,size=64)]\n",
      "[<operator-2493, dropout_forward_branch_offload>] None None\n",
      "[<operator-1369, matmul_v>] [Tensor(uid=1369,size=128), Tensor(uid=1366,size=42)] [Tensor(uid=1371,size=14)]\n",
      "[<operator-2499, matmul_v_branch_offload>] None None\n",
      "[<operator-1370, linear_forward>] [Tensor(uid=1371,size=14)] [Tensor(uid=1372,size=28)]\n",
      "[<operator-2505, linear_forward_branch_offload>] None None\n",
      "[<operator-1371, allreduce_forward>] [Tensor(uid=1372,size=28)] []\n",
      "[<operator-1372, output_dropout>] [Tensor(uid=1372,size=28)] [Tensor(uid=1373,size=28), Tensor(uid=1374,size=14)]\n",
      "[<operator-1373, add_forward>] [Tensor(uid=1364,size=28), Tensor(uid=1373,size=28)] [Tensor(uid=1375,size=28)]\n",
      "[<operator-2511, add_forward_branch_offload>] None None\n",
      "[<operator-1374, layernorm_forward>] [Tensor(uid=1375,size=28)] [Tensor(uid=1376,size=28)]\n",
      "[<operator-1375, linear_1_forward>] [Tensor(uid=1376,size=28)] [Tensor(uid=1377,size=56)]\n",
      "[<operator-2517, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1376, gelu_forward>] [Tensor(uid=1377,size=56)] [Tensor(uid=1378,size=56)]\n",
      "[<operator-2523, gelu_forward_branch_offload>] None None\n",
      "[<operator-1377, linear_2_forward>] [Tensor(uid=1378,size=56)] [Tensor(uid=1379,size=28)]\n",
      "[<operator-2529, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1378, allreduce_forward>] [Tensor(uid=1379,size=28)] []\n",
      "[<operator-1379, dropout_forward>] [Tensor(uid=1379,size=28)] [Tensor(uid=1380,size=28), Tensor(uid=1381,size=14)]\n",
      "[<operator-1380, add_forward>] [Tensor(uid=1375,size=28), Tensor(uid=1380,size=28)] [Tensor(uid=1382,size=28)]\n",
      "[<operator-2535, add_forward_branch_offload>] None None\n",
      "[<operator-1381, layernorm_forward>] [Tensor(uid=1382,size=28)] [Tensor(uid=1383,size=28)]\n",
      "[<operator-1382, linear_qkv>] [Tensor(uid=1383,size=28)] [Tensor(uid=1384,size=42)]\n",
      "[<operator-2541, linear_qkv_branch_offload>] None None\n",
      "[<operator-1383, matmul_qk>] [Tensor(uid=1384,size=42)] [Tensor(uid=1385,size=128)]\n",
      "[<operator-1384, softmax_forward>] [Tensor(uid=1385,size=128)] [Tensor(uid=1386,size=128)]\n",
      "[<operator-1385, dropout_forward>] [Tensor(uid=1386,size=128)] [Tensor(uid=1387,size=128), Tensor(uid=1388,size=64)]\n",
      "[<operator-2547, dropout_forward_branch_offload>] None None\n",
      "[<operator-1386, matmul_v>] [Tensor(uid=1387,size=128), Tensor(uid=1384,size=42)] [Tensor(uid=1389,size=14)]\n",
      "[<operator-2553, matmul_v_branch_offload>] None None\n",
      "[<operator-1387, linear_forward>] [Tensor(uid=1389,size=14)] [Tensor(uid=1390,size=28)]\n",
      "[<operator-2559, linear_forward_branch_offload>] None None\n",
      "[<operator-1388, allreduce_forward>] [Tensor(uid=1390,size=28)] []\n",
      "[<operator-1389, output_dropout>] [Tensor(uid=1390,size=28)] [Tensor(uid=1391,size=28), Tensor(uid=1392,size=14)]\n",
      "[<operator-1390, add_forward>] [Tensor(uid=1382,size=28), Tensor(uid=1391,size=28)] [Tensor(uid=1393,size=28)]\n",
      "[<operator-2565, add_forward_branch_offload>] None None\n",
      "[<operator-1391, layernorm_forward>] [Tensor(uid=1393,size=28)] [Tensor(uid=1394,size=28)]\n",
      "[<operator-1392, linear_1_forward>] [Tensor(uid=1394,size=28)] [Tensor(uid=1395,size=56)]\n",
      "[<operator-2571, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1393, gelu_forward>] [Tensor(uid=1395,size=56)] [Tensor(uid=1396,size=56)]\n",
      "[<operator-2577, gelu_forward_branch_offload>] None None\n",
      "[<operator-1394, linear_2_forward>] [Tensor(uid=1396,size=56)] [Tensor(uid=1397,size=28)]\n",
      "[<operator-2583, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1395, allreduce_forward>] [Tensor(uid=1397,size=28)] []\n",
      "[<operator-1396, dropout_forward>] [Tensor(uid=1397,size=28)] [Tensor(uid=1398,size=28), Tensor(uid=1399,size=14)]\n",
      "[<operator-1397, add_forward>] [Tensor(uid=1393,size=28), Tensor(uid=1398,size=28)] [Tensor(uid=1400,size=28)]\n",
      "[<operator-2589, add_forward_branch_offload>] None None\n",
      "[<operator-1398, layernorm_forward>] [Tensor(uid=1400,size=28)] [Tensor(uid=1401,size=28)]\n",
      "[<operator-1399, linear_qkv>] [Tensor(uid=1401,size=28)] [Tensor(uid=1402,size=42)]\n",
      "[<operator-2595, linear_qkv_branch_offload>] None None\n",
      "[<operator-1400, matmul_qk>] [Tensor(uid=1402,size=42)] [Tensor(uid=1403,size=128)]\n",
      "[<operator-1401, softmax_forward>] [Tensor(uid=1403,size=128)] [Tensor(uid=1404,size=128)]\n",
      "[<operator-1402, dropout_forward>] [Tensor(uid=1404,size=128)] [Tensor(uid=1405,size=128), Tensor(uid=1406,size=64)]\n",
      "[<operator-2601, dropout_forward_branch_offload>] None None\n",
      "[<operator-1403, matmul_v>] [Tensor(uid=1405,size=128), Tensor(uid=1402,size=42)] [Tensor(uid=1407,size=14)]\n",
      "[<operator-2607, matmul_v_branch_offload>] None None\n",
      "[<operator-1404, linear_forward>] [Tensor(uid=1407,size=14)] [Tensor(uid=1408,size=28)]\n",
      "[<operator-2613, linear_forward_branch_offload>] None None\n",
      "[<operator-1405, allreduce_forward>] [Tensor(uid=1408,size=28)] []\n",
      "[<operator-1406, output_dropout>] [Tensor(uid=1408,size=28)] [Tensor(uid=1409,size=28), Tensor(uid=1410,size=14)]\n",
      "[<operator-1407, add_forward>] [Tensor(uid=1400,size=28), Tensor(uid=1409,size=28)] [Tensor(uid=1411,size=28)]\n",
      "[<operator-2619, add_forward_branch_offload>] None None\n",
      "[<operator-1408, layernorm_forward>] [Tensor(uid=1411,size=28)] [Tensor(uid=1412,size=28)]\n",
      "[<operator-1409, linear_1_forward>] [Tensor(uid=1412,size=28)] [Tensor(uid=1413,size=56)]\n",
      "[<operator-2625, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1410, gelu_forward>] [Tensor(uid=1413,size=56)] [Tensor(uid=1414,size=56)]\n",
      "[<operator-2631, gelu_forward_branch_offload>] None None\n",
      "[<operator-1411, linear_2_forward>] [Tensor(uid=1414,size=56)] [Tensor(uid=1415,size=28)]\n",
      "[<operator-2637, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1412, allreduce_forward>] [Tensor(uid=1415,size=28)] []\n",
      "[<operator-1413, dropout_forward>] [Tensor(uid=1415,size=28)] [Tensor(uid=1416,size=28), Tensor(uid=1417,size=14)]\n",
      "[<operator-1414, add_forward>] [Tensor(uid=1411,size=28), Tensor(uid=1416,size=28)] [Tensor(uid=1418,size=28)]\n",
      "[<operator-2643, add_forward_branch_offload>] None None\n",
      "[<operator-1415, layernorm_forward>] [Tensor(uid=1418,size=28)] [Tensor(uid=1419,size=28)]\n",
      "[<operator-1416, linear_qkv>] [Tensor(uid=1419,size=28)] [Tensor(uid=1420,size=42)]\n",
      "[<operator-2649, linear_qkv_branch_offload>] None None\n",
      "[<operator-1417, matmul_qk>] [Tensor(uid=1420,size=42)] [Tensor(uid=1421,size=128)]\n",
      "[<operator-1418, softmax_forward>] [Tensor(uid=1421,size=128)] [Tensor(uid=1422,size=128)]\n",
      "[<operator-1419, dropout_forward>] [Tensor(uid=1422,size=128)] [Tensor(uid=1423,size=128), Tensor(uid=1424,size=64)]\n",
      "[<operator-2655, dropout_forward_branch_offload>] None None\n",
      "[<operator-1420, matmul_v>] [Tensor(uid=1423,size=128), Tensor(uid=1420,size=42)] [Tensor(uid=1425,size=14)]\n",
      "[<operator-2661, matmul_v_branch_offload>] None None\n",
      "[<operator-1421, linear_forward>] [Tensor(uid=1425,size=14)] [Tensor(uid=1426,size=28)]\n",
      "[<operator-2667, linear_forward_branch_offload>] None None\n",
      "[<operator-1422, allreduce_forward>] [Tensor(uid=1426,size=28)] []\n",
      "[<operator-1423, output_dropout>] [Tensor(uid=1426,size=28)] [Tensor(uid=1427,size=28), Tensor(uid=1428,size=14)]\n",
      "[<operator-1424, add_forward>] [Tensor(uid=1418,size=28), Tensor(uid=1427,size=28)] [Tensor(uid=1429,size=28)]\n",
      "[<operator-2673, add_forward_branch_offload>] None None\n",
      "[<operator-1425, layernorm_forward>] [Tensor(uid=1429,size=28)] [Tensor(uid=1430,size=28)]\n",
      "[<operator-1426, linear_1_forward>] [Tensor(uid=1430,size=28)] [Tensor(uid=1431,size=56)]\n",
      "[<operator-2679, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1427, gelu_forward>] [Tensor(uid=1431,size=56)] [Tensor(uid=1432,size=56)]\n",
      "[<operator-2685, gelu_forward_branch_offload>] None None\n",
      "[<operator-1428, linear_2_forward>] [Tensor(uid=1432,size=56)] [Tensor(uid=1433,size=28)]\n",
      "[<operator-2691, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1429, allreduce_forward>] [Tensor(uid=1433,size=28)] []\n",
      "[<operator-1430, dropout_forward>] [Tensor(uid=1433,size=28)] [Tensor(uid=1434,size=28), Tensor(uid=1435,size=14)]\n",
      "[<operator-1431, add_forward>] [Tensor(uid=1429,size=28), Tensor(uid=1434,size=28)] [Tensor(uid=1436,size=28)]\n",
      "[<operator-2697, add_forward_branch_offload>] None None\n",
      "[<operator-1432, layernorm_forward>] [Tensor(uid=1436,size=28)] [Tensor(uid=1437,size=28)]\n",
      "[<operator-1433, linear_qkv>] [Tensor(uid=1437,size=28)] [Tensor(uid=1438,size=42)]\n",
      "[<operator-2703, linear_qkv_branch_offload>] None None\n",
      "[<operator-1434, matmul_qk>] [Tensor(uid=1438,size=42)] [Tensor(uid=1439,size=128)]\n",
      "[<operator-1435, softmax_forward>] [Tensor(uid=1439,size=128)] [Tensor(uid=1440,size=128)]\n",
      "[<operator-1436, dropout_forward>] [Tensor(uid=1440,size=128)] [Tensor(uid=1441,size=128), Tensor(uid=1442,size=64)]\n",
      "[<operator-2709, dropout_forward_branch_offload>] None None\n",
      "[<operator-1437, matmul_v>] [Tensor(uid=1441,size=128), Tensor(uid=1438,size=42)] [Tensor(uid=1443,size=14)]\n",
      "[<operator-2715, matmul_v_branch_offload>] None None\n",
      "[<operator-1438, linear_forward>] [Tensor(uid=1443,size=14)] [Tensor(uid=1444,size=28)]\n",
      "[<operator-2721, linear_forward_branch_offload>] None None\n",
      "[<operator-1439, allreduce_forward>] [Tensor(uid=1444,size=28)] []\n",
      "[<operator-1440, output_dropout>] [Tensor(uid=1444,size=28)] [Tensor(uid=1445,size=28), Tensor(uid=1446,size=14)]\n",
      "[<operator-1441, add_forward>] [Tensor(uid=1436,size=28), Tensor(uid=1445,size=28)] [Tensor(uid=1447,size=28)]\n",
      "[<operator-2727, add_forward_branch_offload>] None None\n",
      "[<operator-1442, layernorm_forward>] [Tensor(uid=1447,size=28)] [Tensor(uid=1448,size=28)]\n",
      "[<operator-1443, linear_1_forward>] [Tensor(uid=1448,size=28)] [Tensor(uid=1449,size=56)]\n",
      "[<operator-2733, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1444, gelu_forward>] [Tensor(uid=1449,size=56)] [Tensor(uid=1450,size=56)]\n",
      "[<operator-2739, gelu_forward_branch_offload>] None None\n",
      "[<operator-1445, linear_2_forward>] [Tensor(uid=1450,size=56)] [Tensor(uid=1451,size=28)]\n",
      "[<operator-2745, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1446, allreduce_forward>] [Tensor(uid=1451,size=28)] []\n",
      "[<operator-1447, dropout_forward>] [Tensor(uid=1451,size=28)] [Tensor(uid=1452,size=28), Tensor(uid=1453,size=14)]\n",
      "[<operator-1448, add_forward>] [Tensor(uid=1447,size=28), Tensor(uid=1452,size=28)] [Tensor(uid=1454,size=28)]\n",
      "[<operator-2751, add_forward_branch_offload>] None None\n",
      "[<operator-1449, layernorm_forward>] [Tensor(uid=1454,size=28)] [Tensor(uid=1455,size=28)]\n",
      "[<operator-1450, linear_qkv>] [Tensor(uid=1455,size=28)] [Tensor(uid=1456,size=42)]\n",
      "[<operator-2757, linear_qkv_branch_offload>] None None\n",
      "[<operator-1451, matmul_qk>] [Tensor(uid=1456,size=42)] [Tensor(uid=1457,size=128)]\n",
      "[<operator-1452, softmax_forward>] [Tensor(uid=1457,size=128)] [Tensor(uid=1458,size=128)]\n",
      "[<operator-1453, dropout_forward>] [Tensor(uid=1458,size=128)] [Tensor(uid=1459,size=128), Tensor(uid=1460,size=64)]\n",
      "[<operator-2763, dropout_forward_branch_offload>] None None\n",
      "[<operator-1454, matmul_v>] [Tensor(uid=1459,size=128), Tensor(uid=1456,size=42)] [Tensor(uid=1461,size=14)]\n",
      "[<operator-2769, matmul_v_branch_offload>] None None\n",
      "[<operator-1455, linear_forward>] [Tensor(uid=1461,size=14)] [Tensor(uid=1462,size=28)]\n",
      "[<operator-2775, linear_forward_branch_offload>] None None\n",
      "[<operator-1456, allreduce_forward>] [Tensor(uid=1462,size=28)] []\n",
      "[<operator-1457, output_dropout>] [Tensor(uid=1462,size=28)] [Tensor(uid=1463,size=28), Tensor(uid=1464,size=14)]\n",
      "[<operator-1458, add_forward>] [Tensor(uid=1454,size=28), Tensor(uid=1463,size=28)] [Tensor(uid=1465,size=28)]\n",
      "[<operator-2781, add_forward_branch_offload>] None None\n",
      "[<operator-1459, layernorm_forward>] [Tensor(uid=1465,size=28)] [Tensor(uid=1466,size=28)]\n",
      "[<operator-1460, linear_1_forward>] [Tensor(uid=1466,size=28)] [Tensor(uid=1467,size=56)]\n",
      "[<operator-2787, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1461, gelu_forward>] [Tensor(uid=1467,size=56)] [Tensor(uid=1468,size=56)]\n",
      "[<operator-2793, gelu_forward_branch_offload>] None None\n",
      "[<operator-1462, linear_2_forward>] [Tensor(uid=1468,size=56)] [Tensor(uid=1469,size=28)]\n",
      "[<operator-2799, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1463, allreduce_forward>] [Tensor(uid=1469,size=28)] []\n",
      "[<operator-1464, dropout_forward>] [Tensor(uid=1469,size=28)] [Tensor(uid=1470,size=28), Tensor(uid=1471,size=14)]\n",
      "[<operator-1465, add_forward>] [Tensor(uid=1465,size=28), Tensor(uid=1470,size=28)] [Tensor(uid=1472,size=28)]\n",
      "[<operator-2805, add_forward_branch_offload>] None None\n",
      "[<operator-1466, layernorm_forward>] [Tensor(uid=1472,size=28)] [Tensor(uid=1473,size=28)]\n",
      "[<operator-1467, linear_qkv>] [Tensor(uid=1473,size=28)] [Tensor(uid=1474,size=42)]\n",
      "[<operator-2811, linear_qkv_branch_offload>] None None\n",
      "[<operator-1468, matmul_qk>] [Tensor(uid=1474,size=42)] [Tensor(uid=1475,size=128)]\n",
      "[<operator-1469, softmax_forward>] [Tensor(uid=1475,size=128)] [Tensor(uid=1476,size=128)]\n",
      "[<operator-1470, dropout_forward>] [Tensor(uid=1476,size=128)] [Tensor(uid=1477,size=128), Tensor(uid=1478,size=64)]\n",
      "[<operator-2817, dropout_forward_branch_offload>] None None\n",
      "[<operator-1471, matmul_v>] [Tensor(uid=1477,size=128), Tensor(uid=1474,size=42)] [Tensor(uid=1479,size=14)]\n",
      "[<operator-2823, matmul_v_branch_offload>] None None\n",
      "[<operator-1472, linear_forward>] [Tensor(uid=1479,size=14)] [Tensor(uid=1480,size=28)]\n",
      "[<operator-2829, linear_forward_branch_offload>] None None\n",
      "[<operator-1473, allreduce_forward>] [Tensor(uid=1480,size=28)] []\n",
      "[<operator-1474, output_dropout>] [Tensor(uid=1480,size=28)] [Tensor(uid=1481,size=28), Tensor(uid=1482,size=14)]\n",
      "[<operator-1475, add_forward>] [Tensor(uid=1472,size=28), Tensor(uid=1481,size=28)] [Tensor(uid=1483,size=28)]\n",
      "[<operator-2835, add_forward_branch_offload>] None None\n",
      "[<operator-1476, layernorm_forward>] [Tensor(uid=1483,size=28)] [Tensor(uid=1484,size=28)]\n",
      "[<operator-1477, linear_1_forward>] [Tensor(uid=1484,size=28)] [Tensor(uid=1485,size=56)]\n",
      "[<operator-2841, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1478, gelu_forward>] [Tensor(uid=1485,size=56)] [Tensor(uid=1486,size=56)]\n",
      "[<operator-2847, gelu_forward_branch_offload>] None None\n",
      "[<operator-1479, linear_2_forward>] [Tensor(uid=1486,size=56)] [Tensor(uid=1487,size=28)]\n",
      "[<operator-2853, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1480, allreduce_forward>] [Tensor(uid=1487,size=28)] []\n",
      "[<operator-1481, dropout_forward>] [Tensor(uid=1487,size=28)] [Tensor(uid=1488,size=28), Tensor(uid=1489,size=14)]\n",
      "[<operator-1482, add_forward>] [Tensor(uid=1483,size=28), Tensor(uid=1488,size=28)] [Tensor(uid=1490,size=28)]\n",
      "[<operator-2859, add_forward_branch_offload>] None None\n",
      "[<operator-1483, layernorm_forward>] [Tensor(uid=1490,size=28)] [Tensor(uid=1491,size=28)]\n",
      "[<operator-1484, linear_qkv>] [Tensor(uid=1491,size=28)] [Tensor(uid=1492,size=42)]\n",
      "[<operator-2865, linear_qkv_branch_offload>] None None\n",
      "[<operator-1485, matmul_qk>] [Tensor(uid=1492,size=42)] [Tensor(uid=1493,size=128)]\n",
      "[<operator-1486, softmax_forward>] [Tensor(uid=1493,size=128)] [Tensor(uid=1494,size=128)]\n",
      "[<operator-1487, dropout_forward>] [Tensor(uid=1494,size=128)] [Tensor(uid=1495,size=128), Tensor(uid=1496,size=64)]\n",
      "[<operator-2871, dropout_forward_branch_offload>] None None\n",
      "[<operator-1488, matmul_v>] [Tensor(uid=1495,size=128), Tensor(uid=1492,size=42)] [Tensor(uid=1497,size=14)]\n",
      "[<operator-2877, matmul_v_branch_offload>] None None\n",
      "[<operator-1489, linear_forward>] [Tensor(uid=1497,size=14)] [Tensor(uid=1498,size=28)]\n",
      "[<operator-2883, linear_forward_branch_offload>] None None\n",
      "[<operator-1490, allreduce_forward>] [Tensor(uid=1498,size=28)] []\n",
      "[<operator-1491, output_dropout>] [Tensor(uid=1498,size=28)] [Tensor(uid=1499,size=28), Tensor(uid=1500,size=14)]\n",
      "[<operator-1492, add_forward>] [Tensor(uid=1490,size=28), Tensor(uid=1499,size=28)] [Tensor(uid=1501,size=28)]\n",
      "[<operator-2889, add_forward_branch_offload>] None None\n",
      "[<operator-1493, layernorm_forward>] [Tensor(uid=1501,size=28)] [Tensor(uid=1502,size=28)]\n",
      "[<operator-1494, linear_1_forward>] [Tensor(uid=1502,size=28)] [Tensor(uid=1503,size=56)]\n",
      "[<operator-2895, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1495, gelu_forward>] [Tensor(uid=1503,size=56)] [Tensor(uid=1504,size=56)]\n",
      "[<operator-2901, gelu_forward_branch_offload>] None None\n",
      "[<operator-1496, linear_2_forward>] [Tensor(uid=1504,size=56)] [Tensor(uid=1505,size=28)]\n",
      "[<operator-2907, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1497, allreduce_forward>] [Tensor(uid=1505,size=28)] []\n",
      "[<operator-1498, dropout_forward>] [Tensor(uid=1505,size=28)] [Tensor(uid=1506,size=28), Tensor(uid=1507,size=14)]\n",
      "[<operator-1499, add_forward>] [Tensor(uid=1501,size=28), Tensor(uid=1506,size=28)] [Tensor(uid=1508,size=28)]\n",
      "[<operator-2913, add_forward_branch_offload>] None None\n",
      "[<operator-1500, layernorm_forward>] [Tensor(uid=1508,size=28)] [Tensor(uid=1509,size=28)]\n",
      "[<operator-1501, linear_qkv>] [Tensor(uid=1509,size=28)] [Tensor(uid=1510,size=42)]\n",
      "[<operator-2919, linear_qkv_branch_offload>] None None\n",
      "[<operator-1502, matmul_qk>] [Tensor(uid=1510,size=42)] [Tensor(uid=1511,size=128)]\n",
      "[<operator-1503, softmax_forward>] [Tensor(uid=1511,size=128)] [Tensor(uid=1512,size=128)]\n",
      "[<operator-1504, dropout_forward>] [Tensor(uid=1512,size=128)] [Tensor(uid=1513,size=128), Tensor(uid=1514,size=64)]\n",
      "[<operator-2925, dropout_forward_branch_offload>] None None\n",
      "[<operator-1505, matmul_v>] [Tensor(uid=1513,size=128), Tensor(uid=1510,size=42)] [Tensor(uid=1515,size=14)]\n",
      "[<operator-2931, matmul_v_branch_offload>] None None\n",
      "[<operator-1506, linear_forward>] [Tensor(uid=1515,size=14)] [Tensor(uid=1516,size=28)]\n",
      "[<operator-2937, linear_forward_branch_offload>] None None\n",
      "[<operator-1507, allreduce_forward>] [Tensor(uid=1516,size=28)] []\n",
      "[<operator-1508, output_dropout>] [Tensor(uid=1516,size=28)] [Tensor(uid=1517,size=28), Tensor(uid=1518,size=14)]\n",
      "[<operator-1509, add_forward>] [Tensor(uid=1508,size=28), Tensor(uid=1517,size=28)] [Tensor(uid=1519,size=28)]\n",
      "[<operator-2943, add_forward_branch_offload>] None None\n",
      "[<operator-1510, layernorm_forward>] [Tensor(uid=1519,size=28)] [Tensor(uid=1520,size=28)]\n",
      "[<operator-1511, linear_1_forward>] [Tensor(uid=1520,size=28)] [Tensor(uid=1521,size=56)]\n",
      "[<operator-2949, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1512, gelu_forward>] [Tensor(uid=1521,size=56)] [Tensor(uid=1522,size=56)]\n",
      "[<operator-2955, gelu_forward_branch_offload>] None None\n",
      "[<operator-1513, linear_2_forward>] [Tensor(uid=1522,size=56)] [Tensor(uid=1523,size=28)]\n",
      "[<operator-2961, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1514, allreduce_forward>] [Tensor(uid=1523,size=28)] []\n",
      "[<operator-1515, dropout_forward>] [Tensor(uid=1523,size=28)] [Tensor(uid=1524,size=28), Tensor(uid=1525,size=14)]\n",
      "[<operator-1516, add_forward>] [Tensor(uid=1519,size=28), Tensor(uid=1524,size=28)] [Tensor(uid=1526,size=28)]\n",
      "[<operator-2967, add_forward_branch_offload>] None None\n",
      "[<operator-1517, layernorm_forward>] [Tensor(uid=1526,size=28)] [Tensor(uid=1527,size=28)]\n",
      "[<operator-1518, linear_qkv>] [Tensor(uid=1527,size=28)] [Tensor(uid=1528,size=42)]\n",
      "[<operator-2973, linear_qkv_branch_offload>] None None\n",
      "[<operator-1519, matmul_qk>] [Tensor(uid=1528,size=42)] [Tensor(uid=1529,size=128)]\n",
      "[<operator-1520, softmax_forward>] [Tensor(uid=1529,size=128)] [Tensor(uid=1530,size=128)]\n",
      "[<operator-1521, dropout_forward>] [Tensor(uid=1530,size=128)] [Tensor(uid=1531,size=128), Tensor(uid=1532,size=64)]\n",
      "[<operator-2979, dropout_forward_branch_offload>] None None\n",
      "[<operator-1522, matmul_v>] [Tensor(uid=1531,size=128), Tensor(uid=1528,size=42)] [Tensor(uid=1533,size=14)]\n",
      "[<operator-2985, matmul_v_branch_offload>] None None\n",
      "[<operator-1523, linear_forward>] [Tensor(uid=1533,size=14)] [Tensor(uid=1534,size=28)]\n",
      "[<operator-2991, linear_forward_branch_offload>] None None\n",
      "[<operator-1524, allreduce_forward>] [Tensor(uid=1534,size=28)] []\n",
      "[<operator-1525, output_dropout>] [Tensor(uid=1534,size=28)] [Tensor(uid=1535,size=28), Tensor(uid=1536,size=14)]\n",
      "[<operator-1526, add_forward>] [Tensor(uid=1526,size=28), Tensor(uid=1535,size=28)] [Tensor(uid=1537,size=28)]\n",
      "[<operator-2997, add_forward_branch_offload>] None None\n",
      "[<operator-1527, layernorm_forward>] [Tensor(uid=1537,size=28)] [Tensor(uid=1538,size=28)]\n",
      "[<operator-1528, linear_1_forward>] [Tensor(uid=1538,size=28)] [Tensor(uid=1539,size=56)]\n",
      "[<operator-3003, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1529, gelu_forward>] [Tensor(uid=1539,size=56)] [Tensor(uid=1540,size=56)]\n",
      "[<operator-3009, gelu_forward_branch_offload>] None None\n",
      "[<operator-1530, linear_2_forward>] [Tensor(uid=1540,size=56)] [Tensor(uid=1541,size=28)]\n",
      "[<operator-3015, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1531, allreduce_forward>] [Tensor(uid=1541,size=28)] []\n",
      "[<operator-1532, dropout_forward>] [Tensor(uid=1541,size=28)] [Tensor(uid=1542,size=28), Tensor(uid=1543,size=14)]\n",
      "[<operator-1533, add_forward>] [Tensor(uid=1537,size=28), Tensor(uid=1542,size=28)] [Tensor(uid=1544,size=28)]\n",
      "[<operator-3021, add_forward_branch_offload>] None None\n",
      "[<operator-1534, layernorm_forward>] [Tensor(uid=1544,size=28)] [Tensor(uid=1545,size=28)]\n",
      "[<operator-1535, linear_qkv>] [Tensor(uid=1545,size=28)] [Tensor(uid=1546,size=42)]\n",
      "[<operator-3027, linear_qkv_branch_offload>] None None\n",
      "[<operator-1536, matmul_qk>] [Tensor(uid=1546,size=42)] [Tensor(uid=1547,size=128)]\n",
      "[<operator-1537, softmax_forward>] [Tensor(uid=1547,size=128)] [Tensor(uid=1548,size=128)]\n",
      "[<operator-1538, dropout_forward>] [Tensor(uid=1548,size=128)] [Tensor(uid=1549,size=128), Tensor(uid=1550,size=64)]\n",
      "[<operator-3033, dropout_forward_branch_offload>] None None\n",
      "[<operator-1539, matmul_v>] [Tensor(uid=1549,size=128), Tensor(uid=1546,size=42)] [Tensor(uid=1551,size=14)]\n",
      "[<operator-3039, matmul_v_branch_offload>] None None\n",
      "[<operator-1540, linear_forward>] [Tensor(uid=1551,size=14)] [Tensor(uid=1552,size=28)]\n",
      "[<operator-3045, linear_forward_branch_offload>] None None\n",
      "[<operator-1541, allreduce_forward>] [Tensor(uid=1552,size=28)] []\n",
      "[<operator-1542, output_dropout>] [Tensor(uid=1552,size=28)] [Tensor(uid=1553,size=28), Tensor(uid=1554,size=14)]\n",
      "[<operator-1543, add_forward>] [Tensor(uid=1544,size=28), Tensor(uid=1553,size=28)] [Tensor(uid=1555,size=28)]\n",
      "[<operator-3051, add_forward_branch_offload>] None None\n",
      "[<operator-1544, layernorm_forward>] [Tensor(uid=1555,size=28)] [Tensor(uid=1556,size=28)]\n",
      "[<operator-1545, linear_1_forward>] [Tensor(uid=1556,size=28)] [Tensor(uid=1557,size=56)]\n",
      "[<operator-3057, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1546, gelu_forward>] [Tensor(uid=1557,size=56)] [Tensor(uid=1558,size=56)]\n",
      "[<operator-3063, gelu_forward_branch_offload>] None None\n",
      "[<operator-1547, linear_2_forward>] [Tensor(uid=1558,size=56)] [Tensor(uid=1559,size=28)]\n",
      "[<operator-3069, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1548, allreduce_forward>] [Tensor(uid=1559,size=28)] []\n",
      "[<operator-1549, dropout_forward>] [Tensor(uid=1559,size=28)] [Tensor(uid=1560,size=28), Tensor(uid=1561,size=14)]\n",
      "[<operator-1550, add_forward>] [Tensor(uid=1555,size=28), Tensor(uid=1560,size=28)] [Tensor(uid=1562,size=28)]\n",
      "[<operator-3075, add_forward_branch_offload>] None None\n",
      "[<operator-1551, layernorm_forward>] [Tensor(uid=1562,size=28)] [Tensor(uid=1563,size=28)]\n",
      "[<operator-1552, linear_qkv>] [Tensor(uid=1563,size=28)] [Tensor(uid=1564,size=42)]\n",
      "[<operator-3081, linear_qkv_branch_offload>] None None\n",
      "[<operator-1553, matmul_qk>] [Tensor(uid=1564,size=42)] [Tensor(uid=1565,size=128)]\n",
      "[<operator-1554, softmax_forward>] [Tensor(uid=1565,size=128)] [Tensor(uid=1566,size=128)]\n",
      "[<operator-1555, dropout_forward>] [Tensor(uid=1566,size=128)] [Tensor(uid=1567,size=128), Tensor(uid=1568,size=64)]\n",
      "[<operator-3087, dropout_forward_branch_offload>] None None\n",
      "[<operator-1556, matmul_v>] [Tensor(uid=1567,size=128), Tensor(uid=1564,size=42)] [Tensor(uid=1569,size=14)]\n",
      "[<operator-3093, matmul_v_branch_offload>] None None\n",
      "[<operator-1557, linear_forward>] [Tensor(uid=1569,size=14)] [Tensor(uid=1570,size=28)]\n",
      "[<operator-3099, linear_forward_branch_offload>] None None\n",
      "[<operator-1558, allreduce_forward>] [Tensor(uid=1570,size=28)] []\n",
      "[<operator-1559, output_dropout>] [Tensor(uid=1570,size=28)] [Tensor(uid=1571,size=28), Tensor(uid=1572,size=14)]\n",
      "[<operator-1560, add_forward>] [Tensor(uid=1562,size=28), Tensor(uid=1571,size=28)] [Tensor(uid=1573,size=28)]\n",
      "[<operator-3105, add_forward_branch_offload>] None None\n",
      "[<operator-1561, layernorm_forward>] [Tensor(uid=1573,size=28)] [Tensor(uid=1574,size=28)]\n",
      "[<operator-1562, linear_1_forward>] [Tensor(uid=1574,size=28)] [Tensor(uid=1575,size=56)]\n",
      "[<operator-3111, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1563, gelu_forward>] [Tensor(uid=1575,size=56)] [Tensor(uid=1576,size=56)]\n",
      "[<operator-3117, gelu_forward_branch_offload>] None None\n",
      "[<operator-1564, linear_2_forward>] [Tensor(uid=1576,size=56)] [Tensor(uid=1577,size=28)]\n",
      "[<operator-3123, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1565, allreduce_forward>] [Tensor(uid=1577,size=28)] []\n",
      "[<operator-1566, dropout_forward>] [Tensor(uid=1577,size=28)] [Tensor(uid=1578,size=28), Tensor(uid=1579,size=14)]\n",
      "[<operator-1567, add_forward>] [Tensor(uid=1573,size=28), Tensor(uid=1578,size=28)] [Tensor(uid=1580,size=28)]\n",
      "[<operator-3129, add_forward_branch_offload>] None None\n",
      "[<operator-1568, layernorm_forward>] [Tensor(uid=1580,size=28)] [Tensor(uid=1581,size=28)]\n",
      "[<operator-1569, linear_qkv>] [Tensor(uid=1581,size=28)] [Tensor(uid=1582,size=42)]\n",
      "[<operator-3135, linear_qkv_branch_offload>] None None\n",
      "[<operator-1570, matmul_qk>] [Tensor(uid=1582,size=42)] [Tensor(uid=1583,size=128)]\n",
      "[<operator-1571, softmax_forward>] [Tensor(uid=1583,size=128)] [Tensor(uid=1584,size=128)]\n",
      "[<operator-1572, dropout_forward>] [Tensor(uid=1584,size=128)] [Tensor(uid=1585,size=128), Tensor(uid=1586,size=64)]\n",
      "[<operator-3141, dropout_forward_branch_offload>] None None\n",
      "[<operator-1573, matmul_v>] [Tensor(uid=1585,size=128), Tensor(uid=1582,size=42)] [Tensor(uid=1587,size=14)]\n",
      "[<operator-3147, matmul_v_branch_offload>] None None\n",
      "[<operator-1574, linear_forward>] [Tensor(uid=1587,size=14)] [Tensor(uid=1588,size=28)]\n",
      "[<operator-3153, linear_forward_branch_offload>] None None\n",
      "[<operator-1575, allreduce_forward>] [Tensor(uid=1588,size=28)] []\n",
      "[<operator-1576, output_dropout>] [Tensor(uid=1588,size=28)] [Tensor(uid=1589,size=28), Tensor(uid=1590,size=14)]\n",
      "[<operator-1577, add_forward>] [Tensor(uid=1580,size=28), Tensor(uid=1589,size=28)] [Tensor(uid=1591,size=28)]\n",
      "[<operator-3159, add_forward_branch_offload>] None None\n",
      "[<operator-1578, layernorm_forward>] [Tensor(uid=1591,size=28)] [Tensor(uid=1592,size=28)]\n",
      "[<operator-1579, linear_1_forward>] [Tensor(uid=1592,size=28)] [Tensor(uid=1593,size=56)]\n",
      "[<operator-3165, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1580, gelu_forward>] [Tensor(uid=1593,size=56)] [Tensor(uid=1594,size=56)]\n",
      "[<operator-3171, gelu_forward_branch_offload>] None None\n",
      "[<operator-1581, linear_2_forward>] [Tensor(uid=1594,size=56)] [Tensor(uid=1595,size=28)]\n",
      "[<operator-3177, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1582, allreduce_forward>] [Tensor(uid=1595,size=28)] []\n",
      "[<operator-1583, dropout_forward>] [Tensor(uid=1595,size=28)] [Tensor(uid=1596,size=28), Tensor(uid=1597,size=14)]\n",
      "[<operator-1584, add_forward>] [Tensor(uid=1591,size=28), Tensor(uid=1596,size=28)] [Tensor(uid=1598,size=28)]\n",
      "[<operator-3183, add_forward_branch_offload>] None None\n",
      "[<operator-1585, layernorm_forward>] [Tensor(uid=1598,size=28)] [Tensor(uid=1599,size=28)]\n",
      "[<operator-1586, linear_qkv>] [Tensor(uid=1599,size=28)] [Tensor(uid=1600,size=42)]\n",
      "[<operator-3189, linear_qkv_branch_offload>] None None\n",
      "[<operator-1587, matmul_qk>] [Tensor(uid=1600,size=42)] [Tensor(uid=1601,size=128)]\n",
      "[<operator-1588, softmax_forward>] [Tensor(uid=1601,size=128)] [Tensor(uid=1602,size=128)]\n",
      "[<operator-1589, dropout_forward>] [Tensor(uid=1602,size=128)] [Tensor(uid=1603,size=128), Tensor(uid=1604,size=64)]\n",
      "[<operator-3195, dropout_forward_branch_offload>] None None\n",
      "[<operator-1590, matmul_v>] [Tensor(uid=1603,size=128), Tensor(uid=1600,size=42)] [Tensor(uid=1605,size=14)]\n",
      "[<operator-3201, matmul_v_branch_offload>] None None\n",
      "[<operator-1591, linear_forward>] [Tensor(uid=1605,size=14)] [Tensor(uid=1606,size=28)]\n",
      "[<operator-3207, linear_forward_branch_offload>] None None\n",
      "[<operator-1592, allreduce_forward>] [Tensor(uid=1606,size=28)] []\n",
      "[<operator-1593, output_dropout>] [Tensor(uid=1606,size=28)] [Tensor(uid=1607,size=28), Tensor(uid=1608,size=14)]\n",
      "[<operator-1594, add_forward>] [Tensor(uid=1598,size=28), Tensor(uid=1607,size=28)] [Tensor(uid=1609,size=28)]\n",
      "[<operator-3213, add_forward_branch_offload>] None None\n",
      "[<operator-1595, layernorm_forward>] [Tensor(uid=1609,size=28)] [Tensor(uid=1610,size=28)]\n",
      "[<operator-1596, linear_1_forward>] [Tensor(uid=1610,size=28)] [Tensor(uid=1611,size=56)]\n",
      "[<operator-3219, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1597, gelu_forward>] [Tensor(uid=1611,size=56)] [Tensor(uid=1612,size=56)]\n",
      "[<operator-3225, gelu_forward_branch_offload>] None None\n",
      "[<operator-1598, linear_2_forward>] [Tensor(uid=1612,size=56)] [Tensor(uid=1613,size=28)]\n",
      "[<operator-3231, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1599, allreduce_forward>] [Tensor(uid=1613,size=28)] []\n",
      "[<operator-1600, dropout_forward>] [Tensor(uid=1613,size=28)] [Tensor(uid=1614,size=28), Tensor(uid=1615,size=14)]\n",
      "[<operator-1601, add_forward>] [Tensor(uid=1609,size=28), Tensor(uid=1614,size=28)] [Tensor(uid=1616,size=28)]\n",
      "[<operator-3237, add_forward_branch_offload>] None None\n",
      "[<operator-1602, layernorm_forward>] [Tensor(uid=1616,size=28)] [Tensor(uid=1617,size=28)]\n",
      "[<operator-1603, linear_qkv>] [Tensor(uid=1617,size=28)] [Tensor(uid=1618,size=42)]\n",
      "[<operator-3243, linear_qkv_branch_offload>] None None\n",
      "[<operator-1604, matmul_qk>] [Tensor(uid=1618,size=42)] [Tensor(uid=1619,size=128)]\n",
      "[<operator-1605, softmax_forward>] [Tensor(uid=1619,size=128)] [Tensor(uid=1620,size=128)]\n",
      "[<operator-1606, dropout_forward>] [Tensor(uid=1620,size=128)] [Tensor(uid=1621,size=128), Tensor(uid=1622,size=64)]\n",
      "[<operator-3249, dropout_forward_branch_offload>] None None\n",
      "[<operator-1607, matmul_v>] [Tensor(uid=1621,size=128), Tensor(uid=1618,size=42)] [Tensor(uid=1623,size=14)]\n",
      "[<operator-3255, matmul_v_branch_offload>] None None\n",
      "[<operator-1608, linear_forward>] [Tensor(uid=1623,size=14)] [Tensor(uid=1624,size=28)]\n",
      "[<operator-3261, linear_forward_branch_offload>] None None\n",
      "[<operator-1609, allreduce_forward>] [Tensor(uid=1624,size=28)] []\n",
      "[<operator-1610, output_dropout>] [Tensor(uid=1624,size=28)] [Tensor(uid=1625,size=28), Tensor(uid=1626,size=14)]\n",
      "[<operator-1611, add_forward>] [Tensor(uid=1616,size=28), Tensor(uid=1625,size=28)] [Tensor(uid=1627,size=28)]\n",
      "[<operator-3267, add_forward_branch_offload>] None None\n",
      "[<operator-1612, layernorm_forward>] [Tensor(uid=1627,size=28)] [Tensor(uid=1628,size=28)]\n",
      "[<operator-1613, linear_1_forward>] [Tensor(uid=1628,size=28)] [Tensor(uid=1629,size=56)]\n",
      "[<operator-3273, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1614, gelu_forward>] [Tensor(uid=1629,size=56)] [Tensor(uid=1630,size=56)]\n",
      "[<operator-3279, gelu_forward_branch_offload>] None None\n",
      "[<operator-1615, linear_2_forward>] [Tensor(uid=1630,size=56)] [Tensor(uid=1631,size=28)]\n",
      "[<operator-3285, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1616, allreduce_forward>] [Tensor(uid=1631,size=28)] []\n",
      "[<operator-1617, dropout_forward>] [Tensor(uid=1631,size=28)] [Tensor(uid=1632,size=28), Tensor(uid=1633,size=14)]\n",
      "[<operator-1618, add_forward>] [Tensor(uid=1627,size=28), Tensor(uid=1632,size=28)] [Tensor(uid=1634,size=28)]\n",
      "[<operator-3291, add_forward_branch_offload>] None None\n",
      "[<operator-1619, layernorm_forward>] [Tensor(uid=1634,size=28)] [Tensor(uid=1635,size=28)]\n",
      "[<operator-1620, linear_qkv>] [Tensor(uid=1635,size=28)] [Tensor(uid=1636,size=42)]\n",
      "[<operator-3297, linear_qkv_branch_offload>] None None\n",
      "[<operator-1621, matmul_qk>] [Tensor(uid=1636,size=42)] [Tensor(uid=1637,size=128)]\n",
      "[<operator-1622, softmax_forward>] [Tensor(uid=1637,size=128)] [Tensor(uid=1638,size=128)]\n",
      "[<operator-1623, dropout_forward>] [Tensor(uid=1638,size=128)] [Tensor(uid=1639,size=128), Tensor(uid=1640,size=64)]\n",
      "[<operator-3303, dropout_forward_branch_offload>] None None\n",
      "[<operator-1624, matmul_v>] [Tensor(uid=1639,size=128), Tensor(uid=1636,size=42)] [Tensor(uid=1641,size=14)]\n",
      "[<operator-3309, matmul_v_branch_offload>] None None\n",
      "[<operator-1625, linear_forward>] [Tensor(uid=1641,size=14)] [Tensor(uid=1642,size=28)]\n",
      "[<operator-3315, linear_forward_branch_offload>] None None\n",
      "[<operator-1626, allreduce_forward>] [Tensor(uid=1642,size=28)] []\n",
      "[<operator-1627, output_dropout>] [Tensor(uid=1642,size=28)] [Tensor(uid=1643,size=28), Tensor(uid=1644,size=14)]\n",
      "[<operator-1628, add_forward>] [Tensor(uid=1634,size=28), Tensor(uid=1643,size=28)] [Tensor(uid=1645,size=28)]\n",
      "[<operator-3321, add_forward_branch_offload>] None None\n",
      "[<operator-1629, layernorm_forward>] [Tensor(uid=1645,size=28)] [Tensor(uid=1646,size=28)]\n",
      "[<operator-1630, linear_1_forward>] [Tensor(uid=1646,size=28)] [Tensor(uid=1647,size=56)]\n",
      "[<operator-3327, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1631, gelu_forward>] [Tensor(uid=1647,size=56)] [Tensor(uid=1648,size=56)]\n",
      "[<operator-3333, gelu_forward_branch_offload>] None None\n",
      "[<operator-1632, linear_2_forward>] [Tensor(uid=1648,size=56)] [Tensor(uid=1649,size=28)]\n",
      "[<operator-3339, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1633, allreduce_forward>] [Tensor(uid=1649,size=28)] []\n",
      "[<operator-1634, dropout_forward>] [Tensor(uid=1649,size=28)] [Tensor(uid=1650,size=28), Tensor(uid=1651,size=14)]\n",
      "[<operator-1635, add_forward>] [Tensor(uid=1645,size=28), Tensor(uid=1650,size=28)] [Tensor(uid=1652,size=28)]\n",
      "[<operator-3345, add_forward_branch_offload>] None None\n",
      "[<operator-1636, layernorm_forward>] [Tensor(uid=1652,size=28)] [Tensor(uid=1653,size=28)]\n",
      "[<operator-1637, linear_qkv>] [Tensor(uid=1653,size=28)] [Tensor(uid=1654,size=42)]\n",
      "[<operator-3351, linear_qkv_branch_offload>] None None\n",
      "[<operator-1638, matmul_qk>] [Tensor(uid=1654,size=42)] [Tensor(uid=1655,size=128)]\n",
      "[<operator-1639, softmax_forward>] [Tensor(uid=1655,size=128)] [Tensor(uid=1656,size=128)]\n",
      "[<operator-1640, dropout_forward>] [Tensor(uid=1656,size=128)] [Tensor(uid=1657,size=128), Tensor(uid=1658,size=64)]\n",
      "[<operator-3357, dropout_forward_branch_offload>] None None\n",
      "[<operator-1641, matmul_v>] [Tensor(uid=1657,size=128), Tensor(uid=1654,size=42)] [Tensor(uid=1659,size=14)]\n",
      "[<operator-3363, matmul_v_branch_offload>] None None\n",
      "[<operator-1642, linear_forward>] [Tensor(uid=1659,size=14)] [Tensor(uid=1660,size=28)]\n",
      "[<operator-3369, linear_forward_branch_offload>] None None\n",
      "[<operator-1643, allreduce_forward>] [Tensor(uid=1660,size=28)] []\n",
      "[<operator-1644, output_dropout>] [Tensor(uid=1660,size=28)] [Tensor(uid=1661,size=28), Tensor(uid=1662,size=14)]\n",
      "[<operator-1645, add_forward>] [Tensor(uid=1652,size=28), Tensor(uid=1661,size=28)] [Tensor(uid=1663,size=28)]\n",
      "[<operator-3375, add_forward_branch_offload>] None None\n",
      "[<operator-1646, layernorm_forward>] [Tensor(uid=1663,size=28)] [Tensor(uid=1664,size=28)]\n",
      "[<operator-1647, linear_1_forward>] [Tensor(uid=1664,size=28)] [Tensor(uid=1665,size=56)]\n",
      "[<operator-3381, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1648, gelu_forward>] [Tensor(uid=1665,size=56)] [Tensor(uid=1666,size=56)]\n",
      "[<operator-3387, gelu_forward_branch_offload>] None None\n",
      "[<operator-1649, linear_2_forward>] [Tensor(uid=1666,size=56)] [Tensor(uid=1667,size=28)]\n",
      "[<operator-3393, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1650, allreduce_forward>] [Tensor(uid=1667,size=28)] []\n",
      "[<operator-1651, dropout_forward>] [Tensor(uid=1667,size=28)] [Tensor(uid=1668,size=28), Tensor(uid=1669,size=14)]\n",
      "[<operator-1652, add_forward>] [Tensor(uid=1663,size=28), Tensor(uid=1668,size=28)] [Tensor(uid=1670,size=28)]\n",
      "[<operator-3399, add_forward_branch_offload>] None None\n",
      "[<operator-1653, layernorm_forward>] [Tensor(uid=1670,size=28)] [Tensor(uid=1671,size=28)]\n",
      "[<operator-1654, linear_qkv>] [Tensor(uid=1671,size=28)] [Tensor(uid=1672,size=42)]\n",
      "[<operator-3405, linear_qkv_branch_offload>] None None\n",
      "[<operator-1655, matmul_qk>] [Tensor(uid=1672,size=42)] [Tensor(uid=1673,size=128)]\n",
      "[<operator-1656, softmax_forward>] [Tensor(uid=1673,size=128)] [Tensor(uid=1674,size=128)]\n",
      "[<operator-1657, dropout_forward>] [Tensor(uid=1674,size=128)] [Tensor(uid=1675,size=128), Tensor(uid=1676,size=64)]\n",
      "[<operator-3411, dropout_forward_branch_offload>] None None\n",
      "[<operator-1658, matmul_v>] [Tensor(uid=1675,size=128), Tensor(uid=1672,size=42)] [Tensor(uid=1677,size=14)]\n",
      "[<operator-3417, matmul_v_branch_offload>] None None\n",
      "[<operator-1659, linear_forward>] [Tensor(uid=1677,size=14)] [Tensor(uid=1678,size=28)]\n",
      "[<operator-3423, linear_forward_branch_offload>] None None\n",
      "[<operator-1660, allreduce_forward>] [Tensor(uid=1678,size=28)] []\n",
      "[<operator-1661, output_dropout>] [Tensor(uid=1678,size=28)] [Tensor(uid=1679,size=28), Tensor(uid=1680,size=14)]\n",
      "[<operator-1662, add_forward>] [Tensor(uid=1670,size=28), Tensor(uid=1679,size=28)] [Tensor(uid=1681,size=28)]\n",
      "[<operator-3429, add_forward_branch_offload>] None None\n",
      "[<operator-1663, layernorm_forward>] [Tensor(uid=1681,size=28)] [Tensor(uid=1682,size=28)]\n",
      "[<operator-1664, linear_1_forward>] [Tensor(uid=1682,size=28)] [Tensor(uid=1683,size=56)]\n",
      "[<operator-3435, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1665, gelu_forward>] [Tensor(uid=1683,size=56)] [Tensor(uid=1684,size=56)]\n",
      "[<operator-3441, gelu_forward_branch_offload>] None None\n",
      "[<operator-1666, linear_2_forward>] [Tensor(uid=1684,size=56)] [Tensor(uid=1685,size=28)]\n",
      "[<operator-3447, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1667, allreduce_forward>] [Tensor(uid=1685,size=28)] []\n",
      "[<operator-1668, dropout_forward>] [Tensor(uid=1685,size=28)] [Tensor(uid=1686,size=28), Tensor(uid=1687,size=14)]\n",
      "[<operator-1669, add_forward>] [Tensor(uid=1681,size=28), Tensor(uid=1686,size=28)] [Tensor(uid=1688,size=28)]\n",
      "[<operator-3453, add_forward_branch_offload>] None None\n",
      "[<operator-1670, layernorm_forward>] [Tensor(uid=1688,size=28)] [Tensor(uid=1689,size=28)]\n",
      "[<operator-1671, linear_qkv>] [Tensor(uid=1689,size=28)] [Tensor(uid=1690,size=42)]\n",
      "[<operator-3459, linear_qkv_branch_offload>] None None\n",
      "[<operator-1672, matmul_qk>] [Tensor(uid=1690,size=42)] [Tensor(uid=1691,size=128)]\n",
      "[<operator-1673, softmax_forward>] [Tensor(uid=1691,size=128)] [Tensor(uid=1692,size=128)]\n",
      "[<operator-1674, dropout_forward>] [Tensor(uid=1692,size=128)] [Tensor(uid=1693,size=128), Tensor(uid=1694,size=64)]\n",
      "[<operator-3465, dropout_forward_branch_offload>] None None\n",
      "[<operator-1675, matmul_v>] [Tensor(uid=1693,size=128), Tensor(uid=1690,size=42)] [Tensor(uid=1695,size=14)]\n",
      "[<operator-3471, matmul_v_branch_offload>] None None\n",
      "[<operator-1676, linear_forward>] [Tensor(uid=1695,size=14)] [Tensor(uid=1696,size=28)]\n",
      "[<operator-3477, linear_forward_branch_offload>] None None\n",
      "[<operator-1677, allreduce_forward>] [Tensor(uid=1696,size=28)] []\n",
      "[<operator-1678, output_dropout>] [Tensor(uid=1696,size=28)] [Tensor(uid=1697,size=28), Tensor(uid=1698,size=14)]\n",
      "[<operator-1679, add_forward>] [Tensor(uid=1688,size=28), Tensor(uid=1697,size=28)] [Tensor(uid=1699,size=28)]\n",
      "[<operator-3483, add_forward_branch_offload>] None None\n",
      "[<operator-1680, layernorm_forward>] [Tensor(uid=1699,size=28)] [Tensor(uid=1700,size=28)]\n",
      "[<operator-1681, linear_1_forward>] [Tensor(uid=1700,size=28)] [Tensor(uid=1701,size=56)]\n",
      "[<operator-3489, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1682, gelu_forward>] [Tensor(uid=1701,size=56)] [Tensor(uid=1702,size=56)]\n",
      "[<operator-3495, gelu_forward_branch_offload>] None None\n",
      "[<operator-1683, linear_2_forward>] [Tensor(uid=1702,size=56)] [Tensor(uid=1703,size=28)]\n",
      "[<operator-3501, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1684, allreduce_forward>] [Tensor(uid=1703,size=28)] []\n",
      "[<operator-1685, dropout_forward>] [Tensor(uid=1703,size=28)] [Tensor(uid=1704,size=28), Tensor(uid=1705,size=14)]\n",
      "[<operator-1686, add_forward>] [Tensor(uid=1699,size=28), Tensor(uid=1704,size=28)] [Tensor(uid=1706,size=28)]\n",
      "[<operator-3507, add_forward_branch_offload>] None None\n",
      "[<operator-1687, layernorm_forward>] [Tensor(uid=1706,size=28)] [Tensor(uid=1707,size=28)]\n",
      "[<operator-1688, linear_qkv>] [Tensor(uid=1707,size=28)] [Tensor(uid=1708,size=42)]\n",
      "[<operator-3513, linear_qkv_branch_offload>] None None\n",
      "[<operator-1689, matmul_qk>] [Tensor(uid=1708,size=42)] [Tensor(uid=1709,size=128)]\n",
      "[<operator-1690, softmax_forward>] [Tensor(uid=1709,size=128)] [Tensor(uid=1710,size=128)]\n",
      "[<operator-1691, dropout_forward>] [Tensor(uid=1710,size=128)] [Tensor(uid=1711,size=128), Tensor(uid=1712,size=64)]\n",
      "[<operator-3519, dropout_forward_branch_offload>] None None\n",
      "[<operator-1692, matmul_v>] [Tensor(uid=1711,size=128), Tensor(uid=1708,size=42)] [Tensor(uid=1713,size=14)]\n",
      "[<operator-3525, matmul_v_branch_offload>] None None\n",
      "[<operator-1693, linear_forward>] [Tensor(uid=1713,size=14)] [Tensor(uid=1714,size=28)]\n",
      "[<operator-3531, linear_forward_branch_offload>] None None\n",
      "[<operator-1694, allreduce_forward>] [Tensor(uid=1714,size=28)] []\n",
      "[<operator-1695, output_dropout>] [Tensor(uid=1714,size=28)] [Tensor(uid=1715,size=28), Tensor(uid=1716,size=14)]\n",
      "[<operator-1696, add_forward>] [Tensor(uid=1706,size=28), Tensor(uid=1715,size=28)] [Tensor(uid=1717,size=28)]\n",
      "[<operator-3537, add_forward_branch_offload>] None None\n",
      "[<operator-1697, layernorm_forward>] [Tensor(uid=1717,size=28)] [Tensor(uid=1718,size=28)]\n",
      "[<operator-1698, linear_1_forward>] [Tensor(uid=1718,size=28)] [Tensor(uid=1719,size=56)]\n",
      "[<operator-3543, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1699, gelu_forward>] [Tensor(uid=1719,size=56)] [Tensor(uid=1720,size=56)]\n",
      "[<operator-3549, gelu_forward_branch_offload>] None None\n",
      "[<operator-1700, linear_2_forward>] [Tensor(uid=1720,size=56)] [Tensor(uid=1721,size=28)]\n",
      "[<operator-3555, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1701, allreduce_forward>] [Tensor(uid=1721,size=28)] []\n",
      "[<operator-1702, dropout_forward>] [Tensor(uid=1721,size=28)] [Tensor(uid=1722,size=28), Tensor(uid=1723,size=14)]\n",
      "[<operator-1703, add_forward>] [Tensor(uid=1717,size=28), Tensor(uid=1722,size=28)] [Tensor(uid=1724,size=28)]\n",
      "[<operator-3561, add_forward_branch_offload>] None None\n",
      "[<operator-1704, layernorm_forward>] [Tensor(uid=1724,size=28)] [Tensor(uid=1725,size=28)]\n",
      "[<operator-1705, linear_qkv>] [Tensor(uid=1725,size=28)] [Tensor(uid=1726,size=42)]\n",
      "[<operator-3567, linear_qkv_branch_offload>] None None\n",
      "[<operator-1706, matmul_qk>] [Tensor(uid=1726,size=42)] [Tensor(uid=1727,size=128)]\n",
      "[<operator-1707, softmax_forward>] [Tensor(uid=1727,size=128)] [Tensor(uid=1728,size=128)]\n",
      "[<operator-1708, dropout_forward>] [Tensor(uid=1728,size=128)] [Tensor(uid=1729,size=128), Tensor(uid=1730,size=64)]\n",
      "[<operator-3573, dropout_forward_branch_offload>] None None\n",
      "[<operator-1709, matmul_v>] [Tensor(uid=1729,size=128), Tensor(uid=1726,size=42)] [Tensor(uid=1731,size=14)]\n",
      "[<operator-3579, matmul_v_branch_offload>] None None\n",
      "[<operator-1710, linear_forward>] [Tensor(uid=1731,size=14)] [Tensor(uid=1732,size=28)]\n",
      "[<operator-3585, linear_forward_branch_offload>] None None\n",
      "[<operator-1711, allreduce_forward>] [Tensor(uid=1732,size=28)] []\n",
      "[<operator-1712, output_dropout>] [Tensor(uid=1732,size=28)] [Tensor(uid=1733,size=28), Tensor(uid=1734,size=14)]\n",
      "[<operator-1713, add_forward>] [Tensor(uid=1724,size=28), Tensor(uid=1733,size=28)] [Tensor(uid=1735,size=28)]\n",
      "[<operator-3591, add_forward_branch_offload>] None None\n",
      "[<operator-1714, layernorm_forward>] [Tensor(uid=1735,size=28)] [Tensor(uid=1736,size=28)]\n",
      "[<operator-1715, linear_1_forward>] [Tensor(uid=1736,size=28)] [Tensor(uid=1737,size=56)]\n",
      "[<operator-3597, linear_1_forward_branch_offload>] None None\n",
      "[<operator-1716, gelu_forward>] [Tensor(uid=1737,size=56)] [Tensor(uid=1738,size=56)]\n",
      "[<operator-3603, gelu_forward_branch_offload>] None None\n",
      "[<operator-1717, linear_2_forward>] [Tensor(uid=1738,size=56)] [Tensor(uid=1739,size=28)]\n",
      "[<operator-3609, linear_2_forward_branch_offload>] None None\n",
      "[<operator-1718, allreduce_forward>] [Tensor(uid=1739,size=28)] []\n",
      "[<operator-1719, dropout_forward>] [Tensor(uid=1739,size=28)] [Tensor(uid=1740,size=28), Tensor(uid=1741,size=14)]\n",
      "[<operator-1720, add_forward>] [Tensor(uid=1735,size=28), Tensor(uid=1740,size=28)] [Tensor(uid=1742,size=28)]\n",
      "[<operator-3615, add_forward_branch_offload>] None None\n",
      "[<operator-1721, layernorm_forward>] [Tensor(uid=1742,size=28)] [Tensor(uid=1743,size=28)]\n",
      "[<operator-1722, linear_qkv>] [Tensor(uid=1743,size=28)] [Tensor(uid=1744,size=42)]\n",
      "[<operator-1723, matmul_qk>] [Tensor(uid=1744,size=42)] [Tensor(uid=1745,size=128)]\n",
      "[<operator-1724, softmax_forward>] [Tensor(uid=1745,size=128)] [Tensor(uid=1746,size=128)]\n",
      "[<operator-1725, dropout_forward>] [Tensor(uid=1746,size=128)] [Tensor(uid=1747,size=128), Tensor(uid=1748,size=64)]\n",
      "[<operator-1726, matmul_v>] [Tensor(uid=1747,size=128), Tensor(uid=1744,size=42)] [Tensor(uid=1749,size=14)]\n",
      "[<operator-1727, linear_forward>] [Tensor(uid=1749,size=14)] [Tensor(uid=1750,size=28)]\n",
      "[<operator-1728, allreduce_forward>] [Tensor(uid=1750,size=28)] []\n",
      "[<operator-1729, output_dropout>] [Tensor(uid=1750,size=28)] [Tensor(uid=1751,size=28), Tensor(uid=1752,size=14)]\n",
      "[<operator-1730, add_forward>] [Tensor(uid=1742,size=28), Tensor(uid=1751,size=28)] [Tensor(uid=1753,size=28)]\n",
      "[<operator-1731, layernorm_forward>] [Tensor(uid=1753,size=28)] [Tensor(uid=1754,size=28)]\n",
      "[<operator-1732, linear_1_forward>] [Tensor(uid=1754,size=28)] [Tensor(uid=1755,size=56)]\n",
      "[<operator-1733, gelu_forward>] [Tensor(uid=1755,size=56)] [Tensor(uid=1756,size=56)]\n",
      "[<operator-1734, linear_2_forward>] [Tensor(uid=1756,size=56)] [Tensor(uid=1757,size=28)]\n",
      "[<operator-1735, allreduce_forward>] [Tensor(uid=1757,size=28)] []\n",
      "[<operator-1736, dropout_forward>] [Tensor(uid=1757,size=28)] [Tensor(uid=1758,size=28), Tensor(uid=1759,size=14)]\n",
      "[<operator-1737, add_forward>] [Tensor(uid=1753,size=28), Tensor(uid=1758,size=28)] [Tensor(uid=1760,size=28)]\n",
      "[<operator-1738, layernorm_forward>] [Tensor(uid=1760,size=28)] [Tensor(uid=1761,size=28)]\n",
      "[<operator-1739, linear_qkv>] [Tensor(uid=1761,size=28)] [Tensor(uid=1762,size=42)]\n",
      "[<operator-1740, matmul_qk>] [Tensor(uid=1762,size=42)] [Tensor(uid=1763,size=128)]\n",
      "[<operator-1741, softmax_forward>] [Tensor(uid=1763,size=128)] [Tensor(uid=1764,size=128)]\n",
      "[<operator-1742, dropout_forward>] [Tensor(uid=1764,size=128)] [Tensor(uid=1765,size=128), Tensor(uid=1766,size=64)]\n",
      "[<operator-1743, matmul_v>] [Tensor(uid=1765,size=128), Tensor(uid=1762,size=42)] [Tensor(uid=1767,size=14)]\n",
      "[<operator-1744, linear_forward>] [Tensor(uid=1767,size=14)] [Tensor(uid=1768,size=28)]\n",
      "[<operator-1745, allreduce_forward>] [Tensor(uid=1768,size=28)] []\n",
      "[<operator-1746, output_dropout>] [Tensor(uid=1768,size=28)] [Tensor(uid=1769,size=28), Tensor(uid=1770,size=14)]\n",
      "[<operator-1747, add_forward>] [Tensor(uid=1760,size=28), Tensor(uid=1769,size=28)] [Tensor(uid=1771,size=28)]\n",
      "[<operator-1748, layernorm_forward>] [Tensor(uid=1771,size=28)] [Tensor(uid=1772,size=28)]\n",
      "[<operator-1749, linear_1_forward>] [Tensor(uid=1772,size=28)] [Tensor(uid=1773,size=56)]\n",
      "[<operator-1750, gelu_forward>] [Tensor(uid=1773,size=56)] [Tensor(uid=1774,size=56)]\n",
      "[<operator-1751, linear_2_forward>] [Tensor(uid=1774,size=56)] [Tensor(uid=1775,size=28)]\n",
      "[<operator-1752, allreduce_forward>] [Tensor(uid=1775,size=28)] []\n",
      "[<operator-1753, dropout_forward>] [Tensor(uid=1775,size=28)] [Tensor(uid=1776,size=28), Tensor(uid=1777,size=14)]\n",
      "[<operator-1754, add_forward>] [Tensor(uid=1771,size=28), Tensor(uid=1776,size=28)] [Tensor(uid=1778,size=28)]\n",
      "[<operator-1755, layernorm_forward>] [Tensor(uid=1778,size=28)] [Tensor(uid=1779,size=28)]\n",
      "[<operator-1756, linear_qkv>] [Tensor(uid=1779,size=28)] [Tensor(uid=1780,size=42)]\n",
      "[<operator-1757, matmul_qk>] [Tensor(uid=1780,size=42)] [Tensor(uid=1781,size=128)]\n",
      "[<operator-1758, softmax_forward>] [Tensor(uid=1781,size=128)] [Tensor(uid=1782,size=128)]\n",
      "[<operator-1759, dropout_forward>] [Tensor(uid=1782,size=128)] [Tensor(uid=1783,size=128), Tensor(uid=1784,size=64)]\n",
      "[<operator-1760, matmul_v>] [Tensor(uid=1783,size=128), Tensor(uid=1780,size=42)] [Tensor(uid=1785,size=14)]\n",
      "[<operator-1761, linear_forward>] [Tensor(uid=1785,size=14)] [Tensor(uid=1786,size=28)]\n",
      "[<operator-1762, allreduce_forward>] [Tensor(uid=1786,size=28)] []\n",
      "[<operator-1763, output_dropout>] [Tensor(uid=1786,size=28)] [Tensor(uid=1787,size=28), Tensor(uid=1788,size=14)]\n",
      "[<operator-1764, add_forward>] [Tensor(uid=1778,size=28), Tensor(uid=1787,size=28)] [Tensor(uid=1789,size=28)]\n",
      "[<operator-1765, layernorm_forward>] [Tensor(uid=1789,size=28)] [Tensor(uid=1790,size=28)]\n",
      "[<operator-1766, linear_1_forward>] [Tensor(uid=1790,size=28)] [Tensor(uid=1791,size=56)]\n",
      "[<operator-1767, gelu_forward>] [Tensor(uid=1791,size=56)] [Tensor(uid=1792,size=56)]\n",
      "[<operator-1768, linear_2_forward>] [Tensor(uid=1792,size=56)] [Tensor(uid=1793,size=28)]\n",
      "[<operator-1769, allreduce_forward>] [Tensor(uid=1793,size=28)] []\n",
      "[<operator-1770, dropout_forward>] [Tensor(uid=1793,size=28)] [Tensor(uid=1794,size=28), Tensor(uid=1795,size=14)]\n",
      "[<operator-1771, add_forward>] [Tensor(uid=1789,size=28), Tensor(uid=1794,size=28)] [Tensor(uid=1796,size=28)]\n",
      "[<operator-1772, layernorm_forward>] [Tensor(uid=1796,size=28)] [Tensor(uid=1797,size=28)]\n",
      "[<operator-1773, linear_qkv>] [Tensor(uid=1797,size=28)] [Tensor(uid=1798,size=42)]\n",
      "[<operator-1774, matmul_qk>] [Tensor(uid=1798,size=42)] [Tensor(uid=1799,size=128)]\n",
      "[<operator-1775, softmax_forward>] [Tensor(uid=1799,size=128)] [Tensor(uid=1800,size=128)]\n",
      "[<operator-1776, dropout_forward>] [Tensor(uid=1800,size=128)] [Tensor(uid=1801,size=128), Tensor(uid=1802,size=64)]\n",
      "[<operator-1777, matmul_v>] [Tensor(uid=1801,size=128), Tensor(uid=1798,size=42)] [Tensor(uid=1803,size=14)]\n",
      "[<operator-1778, linear_forward>] [Tensor(uid=1803,size=14)] [Tensor(uid=1804,size=28)]\n",
      "[<operator-1779, allreduce_forward>] [Tensor(uid=1804,size=28)] []\n",
      "[<operator-1780, output_dropout>] [Tensor(uid=1804,size=28)] [Tensor(uid=1805,size=28), Tensor(uid=1806,size=14)]\n",
      "[<operator-1781, add_forward>] [Tensor(uid=1796,size=28), Tensor(uid=1805,size=28)] [Tensor(uid=1807,size=28)]\n",
      "[<operator-1782, layernorm_forward>] [Tensor(uid=1807,size=28)] [Tensor(uid=1808,size=28)]\n",
      "[<operator-1783, linear_1_forward>] [Tensor(uid=1808,size=28)] [Tensor(uid=1809,size=56)]\n",
      "[<operator-1784, gelu_forward>] [Tensor(uid=1809,size=56)] [Tensor(uid=1810,size=56)]\n",
      "[<operator-1785, linear_2_forward>] [Tensor(uid=1810,size=56)] [Tensor(uid=1811,size=28)]\n",
      "[<operator-1786, allreduce_forward>] [Tensor(uid=1811,size=28)] []\n",
      "[<operator-1787, dropout_forward>] [Tensor(uid=1811,size=28)] [Tensor(uid=1812,size=28), Tensor(uid=1813,size=14)]\n",
      "[<operator-1788, add_forward>] [Tensor(uid=1807,size=28), Tensor(uid=1812,size=28)] [Tensor(uid=1814,size=28)]\n",
      "[<operator-1789, layernorm_forward>] [Tensor(uid=1814,size=28)] [Tensor(uid=1815,size=28)]\n",
      "[<operator-1790, linear_qkv>] [Tensor(uid=1815,size=28)] [Tensor(uid=1816,size=42)]\n",
      "[<operator-1791, matmul_qk>] [Tensor(uid=1816,size=42)] [Tensor(uid=1817,size=128)]\n",
      "[<operator-1792, softmax_forward>] [Tensor(uid=1817,size=128)] [Tensor(uid=1818,size=128)]\n",
      "[<operator-1793, dropout_forward>] [Tensor(uid=1818,size=128)] [Tensor(uid=1819,size=128), Tensor(uid=1820,size=64)]\n",
      "[<operator-1794, matmul_v>] [Tensor(uid=1819,size=128), Tensor(uid=1816,size=42)] [Tensor(uid=1821,size=14)]\n",
      "[<operator-1795, linear_forward>] [Tensor(uid=1821,size=14)] [Tensor(uid=1822,size=28)]\n",
      "[<operator-1796, allreduce_forward>] [Tensor(uid=1822,size=28)] []\n",
      "[<operator-1797, output_dropout>] [Tensor(uid=1822,size=28)] [Tensor(uid=1823,size=28), Tensor(uid=1824,size=14)]\n",
      "[<operator-1798, add_forward>] [Tensor(uid=1814,size=28), Tensor(uid=1823,size=28)] [Tensor(uid=1825,size=28)]\n",
      "[<operator-1799, layernorm_forward>] [Tensor(uid=1825,size=28)] [Tensor(uid=1826,size=28)]\n",
      "[<operator-1800, linear_1_forward>] [Tensor(uid=1826,size=28)] [Tensor(uid=1827,size=56)]\n",
      "[<operator-1801, gelu_forward>] [Tensor(uid=1827,size=56)] [Tensor(uid=1828,size=56)]\n",
      "[<operator-1802, linear_2_forward>] [Tensor(uid=1828,size=56)] [Tensor(uid=1829,size=28)]\n",
      "[<operator-1803, allreduce_forward>] [Tensor(uid=1829,size=28)] []\n",
      "[<operator-1804, dropout_forward>] [Tensor(uid=1829,size=28)] [Tensor(uid=1830,size=28), Tensor(uid=1831,size=14)]\n",
      "[<operator-1805, add_forward>] [Tensor(uid=1825,size=28), Tensor(uid=1830,size=28)] [Tensor(uid=1832,size=28)]\n",
      "[<operator-1806, layernorm_forward>] [Tensor(uid=1832,size=28)] [Tensor(uid=1833,size=28)]\n",
      "[<operator-1807, linear_qkv>] [Tensor(uid=1833,size=28)] [Tensor(uid=1834,size=42)]\n",
      "[<operator-1808, matmul_qk>] [Tensor(uid=1834,size=42)] [Tensor(uid=1835,size=128)]\n",
      "[<operator-1809, softmax_forward>] [Tensor(uid=1835,size=128)] [Tensor(uid=1836,size=128)]\n",
      "[<operator-1810, dropout_forward>] [Tensor(uid=1836,size=128)] [Tensor(uid=1837,size=128), Tensor(uid=1838,size=64)]\n",
      "[<operator-1811, matmul_v>] [Tensor(uid=1837,size=128), Tensor(uid=1834,size=42)] [Tensor(uid=1839,size=14)]\n",
      "[<operator-1812, linear_forward>] [Tensor(uid=1839,size=14)] [Tensor(uid=1840,size=28)]\n",
      "[<operator-1813, allreduce_forward>] [Tensor(uid=1840,size=28)] []\n",
      "[<operator-1814, output_dropout>] [Tensor(uid=1840,size=28)] [Tensor(uid=1841,size=28), Tensor(uid=1842,size=14)]\n",
      "[<operator-1815, add_forward>] [Tensor(uid=1832,size=28), Tensor(uid=1841,size=28)] [Tensor(uid=1843,size=28)]\n",
      "[<operator-1816, layernorm_forward>] [Tensor(uid=1843,size=28)] [Tensor(uid=1844,size=28)]\n",
      "[<operator-1817, linear_1_forward>] [Tensor(uid=1844,size=28)] [Tensor(uid=1845,size=56)]\n",
      "[<operator-1818, gelu_forward>] [Tensor(uid=1845,size=56)] [Tensor(uid=1846,size=56)]\n",
      "[<operator-1819, linear_2_forward>] [Tensor(uid=1846,size=56)] [Tensor(uid=1847,size=28)]\n",
      "[<operator-1820, allreduce_forward>] [Tensor(uid=1847,size=28)] []\n",
      "[<operator-1821, dropout_forward>] [Tensor(uid=1847,size=28)] [Tensor(uid=1848,size=28), Tensor(uid=1849,size=14)]\n",
      "[<operator-1822, add_forward>] [Tensor(uid=1843,size=28), Tensor(uid=1848,size=28)] [Tensor(uid=1850,size=28)]\n",
      "[<operator-1823, layernorm_forward>] [Tensor(uid=1850,size=28)] [Tensor(uid=1851,size=28)]\n",
      "[<operator-1824, linear_qkv>] [Tensor(uid=1851,size=28)] [Tensor(uid=1852,size=42)]\n",
      "[<operator-1825, matmul_qk>] [Tensor(uid=1852,size=42)] [Tensor(uid=1853,size=128)]\n",
      "[<operator-1826, softmax_forward>] [Tensor(uid=1853,size=128)] [Tensor(uid=1854,size=128)]\n",
      "[<operator-1827, dropout_forward>] [Tensor(uid=1854,size=128)] [Tensor(uid=1855,size=128), Tensor(uid=1856,size=64)]\n",
      "[<operator-1828, matmul_v>] [Tensor(uid=1855,size=128), Tensor(uid=1852,size=42)] [Tensor(uid=1857,size=14)]\n",
      "[<operator-1829, linear_forward>] [Tensor(uid=1857,size=14)] [Tensor(uid=1858,size=28)]\n",
      "[<operator-1830, allreduce_forward>] [Tensor(uid=1858,size=28)] []\n",
      "[<operator-1831, output_dropout>] [Tensor(uid=1858,size=28)] [Tensor(uid=1859,size=28), Tensor(uid=1860,size=14)]\n",
      "[<operator-1832, add_forward>] [Tensor(uid=1850,size=28), Tensor(uid=1859,size=28)] [Tensor(uid=1861,size=28)]\n",
      "[<operator-1833, layernorm_forward>] [Tensor(uid=1861,size=28)] [Tensor(uid=1862,size=28)]\n",
      "[<operator-1834, linear_1_forward>] [Tensor(uid=1862,size=28)] [Tensor(uid=1863,size=56)]\n",
      "[<operator-1835, gelu_forward>] [Tensor(uid=1863,size=56)] [Tensor(uid=1864,size=56)]\n",
      "[<operator-1836, linear_2_forward>] [Tensor(uid=1864,size=56)] [Tensor(uid=1865,size=28)]\n",
      "[<operator-1837, allreduce_forward>] [Tensor(uid=1865,size=28)] []\n",
      "[<operator-1838, dropout_forward>] [Tensor(uid=1865,size=28)] [Tensor(uid=1866,size=28), Tensor(uid=1867,size=14)]\n",
      "[<operator-1839, add_forward>] [Tensor(uid=1861,size=28), Tensor(uid=1866,size=28)] [Tensor(uid=1868,size=28)]\n",
      "[<operator-1840, layernorm_forward>] [Tensor(uid=1868,size=28)] [Tensor(uid=1869,size=28)]\n",
      "[<operator-1841, linear_qkv>] [Tensor(uid=1869,size=28)] [Tensor(uid=1870,size=42)]\n",
      "[<operator-1842, matmul_qk>] [Tensor(uid=1870,size=42)] [Tensor(uid=1871,size=128)]\n",
      "[<operator-1843, softmax_forward>] [Tensor(uid=1871,size=128)] [Tensor(uid=1872,size=128)]\n",
      "[<operator-1844, dropout_forward>] [Tensor(uid=1872,size=128)] [Tensor(uid=1873,size=128), Tensor(uid=1874,size=64)]\n",
      "[<operator-1845, matmul_v>] [Tensor(uid=1873,size=128), Tensor(uid=1870,size=42)] [Tensor(uid=1875,size=14)]\n",
      "[<operator-1846, linear_forward>] [Tensor(uid=1875,size=14)] [Tensor(uid=1876,size=28)]\n",
      "[<operator-1847, allreduce_forward>] [Tensor(uid=1876,size=28)] []\n",
      "[<operator-1848, output_dropout>] [Tensor(uid=1876,size=28)] [Tensor(uid=1877,size=28), Tensor(uid=1878,size=14)]\n",
      "[<operator-1849, add_forward>] [Tensor(uid=1868,size=28), Tensor(uid=1877,size=28)] [Tensor(uid=1879,size=28)]\n",
      "[<operator-1850, layernorm_forward>] [Tensor(uid=1879,size=28)] [Tensor(uid=1880,size=28)]\n",
      "[<operator-1851, linear_1_forward>] [Tensor(uid=1880,size=28)] [Tensor(uid=1881,size=56)]\n",
      "[<operator-1852, gelu_forward>] [Tensor(uid=1881,size=56)] [Tensor(uid=1882,size=56)]\n",
      "[<operator-1853, linear_2_forward>] [Tensor(uid=1882,size=56)] [Tensor(uid=1883,size=28)]\n",
      "[<operator-1854, allreduce_forward>] [Tensor(uid=1883,size=28)] []\n",
      "[<operator-1855, dropout_forward>] [Tensor(uid=1883,size=28)] [Tensor(uid=1884,size=28), Tensor(uid=1885,size=14)]\n",
      "[<operator-1856, add_forward>] [Tensor(uid=1879,size=28), Tensor(uid=1884,size=28)] [Tensor(uid=1886,size=28)]\n",
      "[<operator-1857, layernorm_forward>] [Tensor(uid=1886,size=28)] [Tensor(uid=1887,size=28)]\n",
      "[<operator-1858, linear_qkv>] [Tensor(uid=1887,size=28)] [Tensor(uid=1888,size=42)]\n",
      "[<operator-1859, matmul_qk>] [Tensor(uid=1888,size=42)] [Tensor(uid=1889,size=128)]\n",
      "[<operator-1860, softmax_forward>] [Tensor(uid=1889,size=128)] [Tensor(uid=1890,size=128)]\n",
      "[<operator-1861, dropout_forward>] [Tensor(uid=1890,size=128)] [Tensor(uid=1891,size=128), Tensor(uid=1892,size=64)]\n",
      "[<operator-1862, matmul_v>] [Tensor(uid=1891,size=128), Tensor(uid=1888,size=42)] [Tensor(uid=1893,size=14)]\n",
      "[<operator-1863, linear_forward>] [Tensor(uid=1893,size=14)] [Tensor(uid=1894,size=28)]\n",
      "[<operator-1864, allreduce_forward>] [Tensor(uid=1894,size=28)] []\n",
      "[<operator-1865, output_dropout>] [Tensor(uid=1894,size=28)] [Tensor(uid=1895,size=28), Tensor(uid=1896,size=14)]\n",
      "[<operator-1866, add_forward>] [Tensor(uid=1886,size=28), Tensor(uid=1895,size=28)] [Tensor(uid=1897,size=28)]\n",
      "[<operator-1867, layernorm_forward>] [Tensor(uid=1897,size=28)] [Tensor(uid=1898,size=28)]\n",
      "[<operator-1868, linear_1_forward>] [Tensor(uid=1898,size=28)] [Tensor(uid=1899,size=56)]\n",
      "[<operator-1869, gelu_forward>] [Tensor(uid=1899,size=56)] [Tensor(uid=1900,size=56)]\n",
      "[<operator-1870, linear_2_forward>] [Tensor(uid=1900,size=56)] [Tensor(uid=1901,size=28)]\n",
      "[<operator-1871, allreduce_forward>] [Tensor(uid=1901,size=28)] []\n",
      "[<operator-1872, dropout_forward>] [Tensor(uid=1901,size=28)] [Tensor(uid=1902,size=28), Tensor(uid=1903,size=14)]\n",
      "[<operator-1873, add_forward>] [Tensor(uid=1897,size=28), Tensor(uid=1902,size=28)] [Tensor(uid=1904,size=28)]\n",
      "[<operator-1874, layernorm_forward>] [Tensor(uid=1904,size=28)] [Tensor(uid=1905,size=28)]\n",
      "[<operator-1875, linear_qkv>] [Tensor(uid=1905,size=28)] [Tensor(uid=1906,size=42)]\n",
      "[<operator-1876, matmul_qk>] [Tensor(uid=1906,size=42)] [Tensor(uid=1907,size=128)]\n",
      "[<operator-1877, softmax_forward>] [Tensor(uid=1907,size=128)] [Tensor(uid=1908,size=128)]\n",
      "[<operator-1878, dropout_forward>] [Tensor(uid=1908,size=128)] [Tensor(uid=1909,size=128), Tensor(uid=1910,size=64)]\n",
      "[<operator-1879, matmul_v>] [Tensor(uid=1909,size=128), Tensor(uid=1906,size=42)] [Tensor(uid=1911,size=14)]\n",
      "[<operator-1880, linear_forward>] [Tensor(uid=1911,size=14)] [Tensor(uid=1912,size=28)]\n",
      "[<operator-1881, allreduce_forward>] [Tensor(uid=1912,size=28)] []\n",
      "[<operator-1882, output_dropout>] [Tensor(uid=1912,size=28)] [Tensor(uid=1913,size=28), Tensor(uid=1914,size=14)]\n",
      "[<operator-1883, add_forward>] [Tensor(uid=1904,size=28), Tensor(uid=1913,size=28)] [Tensor(uid=1915,size=28)]\n",
      "[<operator-1884, layernorm_forward>] [Tensor(uid=1915,size=28)] [Tensor(uid=1916,size=28)]\n",
      "[<operator-1885, linear_1_forward>] [Tensor(uid=1916,size=28)] [Tensor(uid=1917,size=56)]\n",
      "[<operator-1886, gelu_forward>] [Tensor(uid=1917,size=56)] [Tensor(uid=1918,size=56)]\n",
      "[<operator-1887, linear_2_forward>] [Tensor(uid=1918,size=56)] [Tensor(uid=1919,size=28)]\n",
      "[<operator-1888, allreduce_forward>] [Tensor(uid=1919,size=28)] []\n",
      "[<operator-1889, dropout_forward>] [Tensor(uid=1919,size=28)] [Tensor(uid=1920,size=28), Tensor(uid=1921,size=14)]\n",
      "[<operator-1890, add_forward>] [Tensor(uid=1915,size=28), Tensor(uid=1920,size=28)] [Tensor(uid=1922,size=28)]\n",
      "[<operator-1891, loss_fn>] [Tensor(uid=1922,size=28)] [Tensor(uid=1923,size=28)]\n",
      "[<operator-3618, loss_fn_sync_merge>] None None\n",
      "[<operator-1892, dropout_backward>] [Tensor(uid=1920,size=28), Tensor(uid=1921,size=14), Tensor(uid=1923,size=28)] [Tensor(uid=1924,size=28)]\n",
      "[<operator-1893, linear_2_backward>] [Tensor(uid=1918,size=56), Tensor(uid=1924,size=28)] [Tensor(uid=1925,size=56)]\n",
      "[<operator-1894, gelu_backward>] [Tensor(uid=1917,size=56), Tensor(uid=1925,size=56)] [Tensor(uid=1926,size=56)]\n",
      "[<operator-1895, linear_1_backward>] [Tensor(uid=1916,size=28), Tensor(uid=1926,size=56)] [Tensor(uid=1927,size=28)]\n",
      "[<operator-1896, allreduce_backward>] [Tensor(uid=1927,size=28)] []\n",
      "[<operator-1897, layernorm_backward>] [Tensor(uid=1915,size=28), Tensor(uid=1927,size=28)] [Tensor(uid=1928,size=28)]\n",
      "[<operator-1898, backward_grad_accumulate_res1>] [Tensor(uid=1928,size=28), Tensor(uid=1923,size=28)] []\n",
      "[<operator-1899, output_dropout_backward>] [Tensor(uid=1913,size=28), Tensor(uid=1914,size=14), Tensor(uid=1928,size=28)] [Tensor(uid=1929,size=28)]\n",
      "[<operator-1900, linear_backward>] [Tensor(uid=1911,size=14), Tensor(uid=1929,size=28)] [Tensor(uid=1930,size=14)]\n",
      "[<operator-1901, matmul_v_backward>] [Tensor(uid=1909,size=128), Tensor(uid=1906,size=42), Tensor(uid=1930,size=14)] [Tensor(uid=1931,size=14), Tensor(uid=1932,size=128)]\n",
      "[<operator-1902, dropout_backward>] [Tensor(uid=1909,size=128), Tensor(uid=1910,size=64), Tensor(uid=1932,size=128)] [Tensor(uid=1933,size=128)]\n",
      "[<operator-1903, softmax_backward>] [Tensor(uid=1908,size=128), Tensor(uid=1933,size=128)] [Tensor(uid=1934,size=128)]\n",
      "[<operator-1904, matmul_qk_backward>] [Tensor(uid=1906,size=42), Tensor(uid=1934,size=128)] [Tensor(uid=1935,size=28)]\n",
      "[<operator-1905, linear_qkv_backward>] [Tensor(uid=1905,size=28), Tensor(uid=1931,size=14), Tensor(uid=1935,size=28)] [Tensor(uid=1936,size=28)]\n",
      "[<operator-1906, allreduce_backward>] [Tensor(uid=1936,size=28)] []\n",
      "[<operator-1907, layernorm_backward>] [Tensor(uid=1904,size=28), Tensor(uid=1936,size=28)] [Tensor(uid=1937,size=28)]\n",
      "[<operator-1908, backward_grad_accumulate_input>] [Tensor(uid=1937,size=28), Tensor(uid=1928,size=28)] []\n",
      "[<operator-1909, dropout_backward>] [Tensor(uid=1902,size=28), Tensor(uid=1903,size=14), Tensor(uid=1937,size=28)] [Tensor(uid=1938,size=28)]\n",
      "[<operator-1910, linear_2_backward>] [Tensor(uid=1900,size=56), Tensor(uid=1938,size=28)] [Tensor(uid=1939,size=56)]\n",
      "[<operator-1911, gelu_backward>] [Tensor(uid=1899,size=56), Tensor(uid=1939,size=56)] [Tensor(uid=1940,size=56)]\n",
      "[<operator-1912, linear_1_backward>] [Tensor(uid=1898,size=28), Tensor(uid=1940,size=56)] [Tensor(uid=1941,size=28)]\n",
      "[<operator-1913, allreduce_backward>] [Tensor(uid=1941,size=28)] []\n",
      "[<operator-1914, layernorm_backward>] [Tensor(uid=1897,size=28), Tensor(uid=1941,size=28)] [Tensor(uid=1942,size=28)]\n",
      "[<operator-1915, backward_grad_accumulate_res1>] [Tensor(uid=1942,size=28), Tensor(uid=1937,size=28)] []\n",
      "[<operator-1916, output_dropout_backward>] [Tensor(uid=1895,size=28), Tensor(uid=1896,size=14), Tensor(uid=1942,size=28)] [Tensor(uid=1943,size=28)]\n",
      "[<operator-1917, linear_backward>] [Tensor(uid=1893,size=14), Tensor(uid=1943,size=28)] [Tensor(uid=1944,size=14)]\n",
      "[<operator-1918, matmul_v_backward>] [Tensor(uid=1891,size=128), Tensor(uid=1888,size=42), Tensor(uid=1944,size=14)] [Tensor(uid=1945,size=14), Tensor(uid=1946,size=128)]\n",
      "[<operator-1919, dropout_backward>] [Tensor(uid=1891,size=128), Tensor(uid=1892,size=64), Tensor(uid=1946,size=128)] [Tensor(uid=1947,size=128)]\n",
      "[<operator-1920, softmax_backward>] [Tensor(uid=1890,size=128), Tensor(uid=1947,size=128)] [Tensor(uid=1948,size=128)]\n",
      "[<operator-1921, matmul_qk_backward>] [Tensor(uid=1888,size=42), Tensor(uid=1948,size=128)] [Tensor(uid=1949,size=28)]\n",
      "[<operator-1922, linear_qkv_backward>] [Tensor(uid=1887,size=28), Tensor(uid=1945,size=14), Tensor(uid=1949,size=28)] [Tensor(uid=1950,size=28)]\n",
      "[<operator-1923, allreduce_backward>] [Tensor(uid=1950,size=28)] []\n",
      "[<operator-1924, layernorm_backward>] [Tensor(uid=1886,size=28), Tensor(uid=1950,size=28)] [Tensor(uid=1951,size=28)]\n",
      "[<operator-1925, backward_grad_accumulate_input>] [Tensor(uid=1951,size=28), Tensor(uid=1942,size=28)] []\n",
      "[<operator-1926, dropout_backward>] [Tensor(uid=1884,size=28), Tensor(uid=1885,size=14), Tensor(uid=1951,size=28)] [Tensor(uid=1952,size=28)]\n",
      "[<operator-1927, linear_2_backward>] [Tensor(uid=1882,size=56), Tensor(uid=1952,size=28)] [Tensor(uid=1953,size=56)]\n",
      "[<operator-1928, gelu_backward>] [Tensor(uid=1881,size=56), Tensor(uid=1953,size=56)] [Tensor(uid=1954,size=56)]\n",
      "[<operator-1929, linear_1_backward>] [Tensor(uid=1880,size=28), Tensor(uid=1954,size=56)] [Tensor(uid=1955,size=28)]\n",
      "[<operator-1930, allreduce_backward>] [Tensor(uid=1955,size=28)] []\n",
      "[<operator-1931, layernorm_backward>] [Tensor(uid=1879,size=28), Tensor(uid=1955,size=28)] [Tensor(uid=1956,size=28)]\n",
      "[<operator-1932, backward_grad_accumulate_res1>] [Tensor(uid=1956,size=28), Tensor(uid=1951,size=28)] []\n",
      "[<operator-1933, output_dropout_backward>] [Tensor(uid=1877,size=28), Tensor(uid=1878,size=14), Tensor(uid=1956,size=28)] [Tensor(uid=1957,size=28)]\n",
      "[<operator-1934, linear_backward>] [Tensor(uid=1875,size=14), Tensor(uid=1957,size=28)] [Tensor(uid=1958,size=14)]\n",
      "[<operator-1935, matmul_v_backward>] [Tensor(uid=1873,size=128), Tensor(uid=1870,size=42), Tensor(uid=1958,size=14)] [Tensor(uid=1959,size=14), Tensor(uid=1960,size=128)]\n",
      "[<operator-1936, dropout_backward>] [Tensor(uid=1873,size=128), Tensor(uid=1874,size=64), Tensor(uid=1960,size=128)] [Tensor(uid=1961,size=128)]\n",
      "[<operator-1937, softmax_backward>] [Tensor(uid=1872,size=128), Tensor(uid=1961,size=128)] [Tensor(uid=1962,size=128)]\n",
      "[<operator-1938, matmul_qk_backward>] [Tensor(uid=1870,size=42), Tensor(uid=1962,size=128)] [Tensor(uid=1963,size=28)]\n",
      "[<operator-1939, linear_qkv_backward>] [Tensor(uid=1869,size=28), Tensor(uid=1959,size=14), Tensor(uid=1963,size=28)] [Tensor(uid=1964,size=28)]\n",
      "[<operator-1940, allreduce_backward>] [Tensor(uid=1964,size=28)] []\n",
      "[<operator-1941, layernorm_backward>] [Tensor(uid=1868,size=28), Tensor(uid=1964,size=28)] [Tensor(uid=1965,size=28)]\n",
      "[<operator-1942, backward_grad_accumulate_input>] [Tensor(uid=1965,size=28), Tensor(uid=1956,size=28)] []\n",
      "[<operator-1943, dropout_backward>] [Tensor(uid=1866,size=28), Tensor(uid=1867,size=14), Tensor(uid=1965,size=28)] [Tensor(uid=1966,size=28)]\n",
      "[<operator-1944, linear_2_backward>] [Tensor(uid=1864,size=56), Tensor(uid=1966,size=28)] [Tensor(uid=1967,size=56)]\n",
      "[<operator-1945, gelu_backward>] [Tensor(uid=1863,size=56), Tensor(uid=1967,size=56)] [Tensor(uid=1968,size=56)]\n",
      "[<operator-1946, linear_1_backward>] [Tensor(uid=1862,size=28), Tensor(uid=1968,size=56)] [Tensor(uid=1969,size=28)]\n",
      "[<operator-1947, allreduce_backward>] [Tensor(uid=1969,size=28)] []\n",
      "[<operator-1948, layernorm_backward>] [Tensor(uid=1861,size=28), Tensor(uid=1969,size=28)] [Tensor(uid=1970,size=28)]\n",
      "[<operator-1949, backward_grad_accumulate_res1>] [Tensor(uid=1970,size=28), Tensor(uid=1965,size=28)] []\n",
      "[<operator-1950, output_dropout_backward>] [Tensor(uid=1859,size=28), Tensor(uid=1860,size=14), Tensor(uid=1970,size=28)] [Tensor(uid=1971,size=28)]\n",
      "[<operator-1951, linear_backward>] [Tensor(uid=1857,size=14), Tensor(uid=1971,size=28)] [Tensor(uid=1972,size=14)]\n",
      "[<operator-1952, matmul_v_backward>] [Tensor(uid=1855,size=128), Tensor(uid=1852,size=42), Tensor(uid=1972,size=14)] [Tensor(uid=1973,size=14), Tensor(uid=1974,size=128)]\n",
      "[<operator-1953, dropout_backward>] [Tensor(uid=1855,size=128), Tensor(uid=1856,size=64), Tensor(uid=1974,size=128)] [Tensor(uid=1975,size=128)]\n",
      "[<operator-1954, softmax_backward>] [Tensor(uid=1854,size=128), Tensor(uid=1975,size=128)] [Tensor(uid=1976,size=128)]\n",
      "[<operator-1955, matmul_qk_backward>] [Tensor(uid=1852,size=42), Tensor(uid=1976,size=128)] [Tensor(uid=1977,size=28)]\n",
      "[<operator-1956, linear_qkv_backward>] [Tensor(uid=1851,size=28), Tensor(uid=1973,size=14), Tensor(uid=1977,size=28)] [Tensor(uid=1978,size=28)]\n",
      "[<operator-1957, allreduce_backward>] [Tensor(uid=1978,size=28)] []\n",
      "[<operator-1958, layernorm_backward>] [Tensor(uid=1850,size=28), Tensor(uid=1978,size=28)] [Tensor(uid=1979,size=28)]\n",
      "[<operator-1959, backward_grad_accumulate_input>] [Tensor(uid=1979,size=28), Tensor(uid=1970,size=28)] []\n",
      "[<operator-1960, dropout_backward>] [Tensor(uid=1848,size=28), Tensor(uid=1849,size=14), Tensor(uid=1979,size=28)] [Tensor(uid=1980,size=28)]\n",
      "[<operator-1961, linear_2_backward>] [Tensor(uid=1846,size=56), Tensor(uid=1980,size=28)] [Tensor(uid=1981,size=56)]\n",
      "[<operator-1962, gelu_backward>] [Tensor(uid=1845,size=56), Tensor(uid=1981,size=56)] [Tensor(uid=1982,size=56)]\n",
      "[<operator-1963, linear_1_backward>] [Tensor(uid=1844,size=28), Tensor(uid=1982,size=56)] [Tensor(uid=1983,size=28)]\n",
      "[<operator-1964, allreduce_backward>] [Tensor(uid=1983,size=28)] []\n",
      "[<operator-1965, layernorm_backward>] [Tensor(uid=1843,size=28), Tensor(uid=1983,size=28)] [Tensor(uid=1984,size=28)]\n",
      "[<operator-1966, backward_grad_accumulate_res1>] [Tensor(uid=1984,size=28), Tensor(uid=1979,size=28)] []\n",
      "[<operator-1967, output_dropout_backward>] [Tensor(uid=1841,size=28), Tensor(uid=1842,size=14), Tensor(uid=1984,size=28)] [Tensor(uid=1985,size=28)]\n",
      "[<operator-1968, linear_backward>] [Tensor(uid=1839,size=14), Tensor(uid=1985,size=28)] [Tensor(uid=1986,size=14)]\n",
      "[<operator-1969, matmul_v_backward>] [Tensor(uid=1837,size=128), Tensor(uid=1834,size=42), Tensor(uid=1986,size=14)] [Tensor(uid=1987,size=14), Tensor(uid=1988,size=128)]\n",
      "[<operator-1970, dropout_backward>] [Tensor(uid=1837,size=128), Tensor(uid=1838,size=64), Tensor(uid=1988,size=128)] [Tensor(uid=1989,size=128)]\n",
      "[<operator-1971, softmax_backward>] [Tensor(uid=1836,size=128), Tensor(uid=1989,size=128)] [Tensor(uid=1990,size=128)]\n",
      "[<operator-1972, matmul_qk_backward>] [Tensor(uid=1834,size=42), Tensor(uid=1990,size=128)] [Tensor(uid=1991,size=28)]\n",
      "[<operator-1973, linear_qkv_backward>] [Tensor(uid=1833,size=28), Tensor(uid=1987,size=14), Tensor(uid=1991,size=28)] [Tensor(uid=1992,size=28)]\n",
      "[<operator-1974, allreduce_backward>] [Tensor(uid=1992,size=28)] []\n",
      "[<operator-1975, layernorm_backward>] [Tensor(uid=1832,size=28), Tensor(uid=1992,size=28)] [Tensor(uid=1993,size=28)]\n",
      "[<operator-1976, backward_grad_accumulate_input>] [Tensor(uid=1993,size=28), Tensor(uid=1984,size=28)] []\n",
      "[<operator-1977, dropout_backward>] [Tensor(uid=1830,size=28), Tensor(uid=1831,size=14), Tensor(uid=1993,size=28)] [Tensor(uid=1994,size=28)]\n",
      "[<operator-1978, linear_2_backward>] [Tensor(uid=1828,size=56), Tensor(uid=1994,size=28)] [Tensor(uid=1995,size=56)]\n",
      "[<operator-1979, gelu_backward>] [Tensor(uid=1827,size=56), Tensor(uid=1995,size=56)] [Tensor(uid=1996,size=56)]\n",
      "[<operator-1980, linear_1_backward>] [Tensor(uid=1826,size=28), Tensor(uid=1996,size=56)] [Tensor(uid=1997,size=28)]\n",
      "[<operator-1981, allreduce_backward>] [Tensor(uid=1997,size=28)] []\n",
      "[<operator-1982, layernorm_backward>] [Tensor(uid=1825,size=28), Tensor(uid=1997,size=28)] [Tensor(uid=1998,size=28)]\n",
      "[<operator-1983, backward_grad_accumulate_res1>] [Tensor(uid=1998,size=28), Tensor(uid=1993,size=28)] []\n",
      "[<operator-1984, output_dropout_backward>] [Tensor(uid=1823,size=28), Tensor(uid=1824,size=14), Tensor(uid=1998,size=28)] [Tensor(uid=1999,size=28)]\n",
      "[<operator-1985, linear_backward>] [Tensor(uid=1821,size=14), Tensor(uid=1999,size=28)] [Tensor(uid=2000,size=14)]\n",
      "[<operator-1986, matmul_v_backward>] [Tensor(uid=1819,size=128), Tensor(uid=1816,size=42), Tensor(uid=2000,size=14)] [Tensor(uid=2001,size=14), Tensor(uid=2002,size=128)]\n",
      "[<operator-1987, dropout_backward>] [Tensor(uid=1819,size=128), Tensor(uid=1820,size=64), Tensor(uid=2002,size=128)] [Tensor(uid=2003,size=128)]\n",
      "[<operator-1988, softmax_backward>] [Tensor(uid=1818,size=128), Tensor(uid=2003,size=128)] [Tensor(uid=2004,size=128)]\n",
      "[<operator-1989, matmul_qk_backward>] [Tensor(uid=1816,size=42), Tensor(uid=2004,size=128)] [Tensor(uid=2005,size=28)]\n",
      "[<operator-1990, linear_qkv_backward>] [Tensor(uid=1815,size=28), Tensor(uid=2001,size=14), Tensor(uid=2005,size=28)] [Tensor(uid=2006,size=28)]\n",
      "[<operator-1991, allreduce_backward>] [Tensor(uid=2006,size=28)] []\n",
      "[<operator-1992, layernorm_backward>] [Tensor(uid=1814,size=28), Tensor(uid=2006,size=28)] [Tensor(uid=2007,size=28)]\n",
      "[<operator-1993, backward_grad_accumulate_input>] [Tensor(uid=2007,size=28), Tensor(uid=1998,size=28)] []\n",
      "[<operator-1994, dropout_backward>] [Tensor(uid=1812,size=28), Tensor(uid=1813,size=14), Tensor(uid=2007,size=28)] [Tensor(uid=2008,size=28)]\n",
      "[<operator-1995, linear_2_backward>] [Tensor(uid=1810,size=56), Tensor(uid=2008,size=28)] [Tensor(uid=2009,size=56)]\n",
      "[<operator-1996, gelu_backward>] [Tensor(uid=1809,size=56), Tensor(uid=2009,size=56)] [Tensor(uid=2010,size=56)]\n",
      "[<operator-1997, linear_1_backward>] [Tensor(uid=1808,size=28), Tensor(uid=2010,size=56)] [Tensor(uid=2011,size=28)]\n",
      "[<operator-1998, allreduce_backward>] [Tensor(uid=2011,size=28)] []\n",
      "[<operator-1999, layernorm_backward>] [Tensor(uid=1807,size=28), Tensor(uid=2011,size=28)] [Tensor(uid=2012,size=28)]\n",
      "[<operator-2000, backward_grad_accumulate_res1>] [Tensor(uid=2012,size=28), Tensor(uid=2007,size=28)] []\n",
      "[<operator-2001, output_dropout_backward>] [Tensor(uid=1805,size=28), Tensor(uid=1806,size=14), Tensor(uid=2012,size=28)] [Tensor(uid=2013,size=28)]\n",
      "[<operator-2002, linear_backward>] [Tensor(uid=1803,size=14), Tensor(uid=2013,size=28)] [Tensor(uid=2014,size=14)]\n",
      "[<operator-2003, matmul_v_backward>] [Tensor(uid=1801,size=128), Tensor(uid=1798,size=42), Tensor(uid=2014,size=14)] [Tensor(uid=2015,size=14), Tensor(uid=2016,size=128)]\n",
      "[<operator-2004, dropout_backward>] [Tensor(uid=1801,size=128), Tensor(uid=1802,size=64), Tensor(uid=2016,size=128)] [Tensor(uid=2017,size=128)]\n",
      "[<operator-2005, softmax_backward>] [Tensor(uid=1800,size=128), Tensor(uid=2017,size=128)] [Tensor(uid=2018,size=128)]\n",
      "[<operator-2006, matmul_qk_backward>] [Tensor(uid=1798,size=42), Tensor(uid=2018,size=128)] [Tensor(uid=2019,size=28)]\n",
      "[<operator-2007, linear_qkv_backward>] [Tensor(uid=1797,size=28), Tensor(uid=2015,size=14), Tensor(uid=2019,size=28)] [Tensor(uid=2020,size=28)]\n",
      "[<operator-2008, allreduce_backward>] [Tensor(uid=2020,size=28)] []\n",
      "[<operator-2009, layernorm_backward>] [Tensor(uid=1796,size=28), Tensor(uid=2020,size=28)] [Tensor(uid=2021,size=28)]\n",
      "[<operator-2010, backward_grad_accumulate_input>] [Tensor(uid=2021,size=28), Tensor(uid=2012,size=28)] []\n",
      "[<operator-2011, dropout_backward>] [Tensor(uid=1794,size=28), Tensor(uid=1795,size=14), Tensor(uid=2021,size=28)] [Tensor(uid=2022,size=28)]\n",
      "[<operator-2012, linear_2_backward>] [Tensor(uid=1792,size=56), Tensor(uid=2022,size=28)] [Tensor(uid=2023,size=56)]\n",
      "[<operator-2013, gelu_backward>] [Tensor(uid=1791,size=56), Tensor(uid=2023,size=56)] [Tensor(uid=2024,size=56)]\n",
      "[<operator-2014, linear_1_backward>] [Tensor(uid=1790,size=28), Tensor(uid=2024,size=56)] [Tensor(uid=2025,size=28)]\n",
      "[<operator-2015, allreduce_backward>] [Tensor(uid=2025,size=28)] []\n",
      "[<operator-2016, layernorm_backward>] [Tensor(uid=1789,size=28), Tensor(uid=2025,size=28)] [Tensor(uid=2026,size=28)]\n",
      "[<operator-2017, backward_grad_accumulate_res1>] [Tensor(uid=2026,size=28), Tensor(uid=2021,size=28)] []\n",
      "[<operator-2018, output_dropout_backward>] [Tensor(uid=1787,size=28), Tensor(uid=1788,size=14), Tensor(uid=2026,size=28)] [Tensor(uid=2027,size=28)]\n",
      "[<operator-2019, linear_backward>] [Tensor(uid=1785,size=14), Tensor(uid=2027,size=28)] [Tensor(uid=2028,size=14)]\n",
      "[<operator-2020, matmul_v_backward>] [Tensor(uid=1783,size=128), Tensor(uid=1780,size=42), Tensor(uid=2028,size=14)] [Tensor(uid=2029,size=14), Tensor(uid=2030,size=128)]\n",
      "[<operator-2021, dropout_backward>] [Tensor(uid=1783,size=128), Tensor(uid=1784,size=64), Tensor(uid=2030,size=128)] [Tensor(uid=2031,size=128)]\n",
      "[<operator-2022, softmax_backward>] [Tensor(uid=1782,size=128), Tensor(uid=2031,size=128)] [Tensor(uid=2032,size=128)]\n",
      "[<operator-2023, matmul_qk_backward>] [Tensor(uid=1780,size=42), Tensor(uid=2032,size=128)] [Tensor(uid=2033,size=28)]\n",
      "[<operator-2024, linear_qkv_backward>] [Tensor(uid=1779,size=28), Tensor(uid=2029,size=14), Tensor(uid=2033,size=28)] [Tensor(uid=2034,size=28)]\n",
      "[<operator-2025, allreduce_backward>] [Tensor(uid=2034,size=28)] []\n",
      "[<operator-2026, layernorm_backward>] [Tensor(uid=1778,size=28), Tensor(uid=2034,size=28)] [Tensor(uid=2035,size=28)]\n",
      "[<operator-2027, backward_grad_accumulate_input>] [Tensor(uid=2035,size=28), Tensor(uid=2026,size=28)] []\n",
      "[<operator-2028, dropout_backward>] [Tensor(uid=1776,size=28), Tensor(uid=1777,size=14), Tensor(uid=2035,size=28)] [Tensor(uid=2036,size=28)]\n",
      "[<operator-2029, linear_2_backward>] [Tensor(uid=1774,size=56), Tensor(uid=2036,size=28)] [Tensor(uid=2037,size=56)]\n",
      "[<operator-2030, gelu_backward>] [Tensor(uid=1773,size=56), Tensor(uid=2037,size=56)] [Tensor(uid=2038,size=56)]\n",
      "[<operator-2031, linear_1_backward>] [Tensor(uid=1772,size=28), Tensor(uid=2038,size=56)] [Tensor(uid=2039,size=28)]\n",
      "[<operator-2032, allreduce_backward>] [Tensor(uid=2039,size=28)] []\n",
      "[<operator-2033, layernorm_backward>] [Tensor(uid=1771,size=28), Tensor(uid=2039,size=28)] [Tensor(uid=2040,size=28)]\n",
      "[<operator-2034, backward_grad_accumulate_res1>] [Tensor(uid=2040,size=28), Tensor(uid=2035,size=28)] []\n",
      "[<operator-2035, output_dropout_backward>] [Tensor(uid=1769,size=28), Tensor(uid=1770,size=14), Tensor(uid=2040,size=28)] [Tensor(uid=2041,size=28)]\n",
      "[<operator-2036, linear_backward>] [Tensor(uid=1767,size=14), Tensor(uid=2041,size=28)] [Tensor(uid=2042,size=14)]\n",
      "[<operator-2037, matmul_v_backward>] [Tensor(uid=1765,size=128), Tensor(uid=1762,size=42), Tensor(uid=2042,size=14)] [Tensor(uid=2043,size=14), Tensor(uid=2044,size=128)]\n",
      "[<operator-2038, dropout_backward>] [Tensor(uid=1765,size=128), Tensor(uid=1766,size=64), Tensor(uid=2044,size=128)] [Tensor(uid=2045,size=128)]\n",
      "[<operator-2039, softmax_backward>] [Tensor(uid=1764,size=128), Tensor(uid=2045,size=128)] [Tensor(uid=2046,size=128)]\n",
      "[<operator-2040, matmul_qk_backward>] [Tensor(uid=1762,size=42), Tensor(uid=2046,size=128)] [Tensor(uid=2047,size=28)]\n",
      "[<operator-2041, linear_qkv_backward>] [Tensor(uid=1761,size=28), Tensor(uid=2043,size=14), Tensor(uid=2047,size=28)] [Tensor(uid=2048,size=28)]\n",
      "[<operator-2042, allreduce_backward>] [Tensor(uid=2048,size=28)] []\n",
      "[<operator-2043, layernorm_backward>] [Tensor(uid=1760,size=28), Tensor(uid=2048,size=28)] [Tensor(uid=2049,size=28)]\n",
      "[<operator-2044, backward_grad_accumulate_input>] [Tensor(uid=2049,size=28), Tensor(uid=2040,size=28)] []\n",
      "[<operator-2045, dropout_backward>] [Tensor(uid=1758,size=28), Tensor(uid=1759,size=14), Tensor(uid=2049,size=28)] [Tensor(uid=2050,size=28)]\n",
      "[<operator-2046, linear_2_backward>] [Tensor(uid=1756,size=56), Tensor(uid=2050,size=28)] [Tensor(uid=2051,size=56)]\n",
      "[<operator-2047, gelu_backward>] [Tensor(uid=1755,size=56), Tensor(uid=2051,size=56)] [Tensor(uid=2052,size=56)]\n",
      "[<operator-2048, linear_1_backward>] [Tensor(uid=1754,size=28), Tensor(uid=2052,size=56)] [Tensor(uid=2053,size=28)]\n",
      "[<operator-2049, allreduce_backward>] [Tensor(uid=2053,size=28)] []\n",
      "[<operator-2050, layernorm_backward>] [Tensor(uid=1753,size=28), Tensor(uid=2053,size=28)] [Tensor(uid=2054,size=28)]\n",
      "[<operator-2051, backward_grad_accumulate_res1>] [Tensor(uid=2054,size=28), Tensor(uid=2049,size=28)] []\n",
      "[<operator-2052, output_dropout_backward>] [Tensor(uid=1751,size=28), Tensor(uid=1752,size=14), Tensor(uid=2054,size=28)] [Tensor(uid=2055,size=28)]\n",
      "[<operator-2053, linear_backward>] [Tensor(uid=1749,size=14), Tensor(uid=2055,size=28)] [Tensor(uid=2056,size=14)]\n",
      "[<operator-2054, matmul_v_backward>] [Tensor(uid=1747,size=128), Tensor(uid=1744,size=42), Tensor(uid=2056,size=14)] [Tensor(uid=2057,size=14), Tensor(uid=2058,size=128)]\n",
      "[<operator-2055, dropout_backward>] [Tensor(uid=1747,size=128), Tensor(uid=1748,size=64), Tensor(uid=2058,size=128)] [Tensor(uid=2059,size=128)]\n",
      "[<operator-2056, softmax_backward>] [Tensor(uid=1746,size=128), Tensor(uid=2059,size=128)] [Tensor(uid=2060,size=128)]\n",
      "[<operator-2057, matmul_qk_backward>] [Tensor(uid=1744,size=42), Tensor(uid=2060,size=128)] [Tensor(uid=2061,size=28)]\n",
      "[<operator-2058, linear_qkv_backward>] [Tensor(uid=1743,size=28), Tensor(uid=2057,size=14), Tensor(uid=2061,size=28)] [Tensor(uid=2062,size=28)]\n",
      "[<operator-2059, allreduce_backward>] [Tensor(uid=2062,size=28)] []\n",
      "[<operator-2060, layernorm_backward>] [Tensor(uid=1742,size=28), Tensor(uid=2062,size=28)] [Tensor(uid=2063,size=28)]\n",
      "[<operator-2061, backward_grad_accumulate_input>] [Tensor(uid=2063,size=28), Tensor(uid=2054,size=28)] []\n",
      "[<operator-2062, dropout_backward>] [Tensor(uid=1740,size=28), Tensor(uid=1741,size=14), Tensor(uid=2063,size=28)] [Tensor(uid=2064,size=28)]\n",
      "[<operator-3610, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3611, linear_2_forward_merge>] None None\n",
      "[<operator-2063, linear_2_backward>] [Tensor(uid=1738,size=56), Tensor(uid=2064,size=28)] [Tensor(uid=2065,size=56)]\n",
      "[<operator-3604, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3605, gelu_forward_merge>] None None\n",
      "[<operator-2064, gelu_backward>] [Tensor(uid=1737,size=56), Tensor(uid=2065,size=56)] [Tensor(uid=2066,size=56)]\n",
      "[<operator-3598, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3599, linear_1_forward_merge>] None None\n",
      "[<operator-2065, linear_1_backward>] [Tensor(uid=1736,size=28), Tensor(uid=2066,size=56)] [Tensor(uid=2067,size=28)]\n",
      "[<operator-2066, allreduce_backward>] [Tensor(uid=2067,size=28)] []\n",
      "[<operator-3616, add_forward_branch_loadin>] None None\n",
      "[<operator-3617, add_forward_merge>] None None\n",
      "[<operator-2067, layernorm_backward>] [Tensor(uid=1735,size=28), Tensor(uid=2067,size=28)] [Tensor(uid=2068,size=28)]\n",
      "[<operator-2068, backward_grad_accumulate_res1>] [Tensor(uid=2068,size=28), Tensor(uid=2063,size=28)] []\n",
      "[<operator-2069, output_dropout_backward>] [Tensor(uid=1733,size=28), Tensor(uid=1734,size=14), Tensor(uid=2068,size=28)] [Tensor(uid=2069,size=28)]\n",
      "[<operator-3586, linear_forward_branch_loadin>] None None\n",
      "[<operator-3587, linear_forward_merge>] None None\n",
      "[<operator-2070, linear_backward>] [Tensor(uid=1731,size=14), Tensor(uid=2069,size=28)] [Tensor(uid=2070,size=14)]\n",
      "[<operator-3580, matmul_v_branch_loadin>] None None\n",
      "[<operator-3581, matmul_v_merge>] None None\n",
      "[<operator-2071, matmul_v_backward>] [Tensor(uid=1729,size=128), Tensor(uid=1726,size=42), Tensor(uid=2070,size=14)] [Tensor(uid=2071,size=14), Tensor(uid=2072,size=128)]\n",
      "[<operator-2072, dropout_backward>] [Tensor(uid=1729,size=128), Tensor(uid=1730,size=64), Tensor(uid=2072,size=128)] [Tensor(uid=2073,size=128)]\n",
      "[<operator-3574, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3575, dropout_forward_merge>] None None\n",
      "[<operator-2073, softmax_backward>] [Tensor(uid=1728,size=128), Tensor(uid=2073,size=128)] [Tensor(uid=2074,size=128)]\n",
      "[<operator-2074, matmul_qk_backward>] [Tensor(uid=1726,size=42), Tensor(uid=2074,size=128)] [Tensor(uid=2075,size=28)]\n",
      "[<operator-3568, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3569, linear_qkv_merge>] None None\n",
      "[<operator-2075, linear_qkv_backward>] [Tensor(uid=1725,size=28), Tensor(uid=2071,size=14), Tensor(uid=2075,size=28)] [Tensor(uid=2076,size=28)]\n",
      "[<operator-2076, allreduce_backward>] [Tensor(uid=2076,size=28)] []\n",
      "[<operator-3592, add_forward_branch_loadin>] None None\n",
      "[<operator-3593, add_forward_merge>] None None\n",
      "[<operator-2077, layernorm_backward>] [Tensor(uid=1724,size=28), Tensor(uid=2076,size=28)] [Tensor(uid=2077,size=28)]\n",
      "[<operator-2078, backward_grad_accumulate_input>] [Tensor(uid=2077,size=28), Tensor(uid=2068,size=28)] []\n",
      "[<operator-2079, dropout_backward>] [Tensor(uid=1722,size=28), Tensor(uid=1723,size=14), Tensor(uid=2077,size=28)] [Tensor(uid=2078,size=28)]\n",
      "[<operator-3556, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3557, linear_2_forward_merge>] None None\n",
      "[<operator-2080, linear_2_backward>] [Tensor(uid=1720,size=56), Tensor(uid=2078,size=28)] [Tensor(uid=2079,size=56)]\n",
      "[<operator-3550, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3551, gelu_forward_merge>] None None\n",
      "[<operator-2081, gelu_backward>] [Tensor(uid=1719,size=56), Tensor(uid=2079,size=56)] [Tensor(uid=2080,size=56)]\n",
      "[<operator-3544, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3545, linear_1_forward_merge>] None None\n",
      "[<operator-2082, linear_1_backward>] [Tensor(uid=1718,size=28), Tensor(uid=2080,size=56)] [Tensor(uid=2081,size=28)]\n",
      "[<operator-2083, allreduce_backward>] [Tensor(uid=2081,size=28)] []\n",
      "[<operator-3562, add_forward_branch_loadin>] None None\n",
      "[<operator-3563, add_forward_merge>] None None\n",
      "[<operator-2084, layernorm_backward>] [Tensor(uid=1717,size=28), Tensor(uid=2081,size=28)] [Tensor(uid=2082,size=28)]\n",
      "[<operator-2085, backward_grad_accumulate_res1>] [Tensor(uid=2082,size=28), Tensor(uid=2077,size=28)] []\n",
      "[<operator-2086, output_dropout_backward>] [Tensor(uid=1715,size=28), Tensor(uid=1716,size=14), Tensor(uid=2082,size=28)] [Tensor(uid=2083,size=28)]\n",
      "[<operator-3532, linear_forward_branch_loadin>] None None\n",
      "[<operator-3533, linear_forward_merge>] None None\n",
      "[<operator-2087, linear_backward>] [Tensor(uid=1713,size=14), Tensor(uid=2083,size=28)] [Tensor(uid=2084,size=14)]\n",
      "[<operator-3526, matmul_v_branch_loadin>] None None\n",
      "[<operator-3527, matmul_v_merge>] None None\n",
      "[<operator-2088, matmul_v_backward>] [Tensor(uid=1711,size=128), Tensor(uid=1708,size=42), Tensor(uid=2084,size=14)] [Tensor(uid=2085,size=14), Tensor(uid=2086,size=128)]\n",
      "[<operator-2089, dropout_backward>] [Tensor(uid=1711,size=128), Tensor(uid=1712,size=64), Tensor(uid=2086,size=128)] [Tensor(uid=2087,size=128)]\n",
      "[<operator-3520, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3521, dropout_forward_merge>] None None\n",
      "[<operator-2090, softmax_backward>] [Tensor(uid=1710,size=128), Tensor(uid=2087,size=128)] [Tensor(uid=2088,size=128)]\n",
      "[<operator-2091, matmul_qk_backward>] [Tensor(uid=1708,size=42), Tensor(uid=2088,size=128)] [Tensor(uid=2089,size=28)]\n",
      "[<operator-3514, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3515, linear_qkv_merge>] None None\n",
      "[<operator-2092, linear_qkv_backward>] [Tensor(uid=1707,size=28), Tensor(uid=2085,size=14), Tensor(uid=2089,size=28)] [Tensor(uid=2090,size=28)]\n",
      "[<operator-2093, allreduce_backward>] [Tensor(uid=2090,size=28)] []\n",
      "[<operator-3538, add_forward_branch_loadin>] None None\n",
      "[<operator-3539, add_forward_merge>] None None\n",
      "[<operator-2094, layernorm_backward>] [Tensor(uid=1706,size=28), Tensor(uid=2090,size=28)] [Tensor(uid=2091,size=28)]\n",
      "[<operator-2095, backward_grad_accumulate_input>] [Tensor(uid=2091,size=28), Tensor(uid=2082,size=28)] []\n",
      "[<operator-2096, dropout_backward>] [Tensor(uid=1704,size=28), Tensor(uid=1705,size=14), Tensor(uid=2091,size=28)] [Tensor(uid=2092,size=28)]\n",
      "[<operator-3502, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3503, linear_2_forward_merge>] None None\n",
      "[<operator-2097, linear_2_backward>] [Tensor(uid=1702,size=56), Tensor(uid=2092,size=28)] [Tensor(uid=2093,size=56)]\n",
      "[<operator-3496, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3497, gelu_forward_merge>] None None\n",
      "[<operator-2098, gelu_backward>] [Tensor(uid=1701,size=56), Tensor(uid=2093,size=56)] [Tensor(uid=2094,size=56)]\n",
      "[<operator-3490, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3491, linear_1_forward_merge>] None None\n",
      "[<operator-2099, linear_1_backward>] [Tensor(uid=1700,size=28), Tensor(uid=2094,size=56)] [Tensor(uid=2095,size=28)]\n",
      "[<operator-2100, allreduce_backward>] [Tensor(uid=2095,size=28)] []\n",
      "[<operator-3508, add_forward_branch_loadin>] None None\n",
      "[<operator-3509, add_forward_merge>] None None\n",
      "[<operator-2101, layernorm_backward>] [Tensor(uid=1699,size=28), Tensor(uid=2095,size=28)] [Tensor(uid=2096,size=28)]\n",
      "[<operator-2102, backward_grad_accumulate_res1>] [Tensor(uid=2096,size=28), Tensor(uid=2091,size=28)] []\n",
      "[<operator-2103, output_dropout_backward>] [Tensor(uid=1697,size=28), Tensor(uid=1698,size=14), Tensor(uid=2096,size=28)] [Tensor(uid=2097,size=28)]\n",
      "[<operator-3478, linear_forward_branch_loadin>] None None\n",
      "[<operator-3479, linear_forward_merge>] None None\n",
      "[<operator-2104, linear_backward>] [Tensor(uid=1695,size=14), Tensor(uid=2097,size=28)] [Tensor(uid=2098,size=14)]\n",
      "[<operator-3472, matmul_v_branch_loadin>] None None\n",
      "[<operator-3473, matmul_v_merge>] None None\n",
      "[<operator-2105, matmul_v_backward>] [Tensor(uid=1693,size=128), Tensor(uid=1690,size=42), Tensor(uid=2098,size=14)] [Tensor(uid=2099,size=14), Tensor(uid=2100,size=128)]\n",
      "[<operator-2106, dropout_backward>] [Tensor(uid=1693,size=128), Tensor(uid=1694,size=64), Tensor(uid=2100,size=128)] [Tensor(uid=2101,size=128)]\n",
      "[<operator-3466, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3467, dropout_forward_merge>] None None\n",
      "[<operator-2107, softmax_backward>] [Tensor(uid=1692,size=128), Tensor(uid=2101,size=128)] [Tensor(uid=2102,size=128)]\n",
      "[<operator-2108, matmul_qk_backward>] [Tensor(uid=1690,size=42), Tensor(uid=2102,size=128)] [Tensor(uid=2103,size=28)]\n",
      "[<operator-3460, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3461, linear_qkv_merge>] None None\n",
      "[<operator-2109, linear_qkv_backward>] [Tensor(uid=1689,size=28), Tensor(uid=2099,size=14), Tensor(uid=2103,size=28)] [Tensor(uid=2104,size=28)]\n",
      "[<operator-2110, allreduce_backward>] [Tensor(uid=2104,size=28)] []\n",
      "[<operator-3484, add_forward_branch_loadin>] None None\n",
      "[<operator-3485, add_forward_merge>] None None\n",
      "[<operator-2111, layernorm_backward>] [Tensor(uid=1688,size=28), Tensor(uid=2104,size=28)] [Tensor(uid=2105,size=28)]\n",
      "[<operator-2112, backward_grad_accumulate_input>] [Tensor(uid=2105,size=28), Tensor(uid=2096,size=28)] []\n",
      "[<operator-2113, dropout_backward>] [Tensor(uid=1686,size=28), Tensor(uid=1687,size=14), Tensor(uid=2105,size=28)] [Tensor(uid=2106,size=28)]\n",
      "[<operator-3448, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3449, linear_2_forward_merge>] None None\n",
      "[<operator-2114, linear_2_backward>] [Tensor(uid=1684,size=56), Tensor(uid=2106,size=28)] [Tensor(uid=2107,size=56)]\n",
      "[<operator-3442, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3443, gelu_forward_merge>] None None\n",
      "[<operator-2115, gelu_backward>] [Tensor(uid=1683,size=56), Tensor(uid=2107,size=56)] [Tensor(uid=2108,size=56)]\n",
      "[<operator-3436, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3437, linear_1_forward_merge>] None None\n",
      "[<operator-2116, linear_1_backward>] [Tensor(uid=1682,size=28), Tensor(uid=2108,size=56)] [Tensor(uid=2109,size=28)]\n",
      "[<operator-2117, allreduce_backward>] [Tensor(uid=2109,size=28)] []\n",
      "[<operator-3454, add_forward_branch_loadin>] None None\n",
      "[<operator-3455, add_forward_merge>] None None\n",
      "[<operator-2118, layernorm_backward>] [Tensor(uid=1681,size=28), Tensor(uid=2109,size=28)] [Tensor(uid=2110,size=28)]\n",
      "[<operator-2119, backward_grad_accumulate_res1>] [Tensor(uid=2110,size=28), Tensor(uid=2105,size=28)] []\n",
      "[<operator-2120, output_dropout_backward>] [Tensor(uid=1679,size=28), Tensor(uid=1680,size=14), Tensor(uid=2110,size=28)] [Tensor(uid=2111,size=28)]\n",
      "[<operator-3424, linear_forward_branch_loadin>] None None\n",
      "[<operator-3425, linear_forward_merge>] None None\n",
      "[<operator-2121, linear_backward>] [Tensor(uid=1677,size=14), Tensor(uid=2111,size=28)] [Tensor(uid=2112,size=14)]\n",
      "[<operator-3418, matmul_v_branch_loadin>] None None\n",
      "[<operator-3419, matmul_v_merge>] None None\n",
      "[<operator-2122, matmul_v_backward>] [Tensor(uid=1675,size=128), Tensor(uid=1672,size=42), Tensor(uid=2112,size=14)] [Tensor(uid=2113,size=14), Tensor(uid=2114,size=128)]\n",
      "[<operator-2123, dropout_backward>] [Tensor(uid=1675,size=128), Tensor(uid=1676,size=64), Tensor(uid=2114,size=128)] [Tensor(uid=2115,size=128)]\n",
      "[<operator-3412, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3413, dropout_forward_merge>] None None\n",
      "[<operator-2124, softmax_backward>] [Tensor(uid=1674,size=128), Tensor(uid=2115,size=128)] [Tensor(uid=2116,size=128)]\n",
      "[<operator-2125, matmul_qk_backward>] [Tensor(uid=1672,size=42), Tensor(uid=2116,size=128)] [Tensor(uid=2117,size=28)]\n",
      "[<operator-3406, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3407, linear_qkv_merge>] None None\n",
      "[<operator-2126, linear_qkv_backward>] [Tensor(uid=1671,size=28), Tensor(uid=2113,size=14), Tensor(uid=2117,size=28)] [Tensor(uid=2118,size=28)]\n",
      "[<operator-2127, allreduce_backward>] [Tensor(uid=2118,size=28)] []\n",
      "[<operator-3430, add_forward_branch_loadin>] None None\n",
      "[<operator-3431, add_forward_merge>] None None\n",
      "[<operator-2128, layernorm_backward>] [Tensor(uid=1670,size=28), Tensor(uid=2118,size=28)] [Tensor(uid=2119,size=28)]\n",
      "[<operator-2129, backward_grad_accumulate_input>] [Tensor(uid=2119,size=28), Tensor(uid=2110,size=28)] []\n",
      "[<operator-2130, dropout_backward>] [Tensor(uid=1668,size=28), Tensor(uid=1669,size=14), Tensor(uid=2119,size=28)] [Tensor(uid=2120,size=28)]\n",
      "[<operator-3394, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3395, linear_2_forward_merge>] None None\n",
      "[<operator-2131, linear_2_backward>] [Tensor(uid=1666,size=56), Tensor(uid=2120,size=28)] [Tensor(uid=2121,size=56)]\n",
      "[<operator-3388, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3389, gelu_forward_merge>] None None\n",
      "[<operator-2132, gelu_backward>] [Tensor(uid=1665,size=56), Tensor(uid=2121,size=56)] [Tensor(uid=2122,size=56)]\n",
      "[<operator-3382, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3383, linear_1_forward_merge>] None None\n",
      "[<operator-2133, linear_1_backward>] [Tensor(uid=1664,size=28), Tensor(uid=2122,size=56)] [Tensor(uid=2123,size=28)]\n",
      "[<operator-2134, allreduce_backward>] [Tensor(uid=2123,size=28)] []\n",
      "[<operator-3400, add_forward_branch_loadin>] None None\n",
      "[<operator-3401, add_forward_merge>] None None\n",
      "[<operator-2135, layernorm_backward>] [Tensor(uid=1663,size=28), Tensor(uid=2123,size=28)] [Tensor(uid=2124,size=28)]\n",
      "[<operator-2136, backward_grad_accumulate_res1>] [Tensor(uid=2124,size=28), Tensor(uid=2119,size=28)] []\n",
      "[<operator-2137, output_dropout_backward>] [Tensor(uid=1661,size=28), Tensor(uid=1662,size=14), Tensor(uid=2124,size=28)] [Tensor(uid=2125,size=28)]\n",
      "[<operator-3370, linear_forward_branch_loadin>] None None\n",
      "[<operator-3371, linear_forward_merge>] None None\n",
      "[<operator-2138, linear_backward>] [Tensor(uid=1659,size=14), Tensor(uid=2125,size=28)] [Tensor(uid=2126,size=14)]\n",
      "[<operator-3364, matmul_v_branch_loadin>] None None\n",
      "[<operator-3365, matmul_v_merge>] None None\n",
      "[<operator-2139, matmul_v_backward>] [Tensor(uid=1657,size=128), Tensor(uid=1654,size=42), Tensor(uid=2126,size=14)] [Tensor(uid=2127,size=14), Tensor(uid=2128,size=128)]\n",
      "[<operator-2140, dropout_backward>] [Tensor(uid=1657,size=128), Tensor(uid=1658,size=64), Tensor(uid=2128,size=128)] [Tensor(uid=2129,size=128)]\n",
      "[<operator-3358, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3359, dropout_forward_merge>] None None\n",
      "[<operator-2141, softmax_backward>] [Tensor(uid=1656,size=128), Tensor(uid=2129,size=128)] [Tensor(uid=2130,size=128)]\n",
      "[<operator-2142, matmul_qk_backward>] [Tensor(uid=1654,size=42), Tensor(uid=2130,size=128)] [Tensor(uid=2131,size=28)]\n",
      "[<operator-3352, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3353, linear_qkv_merge>] None None\n",
      "[<operator-2143, linear_qkv_backward>] [Tensor(uid=1653,size=28), Tensor(uid=2127,size=14), Tensor(uid=2131,size=28)] [Tensor(uid=2132,size=28)]\n",
      "[<operator-2144, allreduce_backward>] [Tensor(uid=2132,size=28)] []\n",
      "[<operator-3376, add_forward_branch_loadin>] None None\n",
      "[<operator-3377, add_forward_merge>] None None\n",
      "[<operator-2145, layernorm_backward>] [Tensor(uid=1652,size=28), Tensor(uid=2132,size=28)] [Tensor(uid=2133,size=28)]\n",
      "[<operator-2146, backward_grad_accumulate_input>] [Tensor(uid=2133,size=28), Tensor(uid=2124,size=28)] []\n",
      "[<operator-2147, dropout_backward>] [Tensor(uid=1650,size=28), Tensor(uid=1651,size=14), Tensor(uid=2133,size=28)] [Tensor(uid=2134,size=28)]\n",
      "[<operator-3340, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3341, linear_2_forward_merge>] None None\n",
      "[<operator-2148, linear_2_backward>] [Tensor(uid=1648,size=56), Tensor(uid=2134,size=28)] [Tensor(uid=2135,size=56)]\n",
      "[<operator-3334, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3335, gelu_forward_merge>] None None\n",
      "[<operator-2149, gelu_backward>] [Tensor(uid=1647,size=56), Tensor(uid=2135,size=56)] [Tensor(uid=2136,size=56)]\n",
      "[<operator-3328, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3329, linear_1_forward_merge>] None None\n",
      "[<operator-2150, linear_1_backward>] [Tensor(uid=1646,size=28), Tensor(uid=2136,size=56)] [Tensor(uid=2137,size=28)]\n",
      "[<operator-2151, allreduce_backward>] [Tensor(uid=2137,size=28)] []\n",
      "[<operator-3346, add_forward_branch_loadin>] None None\n",
      "[<operator-3347, add_forward_merge>] None None\n",
      "[<operator-2152, layernorm_backward>] [Tensor(uid=1645,size=28), Tensor(uid=2137,size=28)] [Tensor(uid=2138,size=28)]\n",
      "[<operator-2153, backward_grad_accumulate_res1>] [Tensor(uid=2138,size=28), Tensor(uid=2133,size=28)] []\n",
      "[<operator-2154, output_dropout_backward>] [Tensor(uid=1643,size=28), Tensor(uid=1644,size=14), Tensor(uid=2138,size=28)] [Tensor(uid=2139,size=28)]\n",
      "[<operator-3316, linear_forward_branch_loadin>] None None\n",
      "[<operator-3317, linear_forward_merge>] None None\n",
      "[<operator-2155, linear_backward>] [Tensor(uid=1641,size=14), Tensor(uid=2139,size=28)] [Tensor(uid=2140,size=14)]\n",
      "[<operator-3310, matmul_v_branch_loadin>] None None\n",
      "[<operator-3311, matmul_v_merge>] None None\n",
      "[<operator-2156, matmul_v_backward>] [Tensor(uid=1639,size=128), Tensor(uid=1636,size=42), Tensor(uid=2140,size=14)] [Tensor(uid=2141,size=14), Tensor(uid=2142,size=128)]\n",
      "[<operator-2157, dropout_backward>] [Tensor(uid=1639,size=128), Tensor(uid=1640,size=64), Tensor(uid=2142,size=128)] [Tensor(uid=2143,size=128)]\n",
      "[<operator-3304, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3305, dropout_forward_merge>] None None\n",
      "[<operator-2158, softmax_backward>] [Tensor(uid=1638,size=128), Tensor(uid=2143,size=128)] [Tensor(uid=2144,size=128)]\n",
      "[<operator-2159, matmul_qk_backward>] [Tensor(uid=1636,size=42), Tensor(uid=2144,size=128)] [Tensor(uid=2145,size=28)]\n",
      "[<operator-3298, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3299, linear_qkv_merge>] None None\n",
      "[<operator-2160, linear_qkv_backward>] [Tensor(uid=1635,size=28), Tensor(uid=2141,size=14), Tensor(uid=2145,size=28)] [Tensor(uid=2146,size=28)]\n",
      "[<operator-2161, allreduce_backward>] [Tensor(uid=2146,size=28)] []\n",
      "[<operator-3322, add_forward_branch_loadin>] None None\n",
      "[<operator-3323, add_forward_merge>] None None\n",
      "[<operator-2162, layernorm_backward>] [Tensor(uid=1634,size=28), Tensor(uid=2146,size=28)] [Tensor(uid=2147,size=28)]\n",
      "[<operator-2163, backward_grad_accumulate_input>] [Tensor(uid=2147,size=28), Tensor(uid=2138,size=28)] []\n",
      "[<operator-2164, dropout_backward>] [Tensor(uid=1632,size=28), Tensor(uid=1633,size=14), Tensor(uid=2147,size=28)] [Tensor(uid=2148,size=28)]\n",
      "[<operator-3286, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3287, linear_2_forward_merge>] None None\n",
      "[<operator-2165, linear_2_backward>] [Tensor(uid=1630,size=56), Tensor(uid=2148,size=28)] [Tensor(uid=2149,size=56)]\n",
      "[<operator-3280, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3281, gelu_forward_merge>] None None\n",
      "[<operator-2166, gelu_backward>] [Tensor(uid=1629,size=56), Tensor(uid=2149,size=56)] [Tensor(uid=2150,size=56)]\n",
      "[<operator-3274, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3275, linear_1_forward_merge>] None None\n",
      "[<operator-2167, linear_1_backward>] [Tensor(uid=1628,size=28), Tensor(uid=2150,size=56)] [Tensor(uid=2151,size=28)]\n",
      "[<operator-2168, allreduce_backward>] [Tensor(uid=2151,size=28)] []\n",
      "[<operator-3292, add_forward_branch_loadin>] None None\n",
      "[<operator-3293, add_forward_merge>] None None\n",
      "[<operator-2169, layernorm_backward>] [Tensor(uid=1627,size=28), Tensor(uid=2151,size=28)] [Tensor(uid=2152,size=28)]\n",
      "[<operator-2170, backward_grad_accumulate_res1>] [Tensor(uid=2152,size=28), Tensor(uid=2147,size=28)] []\n",
      "[<operator-2171, output_dropout_backward>] [Tensor(uid=1625,size=28), Tensor(uid=1626,size=14), Tensor(uid=2152,size=28)] [Tensor(uid=2153,size=28)]\n",
      "[<operator-3262, linear_forward_branch_loadin>] None None\n",
      "[<operator-3263, linear_forward_merge>] None None\n",
      "[<operator-2172, linear_backward>] [Tensor(uid=1623,size=14), Tensor(uid=2153,size=28)] [Tensor(uid=2154,size=14)]\n",
      "[<operator-3256, matmul_v_branch_loadin>] None None\n",
      "[<operator-3257, matmul_v_merge>] None None\n",
      "[<operator-2173, matmul_v_backward>] [Tensor(uid=1621,size=128), Tensor(uid=1618,size=42), Tensor(uid=2154,size=14)] [Tensor(uid=2155,size=14), Tensor(uid=2156,size=128)]\n",
      "[<operator-2174, dropout_backward>] [Tensor(uid=1621,size=128), Tensor(uid=1622,size=64), Tensor(uid=2156,size=128)] [Tensor(uid=2157,size=128)]\n",
      "[<operator-3250, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3251, dropout_forward_merge>] None None\n",
      "[<operator-2175, softmax_backward>] [Tensor(uid=1620,size=128), Tensor(uid=2157,size=128)] [Tensor(uid=2158,size=128)]\n",
      "[<operator-2176, matmul_qk_backward>] [Tensor(uid=1618,size=42), Tensor(uid=2158,size=128)] [Tensor(uid=2159,size=28)]\n",
      "[<operator-3244, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3245, linear_qkv_merge>] None None\n",
      "[<operator-2177, linear_qkv_backward>] [Tensor(uid=1617,size=28), Tensor(uid=2155,size=14), Tensor(uid=2159,size=28)] [Tensor(uid=2160,size=28)]\n",
      "[<operator-2178, allreduce_backward>] [Tensor(uid=2160,size=28)] []\n",
      "[<operator-3268, add_forward_branch_loadin>] None None\n",
      "[<operator-3269, add_forward_merge>] None None\n",
      "[<operator-2179, layernorm_backward>] [Tensor(uid=1616,size=28), Tensor(uid=2160,size=28)] [Tensor(uid=2161,size=28)]\n",
      "[<operator-2180, backward_grad_accumulate_input>] [Tensor(uid=2161,size=28), Tensor(uid=2152,size=28)] []\n",
      "[<operator-2181, dropout_backward>] [Tensor(uid=1614,size=28), Tensor(uid=1615,size=14), Tensor(uid=2161,size=28)] [Tensor(uid=2162,size=28)]\n",
      "[<operator-3232, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3233, linear_2_forward_merge>] None None\n",
      "[<operator-2182, linear_2_backward>] [Tensor(uid=1612,size=56), Tensor(uid=2162,size=28)] [Tensor(uid=2163,size=56)]\n",
      "[<operator-3226, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3227, gelu_forward_merge>] None None\n",
      "[<operator-2183, gelu_backward>] [Tensor(uid=1611,size=56), Tensor(uid=2163,size=56)] [Tensor(uid=2164,size=56)]\n",
      "[<operator-3220, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3221, linear_1_forward_merge>] None None\n",
      "[<operator-2184, linear_1_backward>] [Tensor(uid=1610,size=28), Tensor(uid=2164,size=56)] [Tensor(uid=2165,size=28)]\n",
      "[<operator-2185, allreduce_backward>] [Tensor(uid=2165,size=28)] []\n",
      "[<operator-3238, add_forward_branch_loadin>] None None\n",
      "[<operator-3239, add_forward_merge>] None None\n",
      "[<operator-2186, layernorm_backward>] [Tensor(uid=1609,size=28), Tensor(uid=2165,size=28)] [Tensor(uid=2166,size=28)]\n",
      "[<operator-2187, backward_grad_accumulate_res1>] [Tensor(uid=2166,size=28), Tensor(uid=2161,size=28)] []\n",
      "[<operator-2188, output_dropout_backward>] [Tensor(uid=1607,size=28), Tensor(uid=1608,size=14), Tensor(uid=2166,size=28)] [Tensor(uid=2167,size=28)]\n",
      "[<operator-3208, linear_forward_branch_loadin>] None None\n",
      "[<operator-3209, linear_forward_merge>] None None\n",
      "[<operator-2189, linear_backward>] [Tensor(uid=1605,size=14), Tensor(uid=2167,size=28)] [Tensor(uid=2168,size=14)]\n",
      "[<operator-3202, matmul_v_branch_loadin>] None None\n",
      "[<operator-3203, matmul_v_merge>] None None\n",
      "[<operator-2190, matmul_v_backward>] [Tensor(uid=1603,size=128), Tensor(uid=1600,size=42), Tensor(uid=2168,size=14)] [Tensor(uid=2169,size=14), Tensor(uid=2170,size=128)]\n",
      "[<operator-2191, dropout_backward>] [Tensor(uid=1603,size=128), Tensor(uid=1604,size=64), Tensor(uid=2170,size=128)] [Tensor(uid=2171,size=128)]\n",
      "[<operator-3196, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3197, dropout_forward_merge>] None None\n",
      "[<operator-2192, softmax_backward>] [Tensor(uid=1602,size=128), Tensor(uid=2171,size=128)] [Tensor(uid=2172,size=128)]\n",
      "[<operator-2193, matmul_qk_backward>] [Tensor(uid=1600,size=42), Tensor(uid=2172,size=128)] [Tensor(uid=2173,size=28)]\n",
      "[<operator-3190, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3191, linear_qkv_merge>] None None\n",
      "[<operator-2194, linear_qkv_backward>] [Tensor(uid=1599,size=28), Tensor(uid=2169,size=14), Tensor(uid=2173,size=28)] [Tensor(uid=2174,size=28)]\n",
      "[<operator-2195, allreduce_backward>] [Tensor(uid=2174,size=28)] []\n",
      "[<operator-3214, add_forward_branch_loadin>] None None\n",
      "[<operator-3215, add_forward_merge>] None None\n",
      "[<operator-2196, layernorm_backward>] [Tensor(uid=1598,size=28), Tensor(uid=2174,size=28)] [Tensor(uid=2175,size=28)]\n",
      "[<operator-2197, backward_grad_accumulate_input>] [Tensor(uid=2175,size=28), Tensor(uid=2166,size=28)] []\n",
      "[<operator-2198, dropout_backward>] [Tensor(uid=1596,size=28), Tensor(uid=1597,size=14), Tensor(uid=2175,size=28)] [Tensor(uid=2176,size=28)]\n",
      "[<operator-3178, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3179, linear_2_forward_merge>] None None\n",
      "[<operator-2199, linear_2_backward>] [Tensor(uid=1594,size=56), Tensor(uid=2176,size=28)] [Tensor(uid=2177,size=56)]\n",
      "[<operator-3172, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3173, gelu_forward_merge>] None None\n",
      "[<operator-2200, gelu_backward>] [Tensor(uid=1593,size=56), Tensor(uid=2177,size=56)] [Tensor(uid=2178,size=56)]\n",
      "[<operator-3166, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3167, linear_1_forward_merge>] None None\n",
      "[<operator-2201, linear_1_backward>] [Tensor(uid=1592,size=28), Tensor(uid=2178,size=56)] [Tensor(uid=2179,size=28)]\n",
      "[<operator-2202, allreduce_backward>] [Tensor(uid=2179,size=28)] []\n",
      "[<operator-3184, add_forward_branch_loadin>] None None\n",
      "[<operator-3185, add_forward_merge>] None None\n",
      "[<operator-2203, layernorm_backward>] [Tensor(uid=1591,size=28), Tensor(uid=2179,size=28)] [Tensor(uid=2180,size=28)]\n",
      "[<operator-2204, backward_grad_accumulate_res1>] [Tensor(uid=2180,size=28), Tensor(uid=2175,size=28)] []\n",
      "[<operator-2205, output_dropout_backward>] [Tensor(uid=1589,size=28), Tensor(uid=1590,size=14), Tensor(uid=2180,size=28)] [Tensor(uid=2181,size=28)]\n",
      "[<operator-3154, linear_forward_branch_loadin>] None None\n",
      "[<operator-3155, linear_forward_merge>] None None\n",
      "[<operator-2206, linear_backward>] [Tensor(uid=1587,size=14), Tensor(uid=2181,size=28)] [Tensor(uid=2182,size=14)]\n",
      "[<operator-3148, matmul_v_branch_loadin>] None None\n",
      "[<operator-3149, matmul_v_merge>] None None\n",
      "[<operator-2207, matmul_v_backward>] [Tensor(uid=1585,size=128), Tensor(uid=1582,size=42), Tensor(uid=2182,size=14)] [Tensor(uid=2183,size=14), Tensor(uid=2184,size=128)]\n",
      "[<operator-2208, dropout_backward>] [Tensor(uid=1585,size=128), Tensor(uid=1586,size=64), Tensor(uid=2184,size=128)] [Tensor(uid=2185,size=128)]\n",
      "[<operator-3142, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3143, dropout_forward_merge>] None None\n",
      "[<operator-2209, softmax_backward>] [Tensor(uid=1584,size=128), Tensor(uid=2185,size=128)] [Tensor(uid=2186,size=128)]\n",
      "[<operator-2210, matmul_qk_backward>] [Tensor(uid=1582,size=42), Tensor(uid=2186,size=128)] [Tensor(uid=2187,size=28)]\n",
      "[<operator-3136, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3137, linear_qkv_merge>] None None\n",
      "[<operator-2211, linear_qkv_backward>] [Tensor(uid=1581,size=28), Tensor(uid=2183,size=14), Tensor(uid=2187,size=28)] [Tensor(uid=2188,size=28)]\n",
      "[<operator-2212, allreduce_backward>] [Tensor(uid=2188,size=28)] []\n",
      "[<operator-3160, add_forward_branch_loadin>] None None\n",
      "[<operator-3161, add_forward_merge>] None None\n",
      "[<operator-2213, layernorm_backward>] [Tensor(uid=1580,size=28), Tensor(uid=2188,size=28)] [Tensor(uid=2189,size=28)]\n",
      "[<operator-2214, backward_grad_accumulate_input>] [Tensor(uid=2189,size=28), Tensor(uid=2180,size=28)] []\n",
      "[<operator-2215, dropout_backward>] [Tensor(uid=1578,size=28), Tensor(uid=1579,size=14), Tensor(uid=2189,size=28)] [Tensor(uid=2190,size=28)]\n",
      "[<operator-3124, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3125, linear_2_forward_merge>] None None\n",
      "[<operator-2216, linear_2_backward>] [Tensor(uid=1576,size=56), Tensor(uid=2190,size=28)] [Tensor(uid=2191,size=56)]\n",
      "[<operator-3118, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3119, gelu_forward_merge>] None None\n",
      "[<operator-2217, gelu_backward>] [Tensor(uid=1575,size=56), Tensor(uid=2191,size=56)] [Tensor(uid=2192,size=56)]\n",
      "[<operator-3112, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3113, linear_1_forward_merge>] None None\n",
      "[<operator-2218, linear_1_backward>] [Tensor(uid=1574,size=28), Tensor(uid=2192,size=56)] [Tensor(uid=2193,size=28)]\n",
      "[<operator-2219, allreduce_backward>] [Tensor(uid=2193,size=28)] []\n",
      "[<operator-3130, add_forward_branch_loadin>] None None\n",
      "[<operator-3131, add_forward_merge>] None None\n",
      "[<operator-2220, layernorm_backward>] [Tensor(uid=1573,size=28), Tensor(uid=2193,size=28)] [Tensor(uid=2194,size=28)]\n",
      "[<operator-2221, backward_grad_accumulate_res1>] [Tensor(uid=2194,size=28), Tensor(uid=2189,size=28)] []\n",
      "[<operator-2222, output_dropout_backward>] [Tensor(uid=1571,size=28), Tensor(uid=1572,size=14), Tensor(uid=2194,size=28)] [Tensor(uid=2195,size=28)]\n",
      "[<operator-3100, linear_forward_branch_loadin>] None None\n",
      "[<operator-3101, linear_forward_merge>] None None\n",
      "[<operator-2223, linear_backward>] [Tensor(uid=1569,size=14), Tensor(uid=2195,size=28)] [Tensor(uid=2196,size=14)]\n",
      "[<operator-3094, matmul_v_branch_loadin>] None None\n",
      "[<operator-3095, matmul_v_merge>] None None\n",
      "[<operator-2224, matmul_v_backward>] [Tensor(uid=1567,size=128), Tensor(uid=1564,size=42), Tensor(uid=2196,size=14)] [Tensor(uid=2197,size=14), Tensor(uid=2198,size=128)]\n",
      "[<operator-2225, dropout_backward>] [Tensor(uid=1567,size=128), Tensor(uid=1568,size=64), Tensor(uid=2198,size=128)] [Tensor(uid=2199,size=128)]\n",
      "[<operator-3088, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3089, dropout_forward_merge>] None None\n",
      "[<operator-2226, softmax_backward>] [Tensor(uid=1566,size=128), Tensor(uid=2199,size=128)] [Tensor(uid=2200,size=128)]\n",
      "[<operator-2227, matmul_qk_backward>] [Tensor(uid=1564,size=42), Tensor(uid=2200,size=128)] [Tensor(uid=2201,size=28)]\n",
      "[<operator-3082, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3083, linear_qkv_merge>] None None\n",
      "[<operator-2228, linear_qkv_backward>] [Tensor(uid=1563,size=28), Tensor(uid=2197,size=14), Tensor(uid=2201,size=28)] [Tensor(uid=2202,size=28)]\n",
      "[<operator-2229, allreduce_backward>] [Tensor(uid=2202,size=28)] []\n",
      "[<operator-3106, add_forward_branch_loadin>] None None\n",
      "[<operator-3107, add_forward_merge>] None None\n",
      "[<operator-2230, layernorm_backward>] [Tensor(uid=1562,size=28), Tensor(uid=2202,size=28)] [Tensor(uid=2203,size=28)]\n",
      "[<operator-2231, backward_grad_accumulate_input>] [Tensor(uid=2203,size=28), Tensor(uid=2194,size=28)] []\n",
      "[<operator-2232, dropout_backward>] [Tensor(uid=1560,size=28), Tensor(uid=1561,size=14), Tensor(uid=2203,size=28)] [Tensor(uid=2204,size=28)]\n",
      "[<operator-3070, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3071, linear_2_forward_merge>] None None\n",
      "[<operator-2233, linear_2_backward>] [Tensor(uid=1558,size=56), Tensor(uid=2204,size=28)] [Tensor(uid=2205,size=56)]\n",
      "[<operator-3064, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3065, gelu_forward_merge>] None None\n",
      "[<operator-2234, gelu_backward>] [Tensor(uid=1557,size=56), Tensor(uid=2205,size=56)] [Tensor(uid=2206,size=56)]\n",
      "[<operator-3058, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3059, linear_1_forward_merge>] None None\n",
      "[<operator-2235, linear_1_backward>] [Tensor(uid=1556,size=28), Tensor(uid=2206,size=56)] [Tensor(uid=2207,size=28)]\n",
      "[<operator-2236, allreduce_backward>] [Tensor(uid=2207,size=28)] []\n",
      "[<operator-3076, add_forward_branch_loadin>] None None\n",
      "[<operator-3077, add_forward_merge>] None None\n",
      "[<operator-2237, layernorm_backward>] [Tensor(uid=1555,size=28), Tensor(uid=2207,size=28)] [Tensor(uid=2208,size=28)]\n",
      "[<operator-2238, backward_grad_accumulate_res1>] [Tensor(uid=2208,size=28), Tensor(uid=2203,size=28)] []\n",
      "[<operator-2239, output_dropout_backward>] [Tensor(uid=1553,size=28), Tensor(uid=1554,size=14), Tensor(uid=2208,size=28)] [Tensor(uid=2209,size=28)]\n",
      "[<operator-3046, linear_forward_branch_loadin>] None None\n",
      "[<operator-3047, linear_forward_merge>] None None\n",
      "[<operator-2240, linear_backward>] [Tensor(uid=1551,size=14), Tensor(uid=2209,size=28)] [Tensor(uid=2210,size=14)]\n",
      "[<operator-3040, matmul_v_branch_loadin>] None None\n",
      "[<operator-3041, matmul_v_merge>] None None\n",
      "[<operator-2241, matmul_v_backward>] [Tensor(uid=1549,size=128), Tensor(uid=1546,size=42), Tensor(uid=2210,size=14)] [Tensor(uid=2211,size=14), Tensor(uid=2212,size=128)]\n",
      "[<operator-2242, dropout_backward>] [Tensor(uid=1549,size=128), Tensor(uid=1550,size=64), Tensor(uid=2212,size=128)] [Tensor(uid=2213,size=128)]\n",
      "[<operator-3034, dropout_forward_branch_loadin>] None None\n",
      "[<operator-3035, dropout_forward_merge>] None None\n",
      "[<operator-2243, softmax_backward>] [Tensor(uid=1548,size=128), Tensor(uid=2213,size=128)] [Tensor(uid=2214,size=128)]\n",
      "[<operator-2244, matmul_qk_backward>] [Tensor(uid=1546,size=42), Tensor(uid=2214,size=128)] [Tensor(uid=2215,size=28)]\n",
      "[<operator-3028, linear_qkv_branch_loadin>] None None\n",
      "[<operator-3029, linear_qkv_merge>] None None\n",
      "[<operator-2245, linear_qkv_backward>] [Tensor(uid=1545,size=28), Tensor(uid=2211,size=14), Tensor(uid=2215,size=28)] [Tensor(uid=2216,size=28)]\n",
      "[<operator-2246, allreduce_backward>] [Tensor(uid=2216,size=28)] []\n",
      "[<operator-3052, add_forward_branch_loadin>] None None\n",
      "[<operator-3053, add_forward_merge>] None None\n",
      "[<operator-2247, layernorm_backward>] [Tensor(uid=1544,size=28), Tensor(uid=2216,size=28)] [Tensor(uid=2217,size=28)]\n",
      "[<operator-2248, backward_grad_accumulate_input>] [Tensor(uid=2217,size=28), Tensor(uid=2208,size=28)] []\n",
      "[<operator-2249, dropout_backward>] [Tensor(uid=1542,size=28), Tensor(uid=1543,size=14), Tensor(uid=2217,size=28)] [Tensor(uid=2218,size=28)]\n",
      "[<operator-3016, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-3017, linear_2_forward_merge>] None None\n",
      "[<operator-2250, linear_2_backward>] [Tensor(uid=1540,size=56), Tensor(uid=2218,size=28)] [Tensor(uid=2219,size=56)]\n",
      "[<operator-3010, gelu_forward_branch_loadin>] None None\n",
      "[<operator-3011, gelu_forward_merge>] None None\n",
      "[<operator-2251, gelu_backward>] [Tensor(uid=1539,size=56), Tensor(uid=2219,size=56)] [Tensor(uid=2220,size=56)]\n",
      "[<operator-3004, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-3005, linear_1_forward_merge>] None None\n",
      "[<operator-2252, linear_1_backward>] [Tensor(uid=1538,size=28), Tensor(uid=2220,size=56)] [Tensor(uid=2221,size=28)]\n",
      "[<operator-2253, allreduce_backward>] [Tensor(uid=2221,size=28)] []\n",
      "[<operator-3022, add_forward_branch_loadin>] None None\n",
      "[<operator-3023, add_forward_merge>] None None\n",
      "[<operator-2254, layernorm_backward>] [Tensor(uid=1537,size=28), Tensor(uid=2221,size=28)] [Tensor(uid=2222,size=28)]\n",
      "[<operator-2255, backward_grad_accumulate_res1>] [Tensor(uid=2222,size=28), Tensor(uid=2217,size=28)] []\n",
      "[<operator-2256, output_dropout_backward>] [Tensor(uid=1535,size=28), Tensor(uid=1536,size=14), Tensor(uid=2222,size=28)] [Tensor(uid=2223,size=28)]\n",
      "[<operator-2992, linear_forward_branch_loadin>] None None\n",
      "[<operator-2993, linear_forward_merge>] None None\n",
      "[<operator-2257, linear_backward>] [Tensor(uid=1533,size=14), Tensor(uid=2223,size=28)] [Tensor(uid=2224,size=14)]\n",
      "[<operator-2986, matmul_v_branch_loadin>] None None\n",
      "[<operator-2987, matmul_v_merge>] None None\n",
      "[<operator-2258, matmul_v_backward>] [Tensor(uid=1531,size=128), Tensor(uid=1528,size=42), Tensor(uid=2224,size=14)] [Tensor(uid=2225,size=14), Tensor(uid=2226,size=128)]\n",
      "[<operator-2259, dropout_backward>] [Tensor(uid=1531,size=128), Tensor(uid=1532,size=64), Tensor(uid=2226,size=128)] [Tensor(uid=2227,size=128)]\n",
      "[<operator-2980, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2981, dropout_forward_merge>] None None\n",
      "[<operator-2260, softmax_backward>] [Tensor(uid=1530,size=128), Tensor(uid=2227,size=128)] [Tensor(uid=2228,size=128)]\n",
      "[<operator-2261, matmul_qk_backward>] [Tensor(uid=1528,size=42), Tensor(uid=2228,size=128)] [Tensor(uid=2229,size=28)]\n",
      "[<operator-2974, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2975, linear_qkv_merge>] None None\n",
      "[<operator-2262, linear_qkv_backward>] [Tensor(uid=1527,size=28), Tensor(uid=2225,size=14), Tensor(uid=2229,size=28)] [Tensor(uid=2230,size=28)]\n",
      "[<operator-2263, allreduce_backward>] [Tensor(uid=2230,size=28)] []\n",
      "[<operator-2998, add_forward_branch_loadin>] None None\n",
      "[<operator-2999, add_forward_merge>] None None\n",
      "[<operator-2264, layernorm_backward>] [Tensor(uid=1526,size=28), Tensor(uid=2230,size=28)] [Tensor(uid=2231,size=28)]\n",
      "[<operator-2265, backward_grad_accumulate_input>] [Tensor(uid=2231,size=28), Tensor(uid=2222,size=28)] []\n",
      "[<operator-2266, dropout_backward>] [Tensor(uid=1524,size=28), Tensor(uid=1525,size=14), Tensor(uid=2231,size=28)] [Tensor(uid=2232,size=28)]\n",
      "[<operator-2962, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2963, linear_2_forward_merge>] None None\n",
      "[<operator-2267, linear_2_backward>] [Tensor(uid=1522,size=56), Tensor(uid=2232,size=28)] [Tensor(uid=2233,size=56)]\n",
      "[<operator-2956, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2957, gelu_forward_merge>] None None\n",
      "[<operator-2268, gelu_backward>] [Tensor(uid=1521,size=56), Tensor(uid=2233,size=56)] [Tensor(uid=2234,size=56)]\n",
      "[<operator-2950, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2951, linear_1_forward_merge>] None None\n",
      "[<operator-2269, linear_1_backward>] [Tensor(uid=1520,size=28), Tensor(uid=2234,size=56)] [Tensor(uid=2235,size=28)]\n",
      "[<operator-2270, allreduce_backward>] [Tensor(uid=2235,size=28)] []\n",
      "[<operator-2968, add_forward_branch_loadin>] None None\n",
      "[<operator-2969, add_forward_merge>] None None\n",
      "[<operator-2271, layernorm_backward>] [Tensor(uid=1519,size=28), Tensor(uid=2235,size=28)] [Tensor(uid=2236,size=28)]\n",
      "[<operator-2272, backward_grad_accumulate_res1>] [Tensor(uid=2236,size=28), Tensor(uid=2231,size=28)] []\n",
      "[<operator-2273, output_dropout_backward>] [Tensor(uid=1517,size=28), Tensor(uid=1518,size=14), Tensor(uid=2236,size=28)] [Tensor(uid=2237,size=28)]\n",
      "[<operator-2938, linear_forward_branch_loadin>] None None\n",
      "[<operator-2939, linear_forward_merge>] None None\n",
      "[<operator-2274, linear_backward>] [Tensor(uid=1515,size=14), Tensor(uid=2237,size=28)] [Tensor(uid=2238,size=14)]\n",
      "[<operator-2932, matmul_v_branch_loadin>] None None\n",
      "[<operator-2933, matmul_v_merge>] None None\n",
      "[<operator-2275, matmul_v_backward>] [Tensor(uid=1513,size=128), Tensor(uid=1510,size=42), Tensor(uid=2238,size=14)] [Tensor(uid=2239,size=14), Tensor(uid=2240,size=128)]\n",
      "[<operator-2276, dropout_backward>] [Tensor(uid=1513,size=128), Tensor(uid=1514,size=64), Tensor(uid=2240,size=128)] [Tensor(uid=2241,size=128)]\n",
      "[<operator-2926, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2927, dropout_forward_merge>] None None\n",
      "[<operator-2277, softmax_backward>] [Tensor(uid=1512,size=128), Tensor(uid=2241,size=128)] [Tensor(uid=2242,size=128)]\n",
      "[<operator-2278, matmul_qk_backward>] [Tensor(uid=1510,size=42), Tensor(uid=2242,size=128)] [Tensor(uid=2243,size=28)]\n",
      "[<operator-2920, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2921, linear_qkv_merge>] None None\n",
      "[<operator-2279, linear_qkv_backward>] [Tensor(uid=1509,size=28), Tensor(uid=2239,size=14), Tensor(uid=2243,size=28)] [Tensor(uid=2244,size=28)]\n",
      "[<operator-2280, allreduce_backward>] [Tensor(uid=2244,size=28)] []\n",
      "[<operator-2944, add_forward_branch_loadin>] None None\n",
      "[<operator-2945, add_forward_merge>] None None\n",
      "[<operator-2281, layernorm_backward>] [Tensor(uid=1508,size=28), Tensor(uid=2244,size=28)] [Tensor(uid=2245,size=28)]\n",
      "[<operator-2282, backward_grad_accumulate_input>] [Tensor(uid=2245,size=28), Tensor(uid=2236,size=28)] []\n",
      "[<operator-2283, dropout_backward>] [Tensor(uid=1506,size=28), Tensor(uid=1507,size=14), Tensor(uid=2245,size=28)] [Tensor(uid=2246,size=28)]\n",
      "[<operator-2908, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2909, linear_2_forward_merge>] None None\n",
      "[<operator-2284, linear_2_backward>] [Tensor(uid=1504,size=56), Tensor(uid=2246,size=28)] [Tensor(uid=2247,size=56)]\n",
      "[<operator-2902, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2903, gelu_forward_merge>] None None\n",
      "[<operator-2285, gelu_backward>] [Tensor(uid=1503,size=56), Tensor(uid=2247,size=56)] [Tensor(uid=2248,size=56)]\n",
      "[<operator-2896, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2897, linear_1_forward_merge>] None None\n",
      "[<operator-2286, linear_1_backward>] [Tensor(uid=1502,size=28), Tensor(uid=2248,size=56)] [Tensor(uid=2249,size=28)]\n",
      "[<operator-2287, allreduce_backward>] [Tensor(uid=2249,size=28)] []\n",
      "[<operator-2914, add_forward_branch_loadin>] None None\n",
      "[<operator-2915, add_forward_merge>] None None\n",
      "[<operator-2288, layernorm_backward>] [Tensor(uid=1501,size=28), Tensor(uid=2249,size=28)] [Tensor(uid=2250,size=28)]\n",
      "[<operator-2289, backward_grad_accumulate_res1>] [Tensor(uid=2250,size=28), Tensor(uid=2245,size=28)] []\n",
      "[<operator-2290, output_dropout_backward>] [Tensor(uid=1499,size=28), Tensor(uid=1500,size=14), Tensor(uid=2250,size=28)] [Tensor(uid=2251,size=28)]\n",
      "[<operator-2884, linear_forward_branch_loadin>] None None\n",
      "[<operator-2885, linear_forward_merge>] None None\n",
      "[<operator-2291, linear_backward>] [Tensor(uid=1497,size=14), Tensor(uid=2251,size=28)] [Tensor(uid=2252,size=14)]\n",
      "[<operator-2878, matmul_v_branch_loadin>] None None\n",
      "[<operator-2879, matmul_v_merge>] None None\n",
      "[<operator-2292, matmul_v_backward>] [Tensor(uid=1495,size=128), Tensor(uid=1492,size=42), Tensor(uid=2252,size=14)] [Tensor(uid=2253,size=14), Tensor(uid=2254,size=128)]\n",
      "[<operator-2293, dropout_backward>] [Tensor(uid=1495,size=128), Tensor(uid=1496,size=64), Tensor(uid=2254,size=128)] [Tensor(uid=2255,size=128)]\n",
      "[<operator-2872, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2873, dropout_forward_merge>] None None\n",
      "[<operator-2294, softmax_backward>] [Tensor(uid=1494,size=128), Tensor(uid=2255,size=128)] [Tensor(uid=2256,size=128)]\n",
      "[<operator-2295, matmul_qk_backward>] [Tensor(uid=1492,size=42), Tensor(uid=2256,size=128)] [Tensor(uid=2257,size=28)]\n",
      "[<operator-2866, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2867, linear_qkv_merge>] None None\n",
      "[<operator-2296, linear_qkv_backward>] [Tensor(uid=1491,size=28), Tensor(uid=2253,size=14), Tensor(uid=2257,size=28)] [Tensor(uid=2258,size=28)]\n",
      "[<operator-2297, allreduce_backward>] [Tensor(uid=2258,size=28)] []\n",
      "[<operator-2890, add_forward_branch_loadin>] None None\n",
      "[<operator-2891, add_forward_merge>] None None\n",
      "[<operator-2298, layernorm_backward>] [Tensor(uid=1490,size=28), Tensor(uid=2258,size=28)] [Tensor(uid=2259,size=28)]\n",
      "[<operator-2299, backward_grad_accumulate_input>] [Tensor(uid=2259,size=28), Tensor(uid=2250,size=28)] []\n",
      "[<operator-2300, dropout_backward>] [Tensor(uid=1488,size=28), Tensor(uid=1489,size=14), Tensor(uid=2259,size=28)] [Tensor(uid=2260,size=28)]\n",
      "[<operator-2854, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2855, linear_2_forward_merge>] None None\n",
      "[<operator-2301, linear_2_backward>] [Tensor(uid=1486,size=56), Tensor(uid=2260,size=28)] [Tensor(uid=2261,size=56)]\n",
      "[<operator-2848, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2849, gelu_forward_merge>] None None\n",
      "[<operator-2302, gelu_backward>] [Tensor(uid=1485,size=56), Tensor(uid=2261,size=56)] [Tensor(uid=2262,size=56)]\n",
      "[<operator-2842, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2843, linear_1_forward_merge>] None None\n",
      "[<operator-2303, linear_1_backward>] [Tensor(uid=1484,size=28), Tensor(uid=2262,size=56)] [Tensor(uid=2263,size=28)]\n",
      "[<operator-2304, allreduce_backward>] [Tensor(uid=2263,size=28)] []\n",
      "[<operator-2860, add_forward_branch_loadin>] None None\n",
      "[<operator-2861, add_forward_merge>] None None\n",
      "[<operator-2305, layernorm_backward>] [Tensor(uid=1483,size=28), Tensor(uid=2263,size=28)] [Tensor(uid=2264,size=28)]\n",
      "[<operator-2306, backward_grad_accumulate_res1>] [Tensor(uid=2264,size=28), Tensor(uid=2259,size=28)] []\n",
      "[<operator-2307, output_dropout_backward>] [Tensor(uid=1481,size=28), Tensor(uid=1482,size=14), Tensor(uid=2264,size=28)] [Tensor(uid=2265,size=28)]\n",
      "[<operator-2830, linear_forward_branch_loadin>] None None\n",
      "[<operator-2831, linear_forward_merge>] None None\n",
      "[<operator-2308, linear_backward>] [Tensor(uid=1479,size=14), Tensor(uid=2265,size=28)] [Tensor(uid=2266,size=14)]\n",
      "[<operator-2824, matmul_v_branch_loadin>] None None\n",
      "[<operator-2825, matmul_v_merge>] None None\n",
      "[<operator-2309, matmul_v_backward>] [Tensor(uid=1477,size=128), Tensor(uid=1474,size=42), Tensor(uid=2266,size=14)] [Tensor(uid=2267,size=14), Tensor(uid=2268,size=128)]\n",
      "[<operator-2310, dropout_backward>] [Tensor(uid=1477,size=128), Tensor(uid=1478,size=64), Tensor(uid=2268,size=128)] [Tensor(uid=2269,size=128)]\n",
      "[<operator-2818, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2819, dropout_forward_merge>] None None\n",
      "[<operator-2311, softmax_backward>] [Tensor(uid=1476,size=128), Tensor(uid=2269,size=128)] [Tensor(uid=2270,size=128)]\n",
      "[<operator-2312, matmul_qk_backward>] [Tensor(uid=1474,size=42), Tensor(uid=2270,size=128)] [Tensor(uid=2271,size=28)]\n",
      "[<operator-2812, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2813, linear_qkv_merge>] None None\n",
      "[<operator-2313, linear_qkv_backward>] [Tensor(uid=1473,size=28), Tensor(uid=2267,size=14), Tensor(uid=2271,size=28)] [Tensor(uid=2272,size=28)]\n",
      "[<operator-2314, allreduce_backward>] [Tensor(uid=2272,size=28)] []\n",
      "[<operator-2836, add_forward_branch_loadin>] None None\n",
      "[<operator-2837, add_forward_merge>] None None\n",
      "[<operator-2315, layernorm_backward>] [Tensor(uid=1472,size=28), Tensor(uid=2272,size=28)] [Tensor(uid=2273,size=28)]\n",
      "[<operator-2316, backward_grad_accumulate_input>] [Tensor(uid=2273,size=28), Tensor(uid=2264,size=28)] []\n",
      "[<operator-2317, dropout_backward>] [Tensor(uid=1470,size=28), Tensor(uid=1471,size=14), Tensor(uid=2273,size=28)] [Tensor(uid=2274,size=28)]\n",
      "[<operator-2800, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2801, linear_2_forward_merge>] None None\n",
      "[<operator-2318, linear_2_backward>] [Tensor(uid=1468,size=56), Tensor(uid=2274,size=28)] [Tensor(uid=2275,size=56)]\n",
      "[<operator-2794, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2795, gelu_forward_merge>] None None\n",
      "[<operator-2319, gelu_backward>] [Tensor(uid=1467,size=56), Tensor(uid=2275,size=56)] [Tensor(uid=2276,size=56)]\n",
      "[<operator-2788, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2789, linear_1_forward_merge>] None None\n",
      "[<operator-2320, linear_1_backward>] [Tensor(uid=1466,size=28), Tensor(uid=2276,size=56)] [Tensor(uid=2277,size=28)]\n",
      "[<operator-2321, allreduce_backward>] [Tensor(uid=2277,size=28)] []\n",
      "[<operator-2806, add_forward_branch_loadin>] None None\n",
      "[<operator-2807, add_forward_merge>] None None\n",
      "[<operator-2322, layernorm_backward>] [Tensor(uid=1465,size=28), Tensor(uid=2277,size=28)] [Tensor(uid=2278,size=28)]\n",
      "[<operator-2323, backward_grad_accumulate_res1>] [Tensor(uid=2278,size=28), Tensor(uid=2273,size=28)] []\n",
      "[<operator-2324, output_dropout_backward>] [Tensor(uid=1463,size=28), Tensor(uid=1464,size=14), Tensor(uid=2278,size=28)] [Tensor(uid=2279,size=28)]\n",
      "[<operator-2776, linear_forward_branch_loadin>] None None\n",
      "[<operator-2777, linear_forward_merge>] None None\n",
      "[<operator-2325, linear_backward>] [Tensor(uid=1461,size=14), Tensor(uid=2279,size=28)] [Tensor(uid=2280,size=14)]\n",
      "[<operator-2770, matmul_v_branch_loadin>] None None\n",
      "[<operator-2771, matmul_v_merge>] None None\n",
      "[<operator-2326, matmul_v_backward>] [Tensor(uid=1459,size=128), Tensor(uid=1456,size=42), Tensor(uid=2280,size=14)] [Tensor(uid=2281,size=14), Tensor(uid=2282,size=128)]\n",
      "[<operator-2327, dropout_backward>] [Tensor(uid=1459,size=128), Tensor(uid=1460,size=64), Tensor(uid=2282,size=128)] [Tensor(uid=2283,size=128)]\n",
      "[<operator-2764, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2765, dropout_forward_merge>] None None\n",
      "[<operator-2328, softmax_backward>] [Tensor(uid=1458,size=128), Tensor(uid=2283,size=128)] [Tensor(uid=2284,size=128)]\n",
      "[<operator-2329, matmul_qk_backward>] [Tensor(uid=1456,size=42), Tensor(uid=2284,size=128)] [Tensor(uid=2285,size=28)]\n",
      "[<operator-2758, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2759, linear_qkv_merge>] None None\n",
      "[<operator-2330, linear_qkv_backward>] [Tensor(uid=1455,size=28), Tensor(uid=2281,size=14), Tensor(uid=2285,size=28)] [Tensor(uid=2286,size=28)]\n",
      "[<operator-2331, allreduce_backward>] [Tensor(uid=2286,size=28)] []\n",
      "[<operator-2782, add_forward_branch_loadin>] None None\n",
      "[<operator-2783, add_forward_merge>] None None\n",
      "[<operator-2332, layernorm_backward>] [Tensor(uid=1454,size=28), Tensor(uid=2286,size=28)] [Tensor(uid=2287,size=28)]\n",
      "[<operator-2333, backward_grad_accumulate_input>] [Tensor(uid=2287,size=28), Tensor(uid=2278,size=28)] []\n",
      "[<operator-2334, dropout_backward>] [Tensor(uid=1452,size=28), Tensor(uid=1453,size=14), Tensor(uid=2287,size=28)] [Tensor(uid=2288,size=28)]\n",
      "[<operator-2746, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2747, linear_2_forward_merge>] None None\n",
      "[<operator-2335, linear_2_backward>] [Tensor(uid=1450,size=56), Tensor(uid=2288,size=28)] [Tensor(uid=2289,size=56)]\n",
      "[<operator-2740, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2741, gelu_forward_merge>] None None\n",
      "[<operator-2336, gelu_backward>] [Tensor(uid=1449,size=56), Tensor(uid=2289,size=56)] [Tensor(uid=2290,size=56)]\n",
      "[<operator-2734, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2735, linear_1_forward_merge>] None None\n",
      "[<operator-2337, linear_1_backward>] [Tensor(uid=1448,size=28), Tensor(uid=2290,size=56)] [Tensor(uid=2291,size=28)]\n",
      "[<operator-2338, allreduce_backward>] [Tensor(uid=2291,size=28)] []\n",
      "[<operator-2752, add_forward_branch_loadin>] None None\n",
      "[<operator-2753, add_forward_merge>] None None\n",
      "[<operator-2339, layernorm_backward>] [Tensor(uid=1447,size=28), Tensor(uid=2291,size=28)] [Tensor(uid=2292,size=28)]\n",
      "[<operator-2340, backward_grad_accumulate_res1>] [Tensor(uid=2292,size=28), Tensor(uid=2287,size=28)] []\n",
      "[<operator-2341, output_dropout_backward>] [Tensor(uid=1445,size=28), Tensor(uid=1446,size=14), Tensor(uid=2292,size=28)] [Tensor(uid=2293,size=28)]\n",
      "[<operator-2722, linear_forward_branch_loadin>] None None\n",
      "[<operator-2723, linear_forward_merge>] None None\n",
      "[<operator-2342, linear_backward>] [Tensor(uid=1443,size=14), Tensor(uid=2293,size=28)] [Tensor(uid=2294,size=14)]\n",
      "[<operator-2716, matmul_v_branch_loadin>] None None\n",
      "[<operator-2717, matmul_v_merge>] None None\n",
      "[<operator-2343, matmul_v_backward>] [Tensor(uid=1441,size=128), Tensor(uid=1438,size=42), Tensor(uid=2294,size=14)] [Tensor(uid=2295,size=14), Tensor(uid=2296,size=128)]\n",
      "[<operator-2344, dropout_backward>] [Tensor(uid=1441,size=128), Tensor(uid=1442,size=64), Tensor(uid=2296,size=128)] [Tensor(uid=2297,size=128)]\n",
      "[<operator-2710, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2711, dropout_forward_merge>] None None\n",
      "[<operator-2345, softmax_backward>] [Tensor(uid=1440,size=128), Tensor(uid=2297,size=128)] [Tensor(uid=2298,size=128)]\n",
      "[<operator-2346, matmul_qk_backward>] [Tensor(uid=1438,size=42), Tensor(uid=2298,size=128)] [Tensor(uid=2299,size=28)]\n",
      "[<operator-2704, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2705, linear_qkv_merge>] None None\n",
      "[<operator-2347, linear_qkv_backward>] [Tensor(uid=1437,size=28), Tensor(uid=2295,size=14), Tensor(uid=2299,size=28)] [Tensor(uid=2300,size=28)]\n",
      "[<operator-2348, allreduce_backward>] [Tensor(uid=2300,size=28)] []\n",
      "[<operator-2728, add_forward_branch_loadin>] None None\n",
      "[<operator-2729, add_forward_merge>] None None\n",
      "[<operator-2349, layernorm_backward>] [Tensor(uid=1436,size=28), Tensor(uid=2300,size=28)] [Tensor(uid=2301,size=28)]\n",
      "[<operator-2350, backward_grad_accumulate_input>] [Tensor(uid=2301,size=28), Tensor(uid=2292,size=28)] []\n",
      "[<operator-2351, dropout_backward>] [Tensor(uid=1434,size=28), Tensor(uid=1435,size=14), Tensor(uid=2301,size=28)] [Tensor(uid=2302,size=28)]\n",
      "[<operator-2692, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2693, linear_2_forward_merge>] None None\n",
      "[<operator-2352, linear_2_backward>] [Tensor(uid=1432,size=56), Tensor(uid=2302,size=28)] [Tensor(uid=2303,size=56)]\n",
      "[<operator-2686, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2687, gelu_forward_merge>] None None\n",
      "[<operator-2353, gelu_backward>] [Tensor(uid=1431,size=56), Tensor(uid=2303,size=56)] [Tensor(uid=2304,size=56)]\n",
      "[<operator-2680, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2681, linear_1_forward_merge>] None None\n",
      "[<operator-2354, linear_1_backward>] [Tensor(uid=1430,size=28), Tensor(uid=2304,size=56)] [Tensor(uid=2305,size=28)]\n",
      "[<operator-2355, allreduce_backward>] [Tensor(uid=2305,size=28)] []\n",
      "[<operator-2698, add_forward_branch_loadin>] None None\n",
      "[<operator-2699, add_forward_merge>] None None\n",
      "[<operator-2356, layernorm_backward>] [Tensor(uid=1429,size=28), Tensor(uid=2305,size=28)] [Tensor(uid=2306,size=28)]\n",
      "[<operator-2357, backward_grad_accumulate_res1>] [Tensor(uid=2306,size=28), Tensor(uid=2301,size=28)] []\n",
      "[<operator-2358, output_dropout_backward>] [Tensor(uid=1427,size=28), Tensor(uid=1428,size=14), Tensor(uid=2306,size=28)] [Tensor(uid=2307,size=28)]\n",
      "[<operator-2668, linear_forward_branch_loadin>] None None\n",
      "[<operator-2669, linear_forward_merge>] None None\n",
      "[<operator-2359, linear_backward>] [Tensor(uid=1425,size=14), Tensor(uid=2307,size=28)] [Tensor(uid=2308,size=14)]\n",
      "[<operator-2662, matmul_v_branch_loadin>] None None\n",
      "[<operator-2663, matmul_v_merge>] None None\n",
      "[<operator-2360, matmul_v_backward>] [Tensor(uid=1423,size=128), Tensor(uid=1420,size=42), Tensor(uid=2308,size=14)] [Tensor(uid=2309,size=14), Tensor(uid=2310,size=128)]\n",
      "[<operator-2361, dropout_backward>] [Tensor(uid=1423,size=128), Tensor(uid=1424,size=64), Tensor(uid=2310,size=128)] [Tensor(uid=2311,size=128)]\n",
      "[<operator-2656, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2657, dropout_forward_merge>] None None\n",
      "[<operator-2362, softmax_backward>] [Tensor(uid=1422,size=128), Tensor(uid=2311,size=128)] [Tensor(uid=2312,size=128)]\n",
      "[<operator-2363, matmul_qk_backward>] [Tensor(uid=1420,size=42), Tensor(uid=2312,size=128)] [Tensor(uid=2313,size=28)]\n",
      "[<operator-2650, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2651, linear_qkv_merge>] None None\n",
      "[<operator-2364, linear_qkv_backward>] [Tensor(uid=1419,size=28), Tensor(uid=2309,size=14), Tensor(uid=2313,size=28)] [Tensor(uid=2314,size=28)]\n",
      "[<operator-2365, allreduce_backward>] [Tensor(uid=2314,size=28)] []\n",
      "[<operator-2674, add_forward_branch_loadin>] None None\n",
      "[<operator-2675, add_forward_merge>] None None\n",
      "[<operator-2366, layernorm_backward>] [Tensor(uid=1418,size=28), Tensor(uid=2314,size=28)] [Tensor(uid=2315,size=28)]\n",
      "[<operator-2367, backward_grad_accumulate_input>] [Tensor(uid=2315,size=28), Tensor(uid=2306,size=28)] []\n",
      "[<operator-2368, dropout_backward>] [Tensor(uid=1416,size=28), Tensor(uid=1417,size=14), Tensor(uid=2315,size=28)] [Tensor(uid=2316,size=28)]\n",
      "[<operator-2638, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2639, linear_2_forward_merge>] None None\n",
      "[<operator-2369, linear_2_backward>] [Tensor(uid=1414,size=56), Tensor(uid=2316,size=28)] [Tensor(uid=2317,size=56)]\n",
      "[<operator-2632, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2633, gelu_forward_merge>] None None\n",
      "[<operator-2370, gelu_backward>] [Tensor(uid=1413,size=56), Tensor(uid=2317,size=56)] [Tensor(uid=2318,size=56)]\n",
      "[<operator-2626, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2627, linear_1_forward_merge>] None None\n",
      "[<operator-2371, linear_1_backward>] [Tensor(uid=1412,size=28), Tensor(uid=2318,size=56)] [Tensor(uid=2319,size=28)]\n",
      "[<operator-2372, allreduce_backward>] [Tensor(uid=2319,size=28)] []\n",
      "[<operator-2644, add_forward_branch_loadin>] None None\n",
      "[<operator-2645, add_forward_merge>] None None\n",
      "[<operator-2373, layernorm_backward>] [Tensor(uid=1411,size=28), Tensor(uid=2319,size=28)] [Tensor(uid=2320,size=28)]\n",
      "[<operator-2374, backward_grad_accumulate_res1>] [Tensor(uid=2320,size=28), Tensor(uid=2315,size=28)] []\n",
      "[<operator-2375, output_dropout_backward>] [Tensor(uid=1409,size=28), Tensor(uid=1410,size=14), Tensor(uid=2320,size=28)] [Tensor(uid=2321,size=28)]\n",
      "[<operator-2614, linear_forward_branch_loadin>] None None\n",
      "[<operator-2615, linear_forward_merge>] None None\n",
      "[<operator-2376, linear_backward>] [Tensor(uid=1407,size=14), Tensor(uid=2321,size=28)] [Tensor(uid=2322,size=14)]\n",
      "[<operator-2608, matmul_v_branch_loadin>] None None\n",
      "[<operator-2609, matmul_v_merge>] None None\n",
      "[<operator-2377, matmul_v_backward>] [Tensor(uid=1405,size=128), Tensor(uid=1402,size=42), Tensor(uid=2322,size=14)] [Tensor(uid=2323,size=14), Tensor(uid=2324,size=128)]\n",
      "[<operator-2378, dropout_backward>] [Tensor(uid=1405,size=128), Tensor(uid=1406,size=64), Tensor(uid=2324,size=128)] [Tensor(uid=2325,size=128)]\n",
      "[<operator-2602, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2603, dropout_forward_merge>] None None\n",
      "[<operator-2379, softmax_backward>] [Tensor(uid=1404,size=128), Tensor(uid=2325,size=128)] [Tensor(uid=2326,size=128)]\n",
      "[<operator-2380, matmul_qk_backward>] [Tensor(uid=1402,size=42), Tensor(uid=2326,size=128)] [Tensor(uid=2327,size=28)]\n",
      "[<operator-2596, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2597, linear_qkv_merge>] None None\n",
      "[<operator-2381, linear_qkv_backward>] [Tensor(uid=1401,size=28), Tensor(uid=2323,size=14), Tensor(uid=2327,size=28)] [Tensor(uid=2328,size=28)]\n",
      "[<operator-2382, allreduce_backward>] [Tensor(uid=2328,size=28)] []\n",
      "[<operator-2620, add_forward_branch_loadin>] None None\n",
      "[<operator-2621, add_forward_merge>] None None\n",
      "[<operator-2383, layernorm_backward>] [Tensor(uid=1400,size=28), Tensor(uid=2328,size=28)] [Tensor(uid=2329,size=28)]\n",
      "[<operator-2384, backward_grad_accumulate_input>] [Tensor(uid=2329,size=28), Tensor(uid=2320,size=28)] []\n",
      "[<operator-2385, dropout_backward>] [Tensor(uid=1398,size=28), Tensor(uid=1399,size=14), Tensor(uid=2329,size=28)] [Tensor(uid=2330,size=28)]\n",
      "[<operator-2584, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2585, linear_2_forward_merge>] None None\n",
      "[<operator-2386, linear_2_backward>] [Tensor(uid=1396,size=56), Tensor(uid=2330,size=28)] [Tensor(uid=2331,size=56)]\n",
      "[<operator-2578, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2579, gelu_forward_merge>] None None\n",
      "[<operator-2387, gelu_backward>] [Tensor(uid=1395,size=56), Tensor(uid=2331,size=56)] [Tensor(uid=2332,size=56)]\n",
      "[<operator-2572, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2573, linear_1_forward_merge>] None None\n",
      "[<operator-2388, linear_1_backward>] [Tensor(uid=1394,size=28), Tensor(uid=2332,size=56)] [Tensor(uid=2333,size=28)]\n",
      "[<operator-2389, allreduce_backward>] [Tensor(uid=2333,size=28)] []\n",
      "[<operator-2590, add_forward_branch_loadin>] None None\n",
      "[<operator-2591, add_forward_merge>] None None\n",
      "[<operator-2390, layernorm_backward>] [Tensor(uid=1393,size=28), Tensor(uid=2333,size=28)] [Tensor(uid=2334,size=28)]\n",
      "[<operator-2391, backward_grad_accumulate_res1>] [Tensor(uid=2334,size=28), Tensor(uid=2329,size=28)] []\n",
      "[<operator-2392, output_dropout_backward>] [Tensor(uid=1391,size=28), Tensor(uid=1392,size=14), Tensor(uid=2334,size=28)] [Tensor(uid=2335,size=28)]\n",
      "[<operator-2560, linear_forward_branch_loadin>] None None\n",
      "[<operator-2561, linear_forward_merge>] None None\n",
      "[<operator-2393, linear_backward>] [Tensor(uid=1389,size=14), Tensor(uid=2335,size=28)] [Tensor(uid=2336,size=14)]\n",
      "[<operator-2554, matmul_v_branch_loadin>] None None\n",
      "[<operator-2555, matmul_v_merge>] None None\n",
      "[<operator-2394, matmul_v_backward>] [Tensor(uid=1387,size=128), Tensor(uid=1384,size=42), Tensor(uid=2336,size=14)] [Tensor(uid=2337,size=14), Tensor(uid=2338,size=128)]\n",
      "[<operator-2395, dropout_backward>] [Tensor(uid=1387,size=128), Tensor(uid=1388,size=64), Tensor(uid=2338,size=128)] [Tensor(uid=2339,size=128)]\n",
      "[<operator-2548, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2549, dropout_forward_merge>] None None\n",
      "[<operator-2396, softmax_backward>] [Tensor(uid=1386,size=128), Tensor(uid=2339,size=128)] [Tensor(uid=2340,size=128)]\n",
      "[<operator-2397, matmul_qk_backward>] [Tensor(uid=1384,size=42), Tensor(uid=2340,size=128)] [Tensor(uid=2341,size=28)]\n",
      "[<operator-2542, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2543, linear_qkv_merge>] None None\n",
      "[<operator-2398, linear_qkv_backward>] [Tensor(uid=1383,size=28), Tensor(uid=2337,size=14), Tensor(uid=2341,size=28)] [Tensor(uid=2342,size=28)]\n",
      "[<operator-2399, allreduce_backward>] [Tensor(uid=2342,size=28)] []\n",
      "[<operator-2566, add_forward_branch_loadin>] None None\n",
      "[<operator-2567, add_forward_merge>] None None\n",
      "[<operator-2400, layernorm_backward>] [Tensor(uid=1382,size=28), Tensor(uid=2342,size=28)] [Tensor(uid=2343,size=28)]\n",
      "[<operator-2401, backward_grad_accumulate_input>] [Tensor(uid=2343,size=28), Tensor(uid=2334,size=28)] []\n",
      "[<operator-2402, dropout_backward>] [Tensor(uid=1380,size=28), Tensor(uid=1381,size=14), Tensor(uid=2343,size=28)] [Tensor(uid=2344,size=28)]\n",
      "[<operator-2530, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2531, linear_2_forward_merge>] None None\n",
      "[<operator-2403, linear_2_backward>] [Tensor(uid=1378,size=56), Tensor(uid=2344,size=28)] [Tensor(uid=2345,size=56)]\n",
      "[<operator-2524, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2525, gelu_forward_merge>] None None\n",
      "[<operator-2404, gelu_backward>] [Tensor(uid=1377,size=56), Tensor(uid=2345,size=56)] [Tensor(uid=2346,size=56)]\n",
      "[<operator-2518, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2519, linear_1_forward_merge>] None None\n",
      "[<operator-2405, linear_1_backward>] [Tensor(uid=1376,size=28), Tensor(uid=2346,size=56)] [Tensor(uid=2347,size=28)]\n",
      "[<operator-2406, allreduce_backward>] [Tensor(uid=2347,size=28)] []\n",
      "[<operator-2536, add_forward_branch_loadin>] None None\n",
      "[<operator-2537, add_forward_merge>] None None\n",
      "[<operator-2407, layernorm_backward>] [Tensor(uid=1375,size=28), Tensor(uid=2347,size=28)] [Tensor(uid=2348,size=28)]\n",
      "[<operator-2408, backward_grad_accumulate_res1>] [Tensor(uid=2348,size=28), Tensor(uid=2343,size=28)] []\n",
      "[<operator-2409, output_dropout_backward>] [Tensor(uid=1373,size=28), Tensor(uid=1374,size=14), Tensor(uid=2348,size=28)] [Tensor(uid=2349,size=28)]\n",
      "[<operator-2506, linear_forward_branch_loadin>] None None\n",
      "[<operator-2507, linear_forward_merge>] None None\n",
      "[<operator-2410, linear_backward>] [Tensor(uid=1371,size=14), Tensor(uid=2349,size=28)] [Tensor(uid=2350,size=14)]\n",
      "[<operator-2500, matmul_v_branch_loadin>] None None\n",
      "[<operator-2501, matmul_v_merge>] None None\n",
      "[<operator-2411, matmul_v_backward>] [Tensor(uid=1369,size=128), Tensor(uid=1366,size=42), Tensor(uid=2350,size=14)] [Tensor(uid=2351,size=14), Tensor(uid=2352,size=128)]\n",
      "[<operator-2412, dropout_backward>] [Tensor(uid=1369,size=128), Tensor(uid=1370,size=64), Tensor(uid=2352,size=128)] [Tensor(uid=2353,size=128)]\n",
      "[<operator-2494, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2495, dropout_forward_merge>] None None\n",
      "[<operator-2413, softmax_backward>] [Tensor(uid=1368,size=128), Tensor(uid=2353,size=128)] [Tensor(uid=2354,size=128)]\n",
      "[<operator-2414, matmul_qk_backward>] [Tensor(uid=1366,size=42), Tensor(uid=2354,size=128)] [Tensor(uid=2355,size=28)]\n",
      "[<operator-2488, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2489, linear_qkv_merge>] None None\n",
      "[<operator-2415, linear_qkv_backward>] [Tensor(uid=1365,size=28), Tensor(uid=2351,size=14), Tensor(uid=2355,size=28)] [Tensor(uid=2356,size=28)]\n",
      "[<operator-2416, allreduce_backward>] [Tensor(uid=2356,size=28)] []\n",
      "[<operator-2512, add_forward_branch_loadin>] None None\n",
      "[<operator-2513, add_forward_merge>] None None\n",
      "[<operator-2417, layernorm_backward>] [Tensor(uid=1364,size=28), Tensor(uid=2356,size=28)] [Tensor(uid=2357,size=28)]\n",
      "[<operator-2418, backward_grad_accumulate_input>] [Tensor(uid=2357,size=28), Tensor(uid=2348,size=28)] []\n",
      "[<operator-2419, dropout_backward>] [Tensor(uid=1362,size=28), Tensor(uid=1363,size=14), Tensor(uid=2357,size=28)] [Tensor(uid=2358,size=28)]\n",
      "[<operator-2476, linear_2_forward_branch_loadin>] None None\n",
      "[<operator-2477, linear_2_forward_merge>] None None\n",
      "[<operator-2420, linear_2_backward>] [Tensor(uid=1360,size=56), Tensor(uid=2358,size=28)] [Tensor(uid=2359,size=56)]\n",
      "[<operator-2470, gelu_forward_branch_loadin>] None None\n",
      "[<operator-2471, gelu_forward_merge>] None None\n",
      "[<operator-2421, gelu_backward>] [Tensor(uid=1359,size=56), Tensor(uid=2359,size=56)] [Tensor(uid=2360,size=56)]\n",
      "[<operator-2464, linear_1_forward_branch_loadin>] None None\n",
      "[<operator-2465, linear_1_forward_merge>] None None\n",
      "[<operator-2422, linear_1_backward>] [Tensor(uid=1358,size=28), Tensor(uid=2360,size=56)] [Tensor(uid=2361,size=28)]\n",
      "[<operator-2423, allreduce_backward>] [Tensor(uid=2361,size=28)] []\n",
      "[<operator-2482, add_forward_branch_loadin>] None None\n",
      "[<operator-2483, add_forward_merge>] None None\n",
      "[<operator-2424, layernorm_backward>] [Tensor(uid=1357,size=28), Tensor(uid=2361,size=28)] [Tensor(uid=2362,size=28)]\n",
      "[<operator-2425, backward_grad_accumulate_res1>] [Tensor(uid=2362,size=28), Tensor(uid=2357,size=28)] []\n",
      "[<operator-2426, output_dropout_backward>] [Tensor(uid=1355,size=28), Tensor(uid=1356,size=14), Tensor(uid=2362,size=28)] [Tensor(uid=2363,size=28)]\n",
      "[<operator-2458, linear_forward_branch_loadin>] None None\n",
      "[<operator-2459, linear_forward_merge>] None None\n",
      "[<operator-2427, linear_backward>] [Tensor(uid=1353,size=14), Tensor(uid=2363,size=28)] [Tensor(uid=2364,size=14)]\n",
      "[<operator-2452, matmul_v_branch_loadin>] None None\n",
      "[<operator-2453, matmul_v_merge>] None None\n",
      "[<operator-2428, matmul_v_backward>] [Tensor(uid=1351,size=128), Tensor(uid=1348,size=42), Tensor(uid=2364,size=14)] [Tensor(uid=2365,size=14), Tensor(uid=2366,size=128)]\n",
      "[<operator-2429, dropout_backward>] [Tensor(uid=1351,size=128), Tensor(uid=1352,size=64), Tensor(uid=2366,size=128)] [Tensor(uid=2367,size=128)]\n",
      "[<operator-2446, dropout_forward_branch_loadin>] None None\n",
      "[<operator-2447, dropout_forward_merge>] None None\n",
      "[<operator-2430, softmax_backward>] [Tensor(uid=1350,size=128), Tensor(uid=2367,size=128)] [Tensor(uid=2368,size=128)]\n",
      "[<operator-2431, matmul_qk_backward>] [Tensor(uid=1348,size=42), Tensor(uid=2368,size=128)] [Tensor(uid=2369,size=28)]\n",
      "[<operator-2440, linear_qkv_branch_loadin>] None None\n",
      "[<operator-2441, linear_qkv_merge>] None None\n",
      "[<operator-2432, linear_qkv_backward>] [Tensor(uid=1347,size=28), Tensor(uid=2365,size=14), Tensor(uid=2369,size=28)] [Tensor(uid=2370,size=28)]\n",
      "[<operator-2433, allreduce_backward>] [Tensor(uid=2370,size=28)] []\n",
      "[<operator-2434, layernorm_backward>] [Tensor(uid=1218,size=28.0), Tensor(uid=2370,size=28)] [Tensor(uid=2371,size=28.0)]\n",
      "[<operator-2435, backward_grad_accumulate_input>] [Tensor(uid=2371,size=28.0), Tensor(uid=2362,size=28)] []\n"
     ]
    }
   ],
   "source": [
    "for _op in stream_0._flat_seq:\n",
    "        print([_op], \n",
    "              _op._input if isinstance(_op, FlattenOperator) else None,\n",
    "              _op._output if isinstance(_op, FlattenOperator) else None)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print(_interval_tot)\n",
    "# print(FlattenEngine()._interval_tot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_2_0_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
