{
    "Model Arc":"GPT-2, 1.3B model, TP=2, 2 GPU, Operator_time:ms, Activation Size:MB;",
    "Forward head Operator":[
        {
            "id":0,
            "type":0,
            "Description": "Embedding Opration (First Layer)",
            "Operator_time":4,
            "Model Size":89.7,
            "Model Tensor":"[25216, 1792]+[1024, 1792]，词典大小+位置Embedding",
        },
        {
            "id":1,
            "type":0,
            "Description": "FusedLayerNormAffineFunction",
            "Operator_time":0.067,
            "Activation Size":28,
            "Activation Size function":"2sbh",
            "Model Size":0.007,
            "Model Tensor":"LayerNorm的权重+偏置 [1792]+[1792]",
        }
    ],
    "Forward body Operator - recursive":[
        {
            "id":2,
            "type":0,
            "Description": "QKV_Linear",
            "Operator_time":0.49,
            "Activation Size":42,
            "Activation Size function":"6sbh/T",
            "Model Size":9.2,
            "Model Tensor":"QKV线性层权重（将QKV进行线性变换）+偏置，[2688, 1792]+[2688]",
        },
        {
            "id":3,
            "type":0,
            "Description": "Self-Attention-Q*K",
            "Operator_time":0.214,
        },
        {
            "id":4,
            "type":0,
            "Description": "Softmax",
            "Operator_time":0.163,
            "Activation Size":128,
            "Activation Size function":"2bass/T"
        },
        {
            "id":5,
            "type":0,
            "Description": "Dropout",
            "Operator_time":0.286,
            "Activation Size":192,
            "Activation Size function":"bass/T+2bass/T"
        },
        {
            "id":6,
            "type":0,
            "Description": "Self-Attention-Q*K*V",
            "Operator_time":0.191,
            "Activation Size":14,
            "Activation Size function":"2sbh/T"
        },
        {
            "id":7,
            "type":0,
            "Description": "Attention_Linear",
            "Operator_time":0.146,
            //"Activation Size":28,
            //"Activation Size function":"2sbh",
            "Model Size":3.06,
            "Model Tensor":"线性层输出结果权重+偏置，[1792, 896]+[1792]",

        },
        {
            "id":8,
            "type":1,
            "Description": "Attention_forward_AllReduce",
            "Operator_time":2.2
        },
        {
            "id":9,
            "type":0,
            "Description": "Attention_Dropout",
            "Operator_time":0.14,
            "Activation Size":42,
            "Activation Size function":"sbh+2sbh"
        },
        {
            "id":10,
            "type":0,
            "Description": "FusedLayerNormAffineFunction",
            "Operator_time":0.067,
            "Activation Size":28,
            "Activation Size function":"2sbh",
            "Model Size":0.007,
            "Model Tensor":"LayerNorm的权重+偏置，[1792] + [1792]",
        },
        {
            "id":11,
            "type":2,
            "Description": "bubble",
            "Operator_time":0.182
        },
        {
            "id":12,
            "type":0,
            "Description": "MLP_Linear_1",
            "Operator_time":0.512,
            "Activation Size":56,
            "Activation Size function":"8sbh/T",
            "Model Size":12.26,
            "Model Tensor":"h_to_4h线性层权重+偏置，[3584, 1792]+[3584]",
        },
        {
            "id":13,
            "type":0,
            "Description": "GeLU_1",
            "Operator_time":0.428,
            "Activation Size":56,
            "Activation Size function":"8sbh/T"
        },
        {
            "id":14,
            "type":0,
            "Description": "MLP_Linear_2",
            "Operator_time":0.483,
            //"Activation Size":28,
            //"Activation Size function":"2sbh",
            "Model Size":12.25,
            "Model Tensor":"4h_to_h线性层权重+偏置，[1792, 3584]+[1792]",
        },
        {
            "id":15,
            "type":1,
            "Description": "MLP_forward_AllReduce",
            "Operator_time":2.2
        },
        {
            "id":16,
            "type":0,
            "Description": "add",
            "Operator_time":0.067
        },
        {
            "id":17,
            "type":0,
            "Description": "Dropout",
            "Operator_time":0.075,
            "Activation Size":42,
            "Activation Size function":"sbh+2sbh"
        },
        {
            "id":18,
            "type":0,
            "Description": "FusedLayerNormAffineFunction",
            "Operator_time":0.067,
            "Activation Size":28,
            "Activation Size function":"2sbh",
            "Model Size":0.007,
            "Model Tensor":"LayerNorm的权重+偏置，[1792] + [1792]"
        }
    ],

    "Forward tail Operator":[
        {
            "id":19,
            "type":0,
            "Description": "Linear",
            "Operator_time":3.162
        },
        {
            "id":20,
            "type":0,
            "Description": "others",
            "Operator_time":4.2
        },
        {
            "id":21,
            "type":0,
            "Description": "CrossEntropy",
            "Operator_time":4.38
        }
    ],
    
    "Backward head Operator":[
        {
            "id":22,
            "type":0,
            "Description": "Backward oprations",
            "Operator_time":8
        },
        {
            "id":23,
            "type":0,
            "Description": "FusedLayerNormAffineFunctionBackward",
            "Operator_time":0.066
        }
    ],


    "Backward body Operator - recursive":[
        {
            "id":24,
            "type":0,
            "Description": "add",
            "Operator_time":0.06
        },
        {
            "id":25,
            "type":0,
            "Description": "dropout_backward",
            "Operator_time":0.053 
        },
        {
            "id":26,
            "type":0,
            "Description": "sum + add",
            "Operator_time":0.049
        },
        {
            "id":27,
            "type":0,
            "Description": "MLP_Linear_2_back",
            "Operator_time":0.1
        },
        {
            "id":28,
            "type":0,
            "Description": "GeLU",
            "Operator_time":0.21
        },
        {
            "id":29,
            "type":0,
            "Description": "MLP_Linear_1_back",
            "Operator_time":0.442
        },
        {
            "id":30,
            "type":1,
            "Description": "MLP_backward_AllReduce",
            "Operator_time":2.231
        },
        {
            "id":31,
            "type":0,
            "Description": "Accumulate_add",
            "Operator_time":0.032
        },
        {
            "id":32,
            "type":0,
            "Description": "FusedLayerNormAffineFunctionBackward",
            "Operator_time":0.222
        },
        {
            "id":33,
            "type":0,
            "Description": "add",
            "Operator_time":0.01
        },
        {
            "id":34,
            "type":0,
            "Description": "Dropout_backward",
            "Operator_time":0.055
        },
        {
            "id":35,
            "type":0,
            "Description": "sum + add",
            "Operator_time":0.1
        },
        {
            "id":36,
            "type":0,
            "Description": "Attention_Linear",
            "Operator_time":0.25
        },
        {
            "id":37,
            "type":0,
            "Description": "Self-Attention-Q*K*V",
            "Operator_time":0.36
        },
        {
            "id":38,
            "type":0,
            "Description": "Dropout",
            "Operator_time":0.248
        },
        {
            "id":39,
            "type":0,
            "Description": "Softmax",
            "Operator_time":0.212
        },
        {
            "id":40,
            "type":0,
            "Description": "Self-Attention-Q*K",
            "Operator_time":0.531
        },
        {
            "id":41,
            "type":0,
            "Description": "Linear_back",
            "Operator_time":0.34
        },
        {
            "id":42,
            "type":1,
            "Description": "Attention_backward_AllReduce",
            "Operator_time":2.275
        },
        {
            "id":43,
            "type":0,
            "Description": "FusedLayerNormAffineFunctionBackward",
            "Operator_time":0.236
        }
    ],

    "Backward tail Operator":[
        {
            "id":44,
            "type":0,
            "Description": "Backward end",
            "Operator_time":2.3
        }
    ],
    "Gradient Update":[
        {
            "id":45,
            "type":0,
            "Description": "Gradient Update",
            "Operator_time":49
        }
    ]
}


